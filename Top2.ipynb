{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from skopt.space import Integer, Categorical, Real, Log10\n",
    "# from skopt.utils import use_named_args\n",
    "# from skopt import gp_minimize\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import gensim\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 设备信息，包括品牌和型号\n",
    "deviced_brand=pd.read_csv('./Demo/deviceid_brand.tsv',sep='\\t', names=['device_id','brand','model'])\n",
    "# 读取 app 信息，包括 app 所属的类别\n",
    "package_label=pd.read_csv('./Demo/package_label.tsv',sep='\\t',names=['app','class1','class2'])\n",
    "# 读取训练数据集\n",
    "deviceid_train=pd.read_csv('./Demo/deviceid_train.tsv',sep='\\t',names=['device_id','sex','age'])\n",
    "# 读取测试数据集\n",
    "deviceid_test=pd.read_csv('./Demo/deviceid_test.tsv',sep='\\t',names=['device_id'])\n",
    "# 读取 app 数据\n",
    "app_category=pd.read_csv('./Demo/package_label.tsv',sep='\\t', names=['app', 'category', 'app_name'])\n",
    "# 读取设备安装的 app 数据\n",
    "deviceid_packages=pd.read_csv('./Demo/deviceid_packages.tsv',sep='\\t', names=['device_id','apps'])\n",
    "# 读取 APP 使用情况\n",
    "package_time=pd.read_csv('./Demo/deviceid_package_start_close.tsv',sep='\\t',names=['device_id','app','start','close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户 APP 使用行为特征构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算 app 使用时长，单位为秒\n",
    "package_time['period']=(package_time['close']-package_time['start'])/1000\n",
    "# 把 app 的开始使用时间戳转换为 pd.datetime 数据类型\n",
    "package_time['start']=pd.to_datetime(package_time['start'], unit='ms')\n",
    "# 删除 app 使用结束的时间戳\n",
    "del package_time['close']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别提取 app 开始使用的小时，日期，和星期几\n",
    "package_time['hour']=package_time['start'].dt.hour\n",
    "package_time['date']=package_time['start'].dt.date\n",
    "package_time['dayofweek']=package_time['start'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>app</th>\n",
       "      <th>start</th>\n",
       "      <th>period</th>\n",
       "      <th>hour</th>\n",
       "      <th>date</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>e0450666692b72a1f580dfa082e8b2ae</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>2017-03-09 02:05:23.086</td>\n",
       "      <td>10.014</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>e0450666692b72a1f580dfa082e8b2ae</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>2017-03-09 02:09:53.513</td>\n",
       "      <td>5.002</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>e0450666692b72a1f580dfa082e8b2ae</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>2017-03-09 02:11:03.551</td>\n",
       "      <td>1119.971</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>e0450666692b72a1f580dfa082e8b2ae</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>2017-03-09 04:41:04.940</td>\n",
       "      <td>19.984</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>e0450666692b72a1f580dfa082e8b2ae</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>2017-03-09 09:02:56.275</td>\n",
       "      <td>25.001</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id                               app  \\\n",
       "0  e0450666692b72a1f580dfa082e8b2ae  1896072db9ce6406febfc17f681c2086   \n",
       "1  e0450666692b72a1f580dfa082e8b2ae  1896072db9ce6406febfc17f681c2086   \n",
       "2  e0450666692b72a1f580dfa082e8b2ae  1896072db9ce6406febfc17f681c2086   \n",
       "3  e0450666692b72a1f580dfa082e8b2ae  1896072db9ce6406febfc17f681c2086   \n",
       "4  e0450666692b72a1f580dfa082e8b2ae  1896072db9ce6406febfc17f681c2086   \n",
       "\n",
       "                    start    period  hour        date  dayofweek  \n",
       "0 2017-03-09 02:05:23.086    10.014     2  2017-03-09          3  \n",
       "1 2017-03-09 02:09:53.513     5.002     2  2017-03-09          3  \n",
       "2 2017-03-09 02:11:03.551  1119.971     2  2017-03-09          3  \n",
       "3 2017-03-09 04:41:04.940    19.984     4  2017-03-09          3  \n",
       "4 2017-03-09 09:02:56.275    25.001     9  2017-03-09          3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计每个设备分别在每天、每小时、每周几、每个 APP 上使用的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算每个设备的每天使用时间\n",
    "dtime=package_time.groupby(['device_id','date'])['period'].agg('sum')\n",
    "#计算每个设备的每小时使用时间\n",
    "qtime=package_time.groupby(['device_id','hour'])['period'].agg('sum')\n",
    "#计算每个设备的每周几使用时间\n",
    "wtime=package_time.groupby(['device_id','dayofweek'])['period'].agg('sum')\n",
    "#计算每个设备上每个 app 的使用时间\n",
    "atime=package_time.groupby(['device_id','app'])['period'].agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id                         date      \n",
       "00009270c4ec26e1d76f5d86847009c9  2017-02-28    37312.432\n",
       "                                  2017-03-01       22.518\n",
       "                                  2017-03-02     5264.417\n",
       "                                  2017-03-03      642.991\n",
       "                                  2017-03-04       12.237\n",
       "Name: period, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计每个设备使用 APP 数量的方差、平均值、最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个设备每天使用的 app 数量\n",
    "# 首先根据 ['device_id', 'date'] 分组，然后将每个设备每天的所有 app 用空格连接起来\n",
    "dapp=package_time[['device_id', 'date', 'app']].drop_duplicates().groupby(['device_id', 'date'])['app'].agg(' '.join)\n",
    "dapp = dapp.reset_index()\n",
    "# 根据空格分隔 app，并计算数量\n",
    "dapp['app_nums']=dapp['app'].apply(lambda x: x.split(' ')).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>date</th>\n",
       "      <th>app</th>\n",
       "      <th>app_nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>2017-03-04</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id        date  \\\n",
       "0  00009270c4ec26e1d76f5d86847009c9  2017-02-28   \n",
       "1  00009270c4ec26e1d76f5d86847009c9  2017-03-01   \n",
       "2  00009270c4ec26e1d76f5d86847009c9  2017-03-02   \n",
       "3  00009270c4ec26e1d76f5d86847009c9  2017-03-03   \n",
       "4  00009270c4ec26e1d76f5d86847009c9  2017-03-04   \n",
       "\n",
       "                                app  app_nums  \n",
       "0  1896072db9ce6406febfc17f681c2086         1  \n",
       "1  1896072db9ce6406febfc17f681c2086         1  \n",
       "2  1896072db9ce6406febfc17f681c2086         1  \n",
       "3  1896072db9ce6406febfc17f681c2086         1  \n",
       "4  1896072db9ce6406febfc17f681c2086         1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dapp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# 计算每个设备使用 APP 数量的方差、平均值、最大值。 agg() 中可以传入多个函数对 groupby 对象的操作函数\n",
    "dapp_stat = dapp.groupby('device_id')['app_nums'].agg(\n",
    "    {'std': 'std', 'mean': 'mean', 'max': 'max'})\n",
    "dapp_stat = dapp_stat.reset_index()\n",
    "dapp_stat.columns = ['device_id', 'app_num_std', 'app_num_mean', 'app_num_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>app_num_std</th>\n",
       "      <th>app_num_mean</th>\n",
       "      <th>app_num_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>0.461133</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>1.565763</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00026d79a6f0955fc860947724e24765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002e3afb8146bc08e40575e45f0eca6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0004709a296f9b925ae283efe2f043e7</td>\n",
       "      <td>2.366120</td>\n",
       "      <td>5.206897</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id  app_num_std  app_num_mean  app_num_max\n",
       "0  00009270c4ec26e1d76f5d86847009c9     0.461133      1.166667            3\n",
       "1  000189ef5d5b951841d416a8c6c5b995     1.565763      9.500000           12\n",
       "2  00026d79a6f0955fc860947724e24765     0.000000      1.000000            1\n",
       "3  0002e3afb8146bc08e40575e45f0eca6     1.000000      2.000000            3\n",
       "4  0004709a296f9b925ae283efe2f043e7     2.366120      5.206897           11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dapp_stat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计每个设备使用时间的和、方差、平均值、最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "dtime = dtime.reset_index()\n",
    "# 和上面的操作类似，计算每个设备使用时间的和、方差、平均值、最大值\n",
    "dtime_stat = dtime.groupby(['device_id'])['period'].agg(\n",
    "    {'sum': 'sum', 'mean': 'mean', 'std': 'std', 'max': 'max'}).reset_index()\n",
    "dtime_stat.columns = ['device_id', 'date_sum',\n",
    "                      'date_mean', 'date_std', 'date_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>date_sum</th>\n",
       "      <th>date_mean</th>\n",
       "      <th>date_std</th>\n",
       "      <th>date_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>334102.661</td>\n",
       "      <td>11136.755367</td>\n",
       "      <td>18704.949809</td>\n",
       "      <td>63619.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>1099796.807</td>\n",
       "      <td>34368.650219</td>\n",
       "      <td>25602.049326</td>\n",
       "      <td>93056.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00026d79a6f0955fc860947724e24765</td>\n",
       "      <td>669.056</td>\n",
       "      <td>223.018667</td>\n",
       "      <td>318.287555</td>\n",
       "      <td>588.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002e3afb8146bc08e40575e45f0eca6</td>\n",
       "      <td>476878.857</td>\n",
       "      <td>68125.551000</td>\n",
       "      <td>161844.346716</td>\n",
       "      <td>433661.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0004709a296f9b925ae283efe2f043e7</td>\n",
       "      <td>413026.398</td>\n",
       "      <td>14242.289586</td>\n",
       "      <td>11618.480923</td>\n",
       "      <td>49783.284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id     date_sum     date_mean       date_std  \\\n",
       "0  00009270c4ec26e1d76f5d86847009c9   334102.661  11136.755367   18704.949809   \n",
       "1  000189ef5d5b951841d416a8c6c5b995  1099796.807  34368.650219   25602.049326   \n",
       "2  00026d79a6f0955fc860947724e24765      669.056    223.018667     318.287555   \n",
       "3  0002e3afb8146bc08e40575e45f0eca6   476878.857  68125.551000  161844.346716   \n",
       "4  0004709a296f9b925ae283efe2f043e7   413026.398  14242.289586   11618.480923   \n",
       "\n",
       "     date_max  \n",
       "0   63619.553  \n",
       "1   93056.309  \n",
       "2     588.807  \n",
       "3  433661.470  \n",
       "4   49783.284  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtime_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>0</td>\n",
       "      <td>32.902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id  hour  period\n",
       "0  00009270c4ec26e1d76f5d86847009c9     0  32.902"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtime.reset_index().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 通过透视把每个设备的每个小时的使用时间的转置。变换之前的数据每个设备有 24 行，每行表示设备每个小时的使用时间。\n",
    "# 变换之后的数据有 24 列，每一列表示设备每个小时的使用时间\n",
    "qtime = qtime.reset_index()\n",
    "ftime = qtime.pivot(index='device_id', columns='hour',\n",
    "                    values='period').fillna(0)\n",
    "# 设置列名\n",
    "ftime.columns = ['h%s' % i for i in range(24)]\n",
    "ftime.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>h6</th>\n",
       "      <th>h7</th>\n",
       "      <th>h8</th>\n",
       "      <th>...</th>\n",
       "      <th>h14</th>\n",
       "      <th>h15</th>\n",
       "      <th>h16</th>\n",
       "      <th>h17</th>\n",
       "      <th>h18</th>\n",
       "      <th>h19</th>\n",
       "      <th>h20</th>\n",
       "      <th>h21</th>\n",
       "      <th>h22</th>\n",
       "      <th>h23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>32.902</td>\n",
       "      <td>3120.354</td>\n",
       "      <td>19409.942</td>\n",
       "      <td>80.586</td>\n",
       "      <td>44333.680</td>\n",
       "      <td>6281.700</td>\n",
       "      <td>21345.857</td>\n",
       "      <td>72144.487</td>\n",
       "      <td>752.370</td>\n",
       "      <td>...</td>\n",
       "      <td>60830.868</td>\n",
       "      <td>23066.936</td>\n",
       "      <td>28958.591</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>760.276</td>\n",
       "      <td>916.438</td>\n",
       "      <td>2579.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>38946.746</td>\n",
       "      <td>60793.584</td>\n",
       "      <td>49900.472</td>\n",
       "      <td>29420.010</td>\n",
       "      <td>78586.490</td>\n",
       "      <td>4256.499</td>\n",
       "      <td>9826.159</td>\n",
       "      <td>47229.344</td>\n",
       "      <td>66209.618</td>\n",
       "      <td>...</td>\n",
       "      <td>122468.084</td>\n",
       "      <td>59922.699</td>\n",
       "      <td>151795.372</td>\n",
       "      <td>30074.698</td>\n",
       "      <td>319.986</td>\n",
       "      <td>9457.775</td>\n",
       "      <td>5928.054</td>\n",
       "      <td>11045.564</td>\n",
       "      <td>5461.401</td>\n",
       "      <td>9960.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00026d79a6f0955fc860947724e24765</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>71.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002e3afb8146bc08e40575e45f0eca6</td>\n",
       "      <td>1252.860</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1207.510</td>\n",
       "      <td>656.173</td>\n",
       "      <td>277.510</td>\n",
       "      <td>20.466</td>\n",
       "      <td>889.112</td>\n",
       "      <td>431349.747</td>\n",
       "      <td>79.942</td>\n",
       "      <td>...</td>\n",
       "      <td>34971.811</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0004709a296f9b925ae283efe2f043e7</td>\n",
       "      <td>19263.344</td>\n",
       "      <td>43943.525</td>\n",
       "      <td>35355.233</td>\n",
       "      <td>19295.768</td>\n",
       "      <td>21957.694</td>\n",
       "      <td>14968.913</td>\n",
       "      <td>23465.262</td>\n",
       "      <td>17109.129</td>\n",
       "      <td>18054.109</td>\n",
       "      <td>...</td>\n",
       "      <td>8517.143</td>\n",
       "      <td>5339.508</td>\n",
       "      <td>6430.394</td>\n",
       "      <td>585.658</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7827.382</td>\n",
       "      <td>9094.190</td>\n",
       "      <td>13483.280</td>\n",
       "      <td>35541.093</td>\n",
       "      <td>27232.087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id         h0         h1         h2  \\\n",
       "0  00009270c4ec26e1d76f5d86847009c9     32.902   3120.354  19409.942   \n",
       "1  000189ef5d5b951841d416a8c6c5b995  38946.746  60793.584  49900.472   \n",
       "2  00026d79a6f0955fc860947724e24765      0.000      0.000      0.000   \n",
       "3  0002e3afb8146bc08e40575e45f0eca6   1252.860      0.000   1207.510   \n",
       "4  0004709a296f9b925ae283efe2f043e7  19263.344  43943.525  35355.233   \n",
       "\n",
       "          h3         h4         h5         h6          h7         h8  ...  \\\n",
       "0     80.586  44333.680   6281.700  21345.857   72144.487    752.370  ...   \n",
       "1  29420.010  78586.490   4256.499   9826.159   47229.344  66209.618  ...   \n",
       "2      0.000      0.000      0.000      0.000       0.000      0.000  ...   \n",
       "3    656.173    277.510     20.466    889.112  431349.747     79.942  ...   \n",
       "4  19295.768  21957.694  14968.913  23465.262   17109.129  18054.109  ...   \n",
       "\n",
       "          h14        h15         h16        h17      h18       h19       h20  \\\n",
       "0   60830.868  23066.936   28958.591      0.000    0.000     0.000     0.000   \n",
       "1  122468.084  59922.699  151795.372  30074.698  319.986  9457.775  5928.054   \n",
       "2       0.000      0.000       0.000      0.000    0.000     0.000     0.000   \n",
       "3   34971.811      0.000       0.000      0.000    0.000     0.000     0.000   \n",
       "4    8517.143   5339.508    6430.394    585.658    0.000  7827.382  9094.190   \n",
       "\n",
       "         h21        h22        h23  \n",
       "0    760.276    916.438   2579.052  \n",
       "1  11045.564   5461.401   9960.791  \n",
       "2      0.000      0.000     71.046  \n",
       "3      0.000      0.000      0.000  \n",
       "4  13483.280  35541.093  27232.087  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtime = wtime.reset_index()\n",
    "# 通过透视把每个设备的每个周几的使用时间的转置。变换之前的数据每个设备有 7 行，每行表示设备每个周几的使用时间。\n",
    "# 变换之后的数据有 7 列，每一列表示设备每个周几的使用时间\n",
    "weektime = wtime.pivot(\n",
    "    index='device_id', columns='dayofweek', values='period').fillna(0)\n",
    "weektime.columns = ['w0', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6']\n",
    "weektime.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>24704.498</td>\n",
       "      <td>138049.645</td>\n",
       "      <td>55275.594</td>\n",
       "      <td>11877.301</td>\n",
       "      <td>27579.032</td>\n",
       "      <td>65830.257</td>\n",
       "      <td>10786.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>126464.294</td>\n",
       "      <td>231742.053</td>\n",
       "      <td>137188.344</td>\n",
       "      <td>169735.847</td>\n",
       "      <td>206564.846</td>\n",
       "      <td>161872.151</td>\n",
       "      <td>66229.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00026d79a6f0955fc860947724e24765</td>\n",
       "      <td>9.203</td>\n",
       "      <td>71.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>588.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002e3afb8146bc08e40575e45f0eca6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>435997.167</td>\n",
       "      <td>94.055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>257.875</td>\n",
       "      <td>39759.475</td>\n",
       "      <td>770.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0004709a296f9b925ae283efe2f043e7</td>\n",
       "      <td>22878.187</td>\n",
       "      <td>67882.311</td>\n",
       "      <td>38606.127</td>\n",
       "      <td>79848.598</td>\n",
       "      <td>85544.656</td>\n",
       "      <td>79216.949</td>\n",
       "      <td>39049.570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id          w0          w1          w2  \\\n",
       "0  00009270c4ec26e1d76f5d86847009c9   24704.498  138049.645   55275.594   \n",
       "1  000189ef5d5b951841d416a8c6c5b995  126464.294  231742.053  137188.344   \n",
       "2  00026d79a6f0955fc860947724e24765       9.203      71.046       0.000   \n",
       "3  0002e3afb8146bc08e40575e45f0eca6       0.000  435997.167      94.055   \n",
       "4  0004709a296f9b925ae283efe2f043e7   22878.187   67882.311   38606.127   \n",
       "\n",
       "           w3          w4          w5         w6  \n",
       "0   11877.301   27579.032   65830.257  10786.334  \n",
       "1  169735.847  206564.846  161872.151  66229.272  \n",
       "2       0.000       0.000       0.000    588.807  \n",
       "3       0.000     257.875   39759.475    770.285  \n",
       "4   79848.598   85544.656   79216.949  39049.570  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weektime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>app</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>330562.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id                               app  \\\n",
       "0  00009270c4ec26e1d76f5d86847009c9  1896072db9ce6406febfc17f681c2086   \n",
       "\n",
       "      period  \n",
       "0  330562.65  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atime.reset_index().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  找出每个设备上使用时间最多的 app 的行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id\n",
       "00009270c4ec26e1d76f5d86847009c9     0\n",
       "000189ef5d5b951841d416a8c6c5b995    10\n",
       "00026d79a6f0955fc860947724e24765    22\n",
       "0002e3afb8146bc08e40575e45f0eca6    25\n",
       "0004709a296f9b925ae283efe2f043e7    36\n",
       "Name: period, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出每个设备上使用时间最多的 app 的行索引\n",
    "atime = atime.reset_index()\n",
    "app = atime.groupby(['device_id'])['period'].idxmax()\n",
    "app.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把表连接起来，得到用户行为数据表\n",
    "# dapp_stat 是每个设备每天使用 APP 数量的方差、平均值、最大值\n",
    "# dtime_stat 是每个设备使用时间的和、方差、平均值、最大值\n",
    "user = pd.merge(dapp_stat, dtime_stat, on='device_id', how='left')\n",
    "# ftime 是每个设备的每个小时的使用时间\n",
    "user = pd.merge(user, ftime, on='device_id', how='left')\n",
    "# weektime 是每个设备的每个周几的使用时间\n",
    "user = pd.merge(user, weektime, on='device_id', how='left')\n",
    "# atime.iloc[app] 表示每个设备使用时间最多的app 的名字和时间\n",
    "user = pd.merge(user, atime.iloc[app], on='device_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>app_num_std</th>\n",
       "      <th>app_num_mean</th>\n",
       "      <th>app_num_max</th>\n",
       "      <th>date_sum</th>\n",
       "      <th>date_mean</th>\n",
       "      <th>date_std</th>\n",
       "      <th>date_max</th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>...</th>\n",
       "      <th>h23</th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>app</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>0.461133</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>3</td>\n",
       "      <td>334102.661</td>\n",
       "      <td>11136.755367</td>\n",
       "      <td>18704.949809</td>\n",
       "      <td>63619.553</td>\n",
       "      <td>32.902</td>\n",
       "      <td>3120.354</td>\n",
       "      <td>...</td>\n",
       "      <td>2579.052</td>\n",
       "      <td>24704.498</td>\n",
       "      <td>138049.645</td>\n",
       "      <td>55275.594</td>\n",
       "      <td>11877.301</td>\n",
       "      <td>27579.032</td>\n",
       "      <td>65830.257</td>\n",
       "      <td>10786.334</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>330562.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>1.565763</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>1099796.807</td>\n",
       "      <td>34368.650219</td>\n",
       "      <td>25602.049326</td>\n",
       "      <td>93056.309</td>\n",
       "      <td>38946.746</td>\n",
       "      <td>60793.584</td>\n",
       "      <td>...</td>\n",
       "      <td>9960.791</td>\n",
       "      <td>126464.294</td>\n",
       "      <td>231742.053</td>\n",
       "      <td>137188.344</td>\n",
       "      <td>169735.847</td>\n",
       "      <td>206564.846</td>\n",
       "      <td>161872.151</td>\n",
       "      <td>66229.272</td>\n",
       "      <td>5e8709466b22da6b45bfd30825bd3620</td>\n",
       "      <td>621111.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00026d79a6f0955fc860947724e24765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>669.056</td>\n",
       "      <td>223.018667</td>\n",
       "      <td>318.287555</td>\n",
       "      <td>588.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>71.046</td>\n",
       "      <td>9.203</td>\n",
       "      <td>71.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>588.807</td>\n",
       "      <td>c33b35d6254ad9c0c238233eb97a6c60</td>\n",
       "      <td>669.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002e3afb8146bc08e40575e45f0eca6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>476878.857</td>\n",
       "      <td>68125.551000</td>\n",
       "      <td>161844.346716</td>\n",
       "      <td>433661.470</td>\n",
       "      <td>1252.860</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>435997.167</td>\n",
       "      <td>94.055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>257.875</td>\n",
       "      <td>39759.475</td>\n",
       "      <td>770.285</td>\n",
       "      <td>97d0422a3317b1929926dc90cda4fc53</td>\n",
       "      <td>471532.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0004709a296f9b925ae283efe2f043e7</td>\n",
       "      <td>2.366120</td>\n",
       "      <td>5.206897</td>\n",
       "      <td>11</td>\n",
       "      <td>413026.398</td>\n",
       "      <td>14242.289586</td>\n",
       "      <td>11618.480923</td>\n",
       "      <td>49783.284</td>\n",
       "      <td>19263.344</td>\n",
       "      <td>43943.525</td>\n",
       "      <td>...</td>\n",
       "      <td>27232.087</td>\n",
       "      <td>22878.187</td>\n",
       "      <td>67882.311</td>\n",
       "      <td>38606.127</td>\n",
       "      <td>79848.598</td>\n",
       "      <td>85544.656</td>\n",
       "      <td>79216.949</td>\n",
       "      <td>39049.570</td>\n",
       "      <td>86f9f299cdbc8e2a19fed1712f522c49</td>\n",
       "      <td>346571.338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id  app_num_std  app_num_mean  app_num_max  \\\n",
       "0  00009270c4ec26e1d76f5d86847009c9     0.461133      1.166667            3   \n",
       "1  000189ef5d5b951841d416a8c6c5b995     1.565763      9.500000           12   \n",
       "2  00026d79a6f0955fc860947724e24765     0.000000      1.000000            1   \n",
       "3  0002e3afb8146bc08e40575e45f0eca6     1.000000      2.000000            3   \n",
       "4  0004709a296f9b925ae283efe2f043e7     2.366120      5.206897           11   \n",
       "\n",
       "      date_sum     date_mean       date_std    date_max         h0         h1  \\\n",
       "0   334102.661  11136.755367   18704.949809   63619.553     32.902   3120.354   \n",
       "1  1099796.807  34368.650219   25602.049326   93056.309  38946.746  60793.584   \n",
       "2      669.056    223.018667     318.287555     588.807      0.000      0.000   \n",
       "3   476878.857  68125.551000  161844.346716  433661.470   1252.860      0.000   \n",
       "4   413026.398  14242.289586   11618.480923   49783.284  19263.344  43943.525   \n",
       "\n",
       "   ...        h23          w0          w1          w2          w3          w4  \\\n",
       "0  ...   2579.052   24704.498  138049.645   55275.594   11877.301   27579.032   \n",
       "1  ...   9960.791  126464.294  231742.053  137188.344  169735.847  206564.846   \n",
       "2  ...     71.046       9.203      71.046       0.000       0.000       0.000   \n",
       "3  ...      0.000       0.000  435997.167      94.055       0.000     257.875   \n",
       "4  ...  27232.087   22878.187   67882.311   38606.127   79848.598   85544.656   \n",
       "\n",
       "           w5         w6                               app      period  \n",
       "0   65830.257  10786.334  1896072db9ce6406febfc17f681c2086  330562.650  \n",
       "1  161872.151  66229.272  5e8709466b22da6b45bfd30825bd3620  621111.263  \n",
       "2       0.000    588.807  c33b35d6254ad9c0c238233eb97a6c60     669.056  \n",
       "3   39759.475    770.285  97d0422a3317b1929926dc90cda4fc53  471532.292  \n",
       "4   79216.949  39049.570  86f9f299cdbc8e2a19fed1712f522c49  346571.338  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理 APP 类别，加上编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>系统工具</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>金融</td>\n",
       "      <td>976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>教育</td>\n",
       "      <td>843</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>其它</td>\n",
       "      <td>776</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>休闲</td>\n",
       "      <td>625</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  idx\n",
       "系统工具      1005    0\n",
       "金融         976    1\n",
       "教育         843    2\n",
       "其它         776    3\n",
       "休闲         625    4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算每种类别的数量，并且添加编号 idx，结果中类别名作为索引\n",
    "cat_enc = pd.DataFrame(app_category['category'].value_counts())\n",
    "cat_enc['idx']=range(cat_enc.shape[0])\n",
    "cat_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>category</th>\n",
       "      <th>app_name</th>\n",
       "      <th>cat_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8c4ac9e7f1d13362a7a443d9fe385d48</td>\n",
       "      <td>实用工具</td>\n",
       "      <td>日历应用</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>991a8d9248a0b224c8cdc6feda5c70a9</td>\n",
       "      <td>视频</td>\n",
       "      <td>网络电视</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b255f4de409d3f905b8432e6564cd243</td>\n",
       "      <td>母婴亲子</td>\n",
       "      <td>孕育工具助手</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>215263e647821ceb627c55a27475871a</td>\n",
       "      <td>金融</td>\n",
       "      <td>投资理财</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>92b700e7f608dbfe4247809dc6e6dfd0</td>\n",
       "      <td>其它</td>\n",
       "      <td>其它</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                app category app_name  cat_enc\n",
       "0  8c4ac9e7f1d13362a7a443d9fe385d48     实用工具     日历应用        9\n",
       "1  991a8d9248a0b224c8cdc6feda5c70a9       视频     网络电视       10\n",
       "2  b255f4de409d3f905b8432e6564cd243     母婴亲子   孕育工具助手       39\n",
       "3  215263e647821ceb627c55a27475871a       金融     投资理财        1\n",
       "4  92b700e7f608dbfe4247809dc6e6dfd0       其它       其它        3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 map 函数，将每个类别对应的编号映射到原来的 app 表中\n",
    "app_category['cat_enc'] = app_category['category'].map(cat_enc['idx'])\n",
    "app_category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 app 所在的列设置为索引\n",
    "app_category.set_index(['app'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将每个设备的每个 APP 的使用时间的表添加编号映射，如果没有编号，则填入 45\n",
    "atime['app_cat_enc'] = atime['app'].map(app_category['cat_enc']).fillna(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>app</th>\n",
       "      <th>period</th>\n",
       "      <th>app_cat_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>330562.650</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>8c8544b6c129ad4a431be753143ed1c3</td>\n",
       "      <td>15.585</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>90cb852cf345e04d508fe03f74089183</td>\n",
       "      <td>3524.426</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>039be717f253f7b10ed1ce405de08b9f</td>\n",
       "      <td>22.455</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>0b0816ff97e9a3e5501ed2dcb4a0d66e</td>\n",
       "      <td>69578.566</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id                               app  \\\n",
       "0  00009270c4ec26e1d76f5d86847009c9  1896072db9ce6406febfc17f681c2086   \n",
       "1  00009270c4ec26e1d76f5d86847009c9  8c8544b6c129ad4a431be753143ed1c3   \n",
       "2  00009270c4ec26e1d76f5d86847009c9  90cb852cf345e04d508fe03f74089183   \n",
       "3  000189ef5d5b951841d416a8c6c5b995  039be717f253f7b10ed1ce405de08b9f   \n",
       "4  000189ef5d5b951841d416a8c6c5b995  0b0816ff97e9a3e5501ed2dcb4a0d66e   \n",
       "\n",
       "       period  app_cat_enc  \n",
       "0  330562.650          6.0  \n",
       "1      15.585         28.0  \n",
       "2    3524.426         45.0  \n",
       "3      22.455         45.0  \n",
       "4   69578.566         45.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计每个设备在每个APP类别分别使用了多少个 APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个设备在每个APP类别分别使用了多少个 APP\n",
    "cat_num = atime.groupby(['device_id', 'app_cat_enc'])['app'].agg('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个设备在每个APP类别分别使用了多长时间\n",
    "cat_time = atime.groupby(['device_id', 'app_cat_enc'])[\n",
    "    'period'].agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>app_cat_enc</th>\n",
       "      <th>app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id  app_cat_enc  app\n",
       "0  00009270c4ec26e1d76f5d86847009c9          6.0    1\n",
       "1  00009270c4ec26e1d76f5d86847009c9         28.0    1\n",
       "2  00009270c4ec26e1d76f5d86847009c9         45.0    1\n",
       "3  000189ef5d5b951841d416a8c6c5b995          6.0    1\n",
       "4  000189ef5d5b951841d416a8c6c5b995          7.0    2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cat36</th>\n",
       "      <th>cat37</th>\n",
       "      <th>cat38</th>\n",
       "      <th>cat39</th>\n",
       "      <th>cat40</th>\n",
       "      <th>cat41</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat43</th>\n",
       "      <th>cat44</th>\n",
       "      <th>cat45</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00026d79a6f0955fc860947724e24765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0002e3afb8146bc08e40575e45f0eca6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0004709a296f9b925ae283efe2f043e7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  cat0  cat1  cat2  cat3  cat4  cat5  cat6  \\\n",
       "device_id                                                                    \n",
       "00009270c4ec26e1d76f5d86847009c9   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n",
       "000189ef5d5b951841d416a8c6c5b995   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n",
       "00026d79a6f0955fc860947724e24765   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "0002e3afb8146bc08e40575e45f0eca6   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n",
       "0004709a296f9b925ae283efe2f043e7   1.0   1.0   0.0   0.0   0.0   1.0   1.0   \n",
       "\n",
       "                                  cat7  cat8  cat9  ...  cat36  cat37  cat38  \\\n",
       "device_id                                           ...                        \n",
       "00009270c4ec26e1d76f5d86847009c9   0.0   0.0   0.0  ...    0.0    0.0    0.0   \n",
       "000189ef5d5b951841d416a8c6c5b995   2.0   0.0   0.0  ...    0.0    0.0    0.0   \n",
       "00026d79a6f0955fc860947724e24765   0.0   0.0   0.0  ...    0.0    0.0    0.0   \n",
       "0002e3afb8146bc08e40575e45f0eca6   0.0   0.0   0.0  ...    0.0    0.0    0.0   \n",
       "0004709a296f9b925ae283efe2f043e7   0.0   0.0   0.0  ...    0.0    0.0    0.0   \n",
       "\n",
       "                                  cat39  cat40  cat41  cat42  cat43  cat44  \\\n",
       "device_id                                                                    \n",
       "00009270c4ec26e1d76f5d86847009c9    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "000189ef5d5b951841d416a8c6c5b995    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "00026d79a6f0955fc860947724e24765    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "0002e3afb8146bc08e40575e45f0eca6    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "0004709a296f9b925ae283efe2f043e7    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "                                  cat45  \n",
       "device_id                                \n",
       "00009270c4ec26e1d76f5d86847009c9    1.0  \n",
       "000189ef5d5b951841d416a8c6c5b995   15.0  \n",
       "00026d79a6f0955fc860947724e24765    1.0  \n",
       "0002e3afb8146bc08e40575e45f0eca6    2.0  \n",
       "0004709a296f9b925ae283efe2f043e7   11.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过透视来转置。变换之后的数据有 46 列，每一列表示某个列别的 APP 个数。\n",
    "app_cat_num = cat_num.pivot(index='device_id', columns='app_cat_enc', values='app').fillna(0)\n",
    "app_cat_num.columns = ['cat%s' % i for i in range(46)]\n",
    "app_cat_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计每个设备在每个APP类别分别使用了多长时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time0</th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>time4</th>\n",
       "      <th>time5</th>\n",
       "      <th>time6</th>\n",
       "      <th>time7</th>\n",
       "      <th>time8</th>\n",
       "      <th>time9</th>\n",
       "      <th>...</th>\n",
       "      <th>time36</th>\n",
       "      <th>time37</th>\n",
       "      <th>time38</th>\n",
       "      <th>time39</th>\n",
       "      <th>time40</th>\n",
       "      <th>time41</th>\n",
       "      <th>time42</th>\n",
       "      <th>time43</th>\n",
       "      <th>time44</th>\n",
       "      <th>time45</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>330562.650</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3524.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>144465.215</td>\n",
       "      <td>622228.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330802.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00026d79a6f0955fc860947724e24765</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>669.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0002e3afb8146bc08e40575e45f0eca6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5213.155</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>471665.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0004709a296f9b925ae283efe2f043e7</td>\n",
       "      <td>80.021</td>\n",
       "      <td>885.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19890.917</td>\n",
       "      <td>18157.668</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370306.639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   time0   time1  time2  time3  time4  \\\n",
       "device_id                                                               \n",
       "00009270c4ec26e1d76f5d86847009c9   0.000    0.00    0.0    0.0    0.0   \n",
       "000189ef5d5b951841d416a8c6c5b995   0.000    0.00    0.0    0.0    0.0   \n",
       "00026d79a6f0955fc860947724e24765   0.000    0.00    0.0    0.0    0.0   \n",
       "0002e3afb8146bc08e40575e45f0eca6   0.000    0.00    0.0    0.0    0.0   \n",
       "0004709a296f9b925ae283efe2f043e7  80.021  885.89    0.0    0.0    0.0   \n",
       "\n",
       "                                      time5       time6      time7  time8  \\\n",
       "device_id                                                                   \n",
       "00009270c4ec26e1d76f5d86847009c9      0.000  330562.650       0.00    0.0   \n",
       "000189ef5d5b951841d416a8c6c5b995      0.000  144465.215  622228.87    0.0   \n",
       "00026d79a6f0955fc860947724e24765      0.000       0.000       0.00    0.0   \n",
       "0002e3afb8146bc08e40575e45f0eca6      0.000    5213.155       0.00    0.0   \n",
       "0004709a296f9b925ae283efe2f043e7  19890.917   18157.668       0.00    0.0   \n",
       "\n",
       "                                  time9  ...  time36  time37  time38  time39  \\\n",
       "device_id                                ...                                   \n",
       "00009270c4ec26e1d76f5d86847009c9    0.0  ...     0.0     0.0     0.0     0.0   \n",
       "000189ef5d5b951841d416a8c6c5b995    0.0  ...     0.0     0.0     0.0     0.0   \n",
       "00026d79a6f0955fc860947724e24765    0.0  ...     0.0     0.0     0.0     0.0   \n",
       "0002e3afb8146bc08e40575e45f0eca6    0.0  ...     0.0     0.0     0.0     0.0   \n",
       "0004709a296f9b925ae283efe2f043e7    0.0  ...     0.0     0.0     0.0     0.0   \n",
       "\n",
       "                                  time40  time41  time42  time43  time44  \\\n",
       "device_id                                                                  \n",
       "00009270c4ec26e1d76f5d86847009c9     0.0     0.0     0.0     0.0     0.0   \n",
       "000189ef5d5b951841d416a8c6c5b995     0.0     0.0     0.0     0.0     0.0   \n",
       "00026d79a6f0955fc860947724e24765     0.0     0.0     0.0     0.0     0.0   \n",
       "0002e3afb8146bc08e40575e45f0eca6     0.0     0.0     0.0     0.0     0.0   \n",
       "0004709a296f9b925ae283efe2f043e7     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "                                      time45  \n",
       "device_id                                     \n",
       "00009270c4ec26e1d76f5d86847009c9    3524.426  \n",
       "000189ef5d5b951841d416a8c6c5b995  330802.368  \n",
       "00026d79a6f0955fc860947724e24765     669.056  \n",
       "0002e3afb8146bc08e40575e45f0eca6  471665.702  \n",
       "0004709a296f9b925ae283efe2f043e7  370306.639  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过透视来转置每个设备在每个APP类别分别使用了多长时间。变换之后的数据有 46 列，每一列表示设备在某个列别的使用时长。\n",
    "app_cat_time=cat_time.pivot(index='device_id', values='period', columns='app_cat_enc').fillna(0)\n",
    "app_cat_time.columns = ['time%s' % i for i in range(46)]\n",
    "app_cat_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并上面的两张表，并保存到 user_behavior.csv\n",
    "user = pd.merge(user, app_cat_num, on='device_id', how='left')\n",
    "user = pd.merge(user, app_cat_time, on='device_id', how='left')\n",
    "user.to_csv('Demo/user_behavior.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看内存占用，优化内存使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>memory</th>\n",
       "      <th>convert_memory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>package_time</td>\n",
       "      <td>9180235152</td>\n",
       "      <td>9GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>dapp</td>\n",
       "      <td>438686771</td>\n",
       "      <td>418MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>dtime</td>\n",
       "      <td>185835035</td>\n",
       "      <td>177MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>atime</td>\n",
       "      <td>148545564</td>\n",
       "      <td>142MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>qtime</td>\n",
       "      <td>125594117</td>\n",
       "      <td>120MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>user</td>\n",
       "      <td>89745142</td>\n",
       "      <td>86MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>wtime</td>\n",
       "      <td>45867197</td>\n",
       "      <td>44MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>deviceid_packages</td>\n",
       "      <td>35813634</td>\n",
       "      <td>34MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>app_cat_time</td>\n",
       "      <td>33236263</td>\n",
       "      <td>32MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>app_cat_num</td>\n",
       "      <td>33236263</td>\n",
       "      <td>32MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>cat_time</td>\n",
       "      <td>26492177</td>\n",
       "      <td>25MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>cat_num</td>\n",
       "      <td>26492177</td>\n",
       "      <td>25MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>ftime</td>\n",
       "      <td>20436439</td>\n",
       "      <td>19MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>deviced_brand</td>\n",
       "      <td>15833907</td>\n",
       "      <td>15MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>weektime</td>\n",
       "      <td>10545567</td>\n",
       "      <td>10MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>_7</td>\n",
       "      <td>9143498</td>\n",
       "      <td>9MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>dtime_stat</td>\n",
       "      <td>8800119</td>\n",
       "      <td>8MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>dapp_stat</td>\n",
       "      <td>8218303</td>\n",
       "      <td>8MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>app</td>\n",
       "      <td>7054543</td>\n",
       "      <td>7MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>deviceid_train</td>\n",
       "      <td>5250152</td>\n",
       "      <td>5MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>app_category</td>\n",
       "      <td>3148208</td>\n",
       "      <td>3MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>package_label</td>\n",
       "      <td>2779184</td>\n",
       "      <td>3MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>deviceid_test</td>\n",
       "      <td>2022855</td>\n",
       "      <td>2MB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name      memory convert_memory\n",
       "6        package_time  9180235152            9GB\n",
       "12               dapp   438686771          418MB\n",
       "7               dtime   185835035          177MB\n",
       "10              atime   148545564          142MB\n",
       "8               qtime   125594117          120MB\n",
       "18               user    89745142           86MB\n",
       "9               wtime    45867197           44MB\n",
       "5   deviceid_packages    35813634           34MB\n",
       "22       app_cat_time    33236263           32MB\n",
       "21        app_cat_num    33236263           32MB\n",
       "20           cat_time    26492177           25MB\n",
       "19            cat_num    26492177           25MB\n",
       "15              ftime    20436439           19MB\n",
       "0       deviced_brand    15833907           15MB\n",
       "16           weektime    10545567           10MB\n",
       "11                 _7     9143498            9MB\n",
       "14         dtime_stat     8800119            8MB\n",
       "13          dapp_stat     8218303            8MB\n",
       "17                app     7054543            7MB\n",
       "2      deviceid_train     5250152            5MB\n",
       "4        app_category     3148208            3MB\n",
       "1       package_label     2779184            3MB\n",
       "3       deviceid_test     2022855            2MB"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sys import getsizeof\n",
    "def get_memory(threshold=1048576):\n",
    "    '''查看变量占用内存情况\n",
    "\n",
    "    :param threshold: 仅显示内存数值大于等于threshold的变量, 默认为 1MB=1048576B\n",
    "    '''\n",
    "    memory_df=pd.DataFrame(columns=['name', 'memory', 'convert_memory'])\n",
    "    i=0\n",
    "    for key in list(globals().keys()):\n",
    "        memory = eval(\"getsizeof({})\".format(key))\n",
    "        if memory<threshold:\n",
    "            continue\n",
    "        if(memory>1073741824):# GB\n",
    "            unit='GB'\n",
    "            convert_memory=round(memory/1073741824)\n",
    "        elif(memory>1048576):# MB\n",
    "            unit='MB'\n",
    "            convert_memory=round(memory/1048576)           \n",
    "        elif(memory>1024):# KB\n",
    "            unit='KB'\n",
    "            convert_memory=round(memory/1024)  \n",
    "        else:\n",
    "            unit='B' \n",
    "            convert_memory = memory\n",
    "        memory_df.loc[i]=[key, memory, str(convert_memory)+unit]\n",
    "        i=i+1\n",
    "    # 按照内存占用大小降序排序    \n",
    "    memory_df.sort_values(\"memory\",inplace=True,ascending=False)\n",
    "    return memory_df\n",
    "    \n",
    "memory_df = get_memory()\n",
    "memory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        # 如果当前列的类型不是 object，剩下就是 int,int32, float,float32 等\n",
    "        if col_type != object:\n",
    "            # 取出这一列的最小值\n",
    "            c_min = df[col].min()\n",
    "            # 取出这一列的最大值\n",
    "            c_max = df[col].max()\n",
    "            # 如果类型是 int 开头的\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                # 如果最大值和最小值都在 int8 的范围内，则转为 int8\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                # 如果最大值和最小值都在 int16 的范围内，则转为 int16\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                # 如果最大值和最小值都在 int32 的范围内，则转为 int32\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                # 如果最大值和最小值都在 int64 的范围内，则转为 int64\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            elif str(col_type)[:3] == 'float':# 如果类型是 float 开头的\n",
    "                # 如果最大值和最小值都在 float16 的范围内，则转为 float16\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                # 如果最大值和最小值都在 float32 的范围内，则转为 float32\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / (1024 ** 2) # 计算用了多少 M\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961.11 Mb, 1470.83 Mb (25.00 %)\n"
     ]
    }
   ],
   "source": [
    "package_time = reduce_mem(package_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除变量，回收内存\n",
    "del dapp\n",
    "del dtime\n",
    "del qtime\n",
    "del dtime_stat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手机属性特征构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>app</th>\n",
       "      <th>start</th>\n",
       "      <th>period</th>\n",
       "      <th>hour</th>\n",
       "      <th>date</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>e0450666692b72a1f580dfa082e8b2ae</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>2017-03-09 02:05:23.086</td>\n",
       "      <td>10.014</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>e0450666692b72a1f580dfa082e8b2ae</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>2017-03-09 02:09:53.513</td>\n",
       "      <td>5.002</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>e0450666692b72a1f580dfa082e8b2ae</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>2017-03-09 02:11:03.551</td>\n",
       "      <td>1119.971</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>e0450666692b72a1f580dfa082e8b2ae</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>2017-03-09 04:41:04.940</td>\n",
       "      <td>19.984</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>e0450666692b72a1f580dfa082e8b2ae</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>2017-03-09 09:02:56.275</td>\n",
       "      <td>25.001</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id                               app  \\\n",
       "0  e0450666692b72a1f580dfa082e8b2ae  1896072db9ce6406febfc17f681c2086   \n",
       "1  e0450666692b72a1f580dfa082e8b2ae  1896072db9ce6406febfc17f681c2086   \n",
       "2  e0450666692b72a1f580dfa082e8b2ae  1896072db9ce6406febfc17f681c2086   \n",
       "3  e0450666692b72a1f580dfa082e8b2ae  1896072db9ce6406febfc17f681c2086   \n",
       "4  e0450666692b72a1f580dfa082e8b2ae  1896072db9ce6406febfc17f681c2086   \n",
       "\n",
       "                    start    period  hour        date  dayofweek  \n",
       "0 2017-03-09 02:05:23.086    10.014     2  2017-03-09          3  \n",
       "1 2017-03-09 02:09:53.513     5.002     2  2017-03-09          3  \n",
       "2 2017-03-09 02:11:03.551  1119.971     2  2017-03-09          3  \n",
       "3 2017-03-09 04:41:04.940    19.984     4  2017-03-09          3  \n",
       "4 2017-03-09 09:02:56.275    25.001     9  2017-03-09          3  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  统计每个设备在前 100 个 APP的使用时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个 APP 使用的时长总和，并取出使用时间最长的前 100 个 APP 的名称\n",
    "app_use_time = package_time.groupby(['app'])['period'].agg('sum').reset_index()\n",
    "app_use_top100 = app_use_time.sort_values(by='period', ascending=False)[:100]['app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把 app 列设置为索引，取出使用时间最长的前 100 个\n",
    "use_time_top100_statis=atime.set_index('app').loc[list(app_use_top100)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>device_id</th>\n",
       "      <th>period</th>\n",
       "      <th>app_cat_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>330562.650</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>144465.215</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>0002e3afb8146bc08e40575e45f0eca6</td>\n",
       "      <td>5213.155</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>0004709a296f9b925ae283efe2f043e7</td>\n",
       "      <td>18157.668</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>000536b155abcf97971a6b99a6d7dbef</td>\n",
       "      <td>261031.006</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                app                         device_id  \\\n",
       "0  1896072db9ce6406febfc17f681c2086  00009270c4ec26e1d76f5d86847009c9   \n",
       "1  1896072db9ce6406febfc17f681c2086  000189ef5d5b951841d416a8c6c5b995   \n",
       "2  1896072db9ce6406febfc17f681c2086  0002e3afb8146bc08e40575e45f0eca6   \n",
       "3  1896072db9ce6406febfc17f681c2086  0004709a296f9b925ae283efe2f043e7   \n",
       "4  1896072db9ce6406febfc17f681c2086  000536b155abcf97971a6b99a6d7dbef   \n",
       "\n",
       "       period  app_cat_enc  \n",
       "0  330562.650          6.0  \n",
       "1  144465.215          6.0  \n",
       "2    5213.155          6.0  \n",
       "3   18157.668          6.0  \n",
       "4  261031.006          6.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_time_top100_statis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71843, 101)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过透视来转置每个设备在前 100 个 APP的使用时间。变换之后的数据有 100 列，每一列表示设备在这个 APP 使用的时间。\n",
    "top100_statis = use_time_top100_statis.pivot(\n",
    "    index='device_id', columns='app', values='period').reset_index().fillna(0)\n",
    "top100_statis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>f69cdc2f5018aa6d3d6500976b926c09</td>\n",
       "      <td>samsung</td>\n",
       "      <td>GT-N7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>522690089a93278b65025127d937e9bb</td>\n",
       "      <td>samsung</td>\n",
       "      <td>GT-I9507V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>dcf13c9ec255153bfa909dc3c64908c3</td>\n",
       "      <td>Sony</td>\n",
       "      <td>L39u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>58b5f0ec136407caf3708a4b05c1894f</td>\n",
       "      <td>Sony</td>\n",
       "      <td>L39u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>dbca7cb790645b18383f4536e7f1f303</td>\n",
       "      <td>Sony</td>\n",
       "      <td>XM50h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id    brand      model\n",
       "0  f69cdc2f5018aa6d3d6500976b926c09  samsung   GT-N7100\n",
       "1  522690089a93278b65025127d937e9bb  samsung  GT-I9507V\n",
       "2  dcf13c9ec255153bfa909dc3c64908c3     Sony       L39u\n",
       "3  58b5f0ec136407caf3708a4b05c1894f     Sony       L39u\n",
       "4  dbca7cb790645b18383f4536e7f1f303     Sony      XM50h"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviced_brand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计每个设备所属的`品牌_型号`的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果品牌名有空格，则取前面的作为新品牌名\n",
    "deviced_brand.brand=deviced_brand.brand.astype(str).apply(lambda x:x.split(' ')[0].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把品牌和型号拼接起来，作为新的字段\n",
    "deviced_brand['ph_ver'] = deviced_brand['brand'] + '_' + deviced_brand['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计品牌_型号的数量\n",
    "ph_ver = deviced_brand['ph_ver'].value_counts()\n",
    "ph_ver_cnt = pd.DataFrame(ph_ver).reset_index()\n",
    "ph_ver_cnt.columns = ['ph_ver', 'ph_ver_cnt']\n",
    "# 和原表拼接起来\n",
    "deviced_brand = pd.merge(left=deviced_brand, right=ph_ver_cnt, on='ph_ver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>ph_ver</th>\n",
       "      <th>ph_ver_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>f69cdc2f5018aa6d3d6500976b926c09</td>\n",
       "      <td>SAMSUNG</td>\n",
       "      <td>GT-N7100</td>\n",
       "      <td>SAMSUNG_GT-N7100</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7f0119f89b0874947ad11de689744910</td>\n",
       "      <td>SAMSUNG</td>\n",
       "      <td>GT-N7100</td>\n",
       "      <td>SAMSUNG_GT-N7100</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>afc87cbe98e92af973fbd06016e7dd75</td>\n",
       "      <td>SAMSUNG</td>\n",
       "      <td>GT-N7100</td>\n",
       "      <td>SAMSUNG_GT-N7100</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>e2b1082e60c79a5adc2ec17ae5d2e320</td>\n",
       "      <td>SAMSUNG</td>\n",
       "      <td>GT-N7100</td>\n",
       "      <td>SAMSUNG_GT-N7100</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7ecdb8fda13fbfb8ecfedd0a842bc50b</td>\n",
       "      <td>SAMSUNG</td>\n",
       "      <td>GT-N7100</td>\n",
       "      <td>SAMSUNG_GT-N7100</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id    brand     model            ph_ver  \\\n",
       "0  f69cdc2f5018aa6d3d6500976b926c09  SAMSUNG  GT-N7100  SAMSUNG_GT-N7100   \n",
       "1  7f0119f89b0874947ad11de689744910  SAMSUNG  GT-N7100  SAMSUNG_GT-N7100   \n",
       "2  afc87cbe98e92af973fbd06016e7dd75  SAMSUNG  GT-N7100  SAMSUNG_GT-N7100   \n",
       "3  e2b1082e60c79a5adc2ec17ae5d2e320  SAMSUNG  GT-N7100  SAMSUNG_GT-N7100   \n",
       "4  7ecdb8fda13fbfb8ecfedd0a842bc50b  SAMSUNG  GT-N7100  SAMSUNG_GT-N7100   \n",
       "\n",
       "   ph_ver_cnt  \n",
       "0        1320  \n",
       "1        1320  \n",
       "2        1320  \n",
       "3        1320  \n",
       "4        1320  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviced_brand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 针对长尾分布做的一点处理\n",
    "mask = (deviced_brand.ph_ver_cnt < 100)\n",
    "deviced_brand.loc[mask, 'ph_ver'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将手机属性数据和训练集、测试集合并\n",
    "deviceid_train = pd.merge(deviced_brand[['device_id', 'ph_ver']],\n",
    "                 deviceid_train, on='device_id', how='right')\n",
    "deviceid_test = pd.merge(deviced_brand[['device_id', 'ph_ver']],\n",
    "                deviceid_test, on='device_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 ph_ver 进行 label encoder\n",
    "deviceid_train['ph_ver'] = deviceid_train['ph_ver'].astype(str)\n",
    "deviceid_test['ph_ver'] = deviceid_test['ph_ver'].astype(str)\n",
    "ph_ver_le = preprocessing.LabelEncoder()\n",
    "deviceid_train['ph_ver'] = ph_ver_le.fit_transform(deviceid_train['ph_ver'])\n",
    "deviceid_test['ph_ver'] = ph_ver_le.transform(deviceid_test['ph_ver'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并训练集、测试集，构造标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造标签，并对标签进行 label encoder\n",
    "deviceid_train['label'] = deviceid_train['sex'].astype(str) + '-' + deviceid_train['age'].astype(str)\n",
    "label_le = preprocessing.LabelEncoder()\n",
    "deviceid_train['label'] = label_le.fit_transform(deviceid_train['label'])\n",
    "\n",
    "# 把测试集的标签进行处理，合并训练集和测试集\n",
    "deviceid_test['sex'] = -1\n",
    "deviceid_test['age'] = -1\n",
    "deviceid_test['label'] = -1\n",
    "data = pd.concat([deviceid_train, deviceid_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 将 ph_ver 进行独热编码\n",
    "ph_ver_dummy = pd.get_dummies(data['ph_ver'])\n",
    "ph_ver_dummy.columns = ['ph_ver_%s' %i\n",
    "                        for i in range(ph_ver_dummy.shape[1])]\n",
    "data = pd.concat([data, ph_ver_dummy], axis=1)\n",
    "del data['ph_ver']\n",
    "deviceid_train = data[data['sex']!=-1]\n",
    "deviceid_test = data[data['sex']==-1]\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计每个app的总使用次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>app_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "      <td>12050342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>07e967d75aab2f6a52c558695a572a7c</td>\n",
       "      <td>3557203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8d2448133beb3422f0f638bacf8f7051</td>\n",
       "      <td>1287254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>e29eb7083bdf54af48352ffa979fc830</td>\n",
       "      <td>1153291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4b58ecb20fe0d5e7a823b7d95911166d</td>\n",
       "      <td>817326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                app   app_num\n",
       "0  1896072db9ce6406febfc17f681c2086  12050342\n",
       "1  07e967d75aab2f6a52c558695a572a7c   3557203\n",
       "2  8d2448133beb3422f0f638bacf8f7051   1287254\n",
       "3  e29eb7083bdf54af48352ffa979fc830   1153291\n",
       "4  4b58ecb20fe0d5e7a823b7d95911166d    817326"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计每个app的总使用次数\n",
    "app_num = package_time['app'].value_counts().reset_index()\n",
    "app_num.columns = ['app', 'app_num']\n",
    "app_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 将 APP 的使用次数和原表合并\n",
    "package_time = pd.merge(left=package_time, right=app_num, how='inner',on='app')\n",
    "# 同样的，针对长尾分布做些处理（尝试过不做处理，或换其他阈值，这个100的阈值的准确率最高）\n",
    "package_time.loc[package_time.app_num < 100, 'app'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计每台设备的app数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每台设备的app数量\n",
    "df_app = package_time[['device_id', 'app']]\n",
    "apps = df_app.drop_duplicates().groupby(['device_id'])[\n",
    "    'app'].apply(' '.join).reset_index()\n",
    "apps['app_length'] = apps['app'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "# 这是另一种统计每台设备的app数量的方法\n",
    "# df_app = package_time[['device_id', 'app']]\n",
    "# apps = df_app.drop_duplicates().groupby(['device_id'])[\n",
    "#     'app'].agg('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>app</th>\n",
       "      <th>app_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086 90cb852cf345e...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086 37de3dfb9d3bc...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00026d79a6f0955fc860947724e24765</td>\n",
       "      <td>c33b35d6254ad9c0c238233eb97a6c60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002e3afb8146bc08e40575e45f0eca6</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086 07e967d75aab2...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0004709a296f9b925ae283efe2f043e7</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086 07e967d75aab2...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id  \\\n",
       "0  00009270c4ec26e1d76f5d86847009c9   \n",
       "1  000189ef5d5b951841d416a8c6c5b995   \n",
       "2  00026d79a6f0955fc860947724e24765   \n",
       "3  0002e3afb8146bc08e40575e45f0eca6   \n",
       "4  0004709a296f9b925ae283efe2f043e7   \n",
       "\n",
       "                                                 app  app_length  \n",
       "0  1896072db9ce6406febfc17f681c2086 90cb852cf345e...           3  \n",
       "1  1896072db9ce6406febfc17f681c2086 37de3dfb9d3bc...          19  \n",
       "2                   c33b35d6254ad9c0c238233eb97a6c60           1  \n",
       "3  1896072db9ce6406febfc17f681c2086 07e967d75aab2...           3  \n",
       "4  1896072db9ce6406febfc17f681c2086 07e967d75aab2...          14  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将每台设备的 app 数量和分别和训练集、测试集合并\n",
    "deviceid_train = pd.merge(deviceid_train, apps, on='device_id', how='left')\n",
    "deviceid_test = pd.merge(deviceid_test, apps, on='device_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计每个设备在每周几使用时间的的最大值、最小值、和、方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>week_max</th>\n",
       "      <th>week_min</th>\n",
       "      <th>week_sum</th>\n",
       "      <th>week_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>24704.498</td>\n",
       "      <td>138049.645</td>\n",
       "      <td>55275.594</td>\n",
       "      <td>11877.301</td>\n",
       "      <td>27579.032</td>\n",
       "      <td>65830.257</td>\n",
       "      <td>10786.334</td>\n",
       "      <td>138049.645</td>\n",
       "      <td>10786.334</td>\n",
       "      <td>482938.640</td>\n",
       "      <td>144217.018764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>126464.294</td>\n",
       "      <td>231742.053</td>\n",
       "      <td>137188.344</td>\n",
       "      <td>169735.847</td>\n",
       "      <td>206564.846</td>\n",
       "      <td>161872.151</td>\n",
       "      <td>66229.272</td>\n",
       "      <td>231742.053</td>\n",
       "      <td>66229.272</td>\n",
       "      <td>1397768.132</td>\n",
       "      <td>397342.643587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00026d79a6f0955fc860947724e24765</td>\n",
       "      <td>9.203</td>\n",
       "      <td>71.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>588.807</td>\n",
       "      <td>588.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1257.863</td>\n",
       "      <td>427.895521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002e3afb8146bc08e40575e45f0eca6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>435997.167</td>\n",
       "      <td>94.055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>257.875</td>\n",
       "      <td>39759.475</td>\n",
       "      <td>770.285</td>\n",
       "      <td>435997.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>912876.024</td>\n",
       "      <td>313009.429201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0004709a296f9b925ae283efe2f043e7</td>\n",
       "      <td>22878.187</td>\n",
       "      <td>67882.311</td>\n",
       "      <td>38606.127</td>\n",
       "      <td>79848.598</td>\n",
       "      <td>85544.656</td>\n",
       "      <td>79216.949</td>\n",
       "      <td>39049.570</td>\n",
       "      <td>85544.656</td>\n",
       "      <td>22878.187</td>\n",
       "      <td>521449.241</td>\n",
       "      <td>148736.388547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id          w0          w1          w2  \\\n",
       "0  00009270c4ec26e1d76f5d86847009c9   24704.498  138049.645   55275.594   \n",
       "1  000189ef5d5b951841d416a8c6c5b995  126464.294  231742.053  137188.344   \n",
       "2  00026d79a6f0955fc860947724e24765       9.203      71.046       0.000   \n",
       "3  0002e3afb8146bc08e40575e45f0eca6       0.000  435997.167      94.055   \n",
       "4  0004709a296f9b925ae283efe2f043e7   22878.187   67882.311   38606.127   \n",
       "\n",
       "           w3          w4          w5         w6    week_max   week_min  \\\n",
       "0   11877.301   27579.032   65830.257  10786.334  138049.645  10786.334   \n",
       "1  169735.847  206564.846  161872.151  66229.272  231742.053  66229.272   \n",
       "2       0.000       0.000       0.000    588.807     588.807      0.000   \n",
       "3       0.000     257.875   39759.475    770.285  435997.167      0.000   \n",
       "4   79848.598   85544.656   79216.949  39049.570   85544.656  22878.187   \n",
       "\n",
       "      week_sum       week_std  \n",
       "0   482938.640  144217.018764  \n",
       "1  1397768.132  397342.643587  \n",
       "2     1257.863     427.895521  \n",
       "3   912876.024  313009.429201  \n",
       "4   521449.241  148736.388547  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计每个设备在每周几使用时间的的最大值、最小值、和、方差\n",
    "weektime['week_max'] = weektime.max(axis=1)\n",
    "weektime['week_min'] = weektime.min(axis=1)\n",
    "weektime['week_sum'] = weektime.sum(axis=1)\n",
    "weektime['week_std'] = weektime.std(axis=1)\n",
    "weektime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将用户行为数据和训练集、测试集合并\n",
    "del user['app']\n",
    "deviceid_train = pd.merge(deviceid_train, user, on='device_id', how='left')\n",
    "deviceid_test = pd.merge(deviceid_test, user, on='device_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将每个设备在前 100 个 APP的使用时间的表和训练集、测试集合并\n",
    "top100_statis.columns = ['device_id'] + ['top100_statis_' + str(i) for i in range(0, 100)]\n",
    "deviceid_train = pd.merge(deviceid_train, top100_statis, on='device_id', how='left')\n",
    "deviceid_test = pd.merge(deviceid_test, top100_statis, on='device_id', how='left')\n",
    "# 把处理后的训练集、测试集保存到 csv 中\n",
    "deviceid_train.to_csv(\"./Demo/train_statistic_feat.csv\", index=False)\n",
    "deviceid_test.to_csv(\"./Demo/test_statistic_feat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个设备安装的 APP，使用空格分割\n",
    "def get_str(df):\n",
    "    res=\"\"\n",
    "    for i in df.split(','):\n",
    "        res+=i+\" \"\n",
    "    return res\n",
    "deviceid_packages[\"str_app\"]=deviceid_packages['apps'].apply(lambda x:get_str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个 APP 的 tf-idf\n",
    "tfidf = TfidfVectorizer()\n",
    "train_str_app=pd.merge(deviceid_train[['device_id']],deviceid_packages[[\"device_id\",'str_app']],on=\"device_id\",how=\"left\")\n",
    "test_str_app=pd.merge(deviceid_test[['device_id']],deviceid_packages[[\"device_id\",'str_app']],on=\"device_id\",how=\"left\")\n",
    "cntTf=tfidf.fit_transform(deviceid_packages['str_app'])\n",
    "# 将训练集和测试集的 app 列表转换为 tf-idf。使用 .tocsr() 转换为稀疏矩阵，节省内存。\n",
    "train_app = tfidf.transform(list(train_str_app['str_app'])).tocsr()\n",
    "test_app = tfidf.transform(list(test_str_app['str_app'])).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出训练集和测试集的设备 id\n",
    "all_id=pd.concat([deviceid_train[[\"device_id\"]],deviceid_test[['device_id']]])\n",
    "all_id.index=range(len(all_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 app 的tfidf 来预测性别，分别使用 7 种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr stacking\n",
      "stack:1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分0.3444655534446555\n",
      "stack:2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分0.3478\n",
      "stack:3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分0.3481\n",
      "stack:4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分0.352\n",
      "stack:5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分0.3714371437143714\n",
      "SGDClassifier stacking\n",
      "stack:1/5\n",
      "得分0.33486651334866513\n",
      "stack:2/5\n",
      "得分0.3361\n",
      "stack:3/5\n",
      "得分0.3379\n",
      "stack:4/5\n",
      "得分0.3369\n",
      "stack:5/5\n",
      "得分0.35313531353135313\n",
      "PassiveAggressiveClassifier stacking\n",
      "stack:1/5\n",
      "[0.22603554 0.40080821 0.68611114 ... 0.22700054 0.92438757 0.11568248]\n",
      "得分0.37716228377162286\n",
      "stack:2/5\n",
      "[0.23937409 0.29277283 0.65401563 ... 0.45811155 0.69891796 0.09252268]\n",
      "得分0.41\n",
      "stack:3/5\n",
      "[0.19112784 0.58984072 0.65485523 ... 0.65510191 0.56784305 0.19348972]\n",
      "得分0.3908\n",
      "stack:4/5\n",
      "[0.33016848 0.32924396 0.13881066 ... 0.4053131  0.39158015 0.7748465 ]\n",
      "得分0.4025\n",
      "stack:5/5\n",
      "[0.03220108 0.84593773 0.88390923 ... 0.73196673 0.43003357 0.34898293]\n",
      "得分0.4172417241724172\n",
      "RidgeClassfiy stacking\n",
      "stack:1/5\n",
      "[0.54860796 0.40482193 0.47736859 ... 0.42737929 0.66225863 0.37288188]\n",
      "得分0.3374662533746625\n",
      "stack:2/5\n",
      "[0.37303388 0.38652208 0.53700431 ... 0.45571546 0.46636579 0.26696679]\n",
      "得分0.3422\n",
      "stack:3/5\n",
      "[0.42362116 0.48107678 0.40384204 ... 0.49729276 0.47427299 0.35256109]\n",
      "得分0.3469\n",
      "stack:4/5\n",
      "[0.386541   0.29004235 0.30222274 ... 0.46175029 0.34697989 0.6133661 ]\n",
      "得分0.3484\n",
      "stack:5/5\n",
      "[0.33809071 0.54076546 0.49152344 ... 0.59639641 0.43723505 0.41625188]\n",
      "得分0.36663666366636666\n",
      "BernoulliNB stacking\n",
      "stack:1/5\n",
      "[0.68678544 0.11310023 0.17405429 ... 0.10491726 0.99896417 0.00388883]\n",
      "得分0.34526547345265474\n",
      "stack:2/5\n",
      "[0.08620693 0.14775586 0.48707798 ... 0.12103721 0.16728694 0.01480953]\n",
      "得分0.3411\n",
      "stack:3/5\n",
      "[0.34796802 0.16678098 0.12539807 ... 0.9990923  0.99990338 0.10724536]\n",
      "得分0.3495\n",
      "stack:4/5\n",
      "[0.11879831 0.03110432 0.00410452 ... 0.99727084 0.02604782 0.9662213 ]\n",
      "得分0.3532\n",
      "stack:5/5\n",
      "[0.01280943 0.81168202 0.27090632 ... 0.18765636 0.16419783 0.1692828 ]\n",
      "得分0.3684368436843684\n",
      "MultinomialNB stacking\n",
      "stack:1/5\n",
      "[0.33372164 0.31043587 0.22904111 ... 0.22774826 0.62804444 0.11290587]\n",
      "得分0.35066493350664935\n",
      "stack:2/5\n",
      "[0.21504353 0.27164469 0.25324546 ... 0.26878815 0.28610803 0.12557815]\n",
      "得分0.3485\n",
      "stack:3/5\n",
      "[0.24945089 0.32754455 0.22790624 ... 0.63128194 0.5831381  0.21488049]\n",
      "得分0.3496\n",
      "stack:4/5\n",
      "[0.20055729 0.12694247 0.08498769 ... 0.52822329 0.2195117  0.40791497]\n",
      "得分0.3545\n",
      "stack:5/5\n",
      "[0.12780091 0.4146773  0.25318243 ... 0.3965373  0.33728684 0.21938504]\n",
      "得分0.35903590359035903\n",
      "LinearSVC stacking\n",
      "stack:1/5\n",
      "[0.54891641 0.40735885 0.48467928 ... 0.42953085 0.66986724 0.36107334]\n",
      "得分0.3464653534646535\n",
      "stack:2/5\n",
      "[0.37361615 0.37908615 0.54385051 ... 0.45591549 0.46869675 0.260203  ]\n",
      "得分0.3495\n",
      "stack:3/5\n",
      "[0.42832626 0.48003183 0.40934444 ... 0.51987169 0.48628184 0.35054812]\n",
      "得分0.3517\n",
      "stack:4/5\n",
      "[0.38568885 0.28985552 0.29952874 ... 0.46083585 0.36050105 0.61764835]\n",
      "得分0.3538\n",
      "stack:5/5\n",
      "[0.30815149 0.56111969 0.52216608 ... 0.59824556 0.4382184  0.41507076]\n",
      "得分0.37173717371737175\n"
     ]
    }
   ],
   "source": [
    "# 使用 app 的tfidf 来预测性别，分别使用 7 种方法\n",
    "df_stack = pd.DataFrame()\n",
    "n_folds = 5\n",
    "# 预测性别，由于原表是从 1 开始，因此-1，变为从 0 开始\n",
    "sex = deviceid_train['sex']-1\n",
    "print('lr stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 1))\n",
    "stack_test = np.zeros((len(deviceid_test), 1))\n",
    "sex_va = 0\n",
    "kv=StratifiedKFold(n_splits=n_folds, random_state=1017)\n",
    "# LogisticRegression\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,sex)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    clf = LogisticRegression(random_state=1017, C=8)\n",
    "    clf.fit(train_app[tr], sex[tr])\n",
    "    # 由于标签为 0 和 1，因此取第一列作为标签\n",
    "    sex_va = clf.predict_proba(train_app[va])[:,1]\n",
    "    sex_te=clf.predict_proba(test_app)[:,1]\n",
    "    print('得分' + str(mean_squared_error(sex[va], clf.predict(train_app[va]))))\n",
    "    stack_train[va,0]=sex_va\n",
    "    stack_test[:,0]+=sex_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "df_stack['pack_tfidf_lr_classfiy_{}'.format(sex)] = stack[:, 0]\n",
    "\n",
    "print('SGDClassifier stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 1))\n",
    "stack_test = np.zeros((len(deviceid_test), 1))\n",
    "# SGDClassifier\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,sex)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    sgd = SGDClassifier(random_state=1017, loss='log')\n",
    "    sgd.fit(train_app[tr], sex[tr])\n",
    "    sex_va = sgd.predict_proba(train_app[va])[:,1]\n",
    "    sex_te = sgd.predict_proba(test_app)[:,1]\n",
    "    print('得分' + str(mean_squared_error(sex[va], sgd.predict(train_app[va]))))\n",
    "    stack_train[va,0] = sex_va\n",
    "    stack_test[:,0]+= sex_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "df_stack['tfidf_sgd_classfiy_{}'.format(sex)] = stack[:, 0]\n",
    "\n",
    "\n",
    "print('PassiveAggressiveClassifier stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 1))\n",
    "stack_test = np.zeros((len(deviceid_test), 1))\n",
    "# PassiveAggressiveClassifier\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,sex)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    pac = PassiveAggressiveClassifier(random_state=1017)\n",
    "    pac.fit(train_app[tr], sex[tr])\n",
    "    sex_va = pac._predict_proba_lr(train_app[va])[:,1]\n",
    "    sex_te = pac._predict_proba_lr(test_app)[:,1]\n",
    "    print(sex_va)\n",
    "    print('得分' + str(mean_squared_error(sex[va], pac.predict(train_app[va]))))\n",
    "    stack_train[va,0] += sex_va\n",
    "    stack_test[:,0] += sex_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "df_stack['tfidf_pac_classfiy_{}'.format(sex)] = stack[:, 0]\n",
    "\n",
    "\n",
    "# RidgeClassifier\n",
    "print('RidgeClassfiy stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 1))\n",
    "stack_test = np.zeros((len(deviceid_test), 1))\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,sex)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    ridge = RidgeClassifier(random_state=1017)\n",
    "    ridge.fit(train_app[tr], sex[tr])\n",
    "    sex_va = ridge._predict_proba_lr(train_app[va])[:,1]\n",
    "    sex_te = ridge._predict_proba_lr(test_app)[:,1]\n",
    "    print(sex_va)\n",
    "    print('得分' + str(mean_squared_error(sex[va], ridge.predict(train_app[va]))))\n",
    "    stack_train[va,0] += sex_va\n",
    "    stack_test[:,0] += sex_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "df_stack['tfidf_ridge_classfiy_{}'.format(sex)] = stack[:, 0]\n",
    "    \n",
    "    \n",
    "# BernoulliNB\n",
    "print('BernoulliNB stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 1))\n",
    "stack_test = np.zeros((len(deviceid_test), 1))\n",
    "\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,sex)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(train_app[tr], sex[tr])\n",
    "    sex_va = bnb.predict_proba(train_app[va])[:,1]\n",
    "    sex_te = bnb.predict_proba(test_app)[:,1]\n",
    "    print(sex_va)\n",
    "    print('得分' + str(mean_squared_error(sex[va], bnb.predict(train_app[va]))))\n",
    "    stack_train[va,0] += sex_va\n",
    "    stack_test[:,0] += sex_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "df_stack['tfidf_bnb_classfiy_{}'.format(sex)] = stack[:, 0]    \n",
    "    \n",
    "    \n",
    "# MultinomialNB\n",
    "print('MultinomialNB stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 1))\n",
    "stack_test = np.zeros((len(deviceid_test), 1))\n",
    "\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,sex)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(train_app[tr], sex[tr])\n",
    "    \n",
    "    sex_va = mnb.predict_proba(train_app[va])[:,1]\n",
    "    sex_te = mnb.predict_proba(test_app)[:,1]\n",
    "    print(sex_va)\n",
    "    print('得分' + str(mean_squared_error(sex[va], mnb.predict(train_app[va]))))\n",
    "    stack_train[va,0] += sex_va\n",
    "    stack_test[:,0] += sex_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "df_stack['tfidf_mnb_classfiy_{}'.format(sex)] = stack[:, 0]    \n",
    "    \n",
    "  \n",
    "# LinearSVC\n",
    "print('LinearSVC stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 1))\n",
    "stack_test = np.zeros((len(deviceid_test), 1))\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,sex)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    lsvc = LinearSVC(random_state=1017)\n",
    "    lsvc.fit(train_app[tr], sex[tr])\n",
    "    sex_va = lsvc._predict_proba_lr(train_app[va])[:,1]\n",
    "    sex_te = lsvc._predict_proba_lr(test_app)[:,1]\n",
    "    print(sex_va)\n",
    "    print('得分' + str(mean_squared_error(sex[va], lsvc.predict(train_app[va]))))\n",
    "    stack_train[va,0] += sex_va\n",
    "    stack_test[:,0] += sex_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "df_stack['tfidf_lsvc_classfiy_{}'.format(sex)] = stack[:, 0]    \n",
    "# 添加设备 id 列\n",
    "df_stack['device_id']=all_id\n",
    "# 保存到 csv 文件中\n",
    "df_stack.to_csv('./Demo/tfidf_classfiy.csv', index=None, encoding='utf8')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feat=pd.read_csv(\"./Demo/tfidf_classfiy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将性别预测结果和训练集、测试集合并\n",
    "train_data = pd.merge(deviceid_train,tfidf_feat,on=\"device_id\",how=\"left\")\n",
    "test_data = pd.merge(deviceid_test,tfidf_feat,on=\"device_id\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再次构造性别预测训练集\n",
    "features = [x for x in train_data.columns if x not in ['device_id', 'sex',\"age\",\"label\",\"app\"]]\n",
    "X=train_data[features]\n",
    "Y = train_data['sex'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 xgb 预测最终的性别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.691722\tval-logloss:0.691713\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.593042\tval-logloss:0.611817\n",
      "[400]\ttrain-logloss:0.574775\tval-logloss:0.612024\n",
      "Stopping. Best iteration:\n",
      "[305]\ttrain-logloss:0.582035\tval-logloss:0.611137\n",
      "\n",
      "idx:  0\n",
      " loss: 0.61199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.691727\tval-logloss:0.691861\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.595386\tval-logloss:0.614948\n",
      "Stopping. Best iteration:\n",
      "[208]\ttrain-logloss:0.594388\tval-logloss:0.614589\n",
      "\n",
      "idx:  1\n",
      " loss: 0.61950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.691712\tval-logloss:0.692172\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.594102\tval-logloss:0.642882\n",
      "Stopping. Best iteration:\n",
      "[113]\ttrain-logloss:0.610846\tval-logloss:0.637773\n",
      "\n",
      "idx:  2\n",
      " loss: 0.64459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.691712\tval-logloss:0.691948\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.59368\tval-logloss:0.627033\n",
      "Stopping. Best iteration:\n",
      "[185]\ttrain-logloss:0.595625\tval-logloss:0.626687\n",
      "\n",
      "idx:  3\n",
      " loss: 0.63063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.691656\tval-logloss:0.691937\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-logloss:0.59061\tval-logloss:0.623712\n",
      "Stopping. Best iteration:\n",
      "[288]\ttrain-logloss:0.580737\tval-logloss:0.622391\n",
      "\n",
      "idx:  4\n",
      " loss: 0.62349\n",
      "mean\n",
      "auc:       0.626039586467934\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, log_loss, roc_auc_score,f1_score,recall_score,precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold( n_splits=5, shuffle=True, random_state=1024)\n",
    "\n",
    "params={\n",
    "\t'booster':'gbtree',\n",
    "    \n",
    "\t'objective': 'binary:logistic',\n",
    "#      'is_unbalance':'True',\n",
    "# \t'scale_pos_weight': 1500.0/13458.0,\n",
    "        'eval_metric': \"logloss\",\n",
    "    \n",
    "\t'gamma':0.2,#0.2 is ok\n",
    "\t'max_depth':6,\n",
    "# \t'lambda':20,\n",
    "    # \"alpha\":5,\n",
    "        'subsample':0.7,\n",
    "        'colsample_bytree':0.4 ,\n",
    "#         'min_child_weight':2.5, \n",
    "        'eta': 0.01,\n",
    "    # 'learning_rate':0.01,\n",
    "    \"silent\":1,\n",
    "\t'seed':1024,\n",
    "\t'nthread':12,\n",
    "   \n",
    "    }\n",
    "num_round = 3500\n",
    "early_stopping_rounds = 100\n",
    "\n",
    "auc = []\n",
    "\n",
    "test_sex = np.zeros((len(deviceid_test), ))\n",
    "pred_sex=np.zeros((len(deviceid_train),))\n",
    "for i, (train_index,valid_index) in enumerate(kv.split(X,Y)):\n",
    "    tr_x = X.loc[train_index,:]\n",
    "    tr_y = Y[train_index]\n",
    "    valid_x = X.loc[valid_index,:]\n",
    "    valid_y = Y[valid_index]    \n",
    "    d_tr = xgb.DMatrix(tr_x, label=tr_y)\n",
    "    d_valid = xgb.DMatrix(valid_x, label=valid_y)\n",
    "    watchlist  = [(d_tr,'train'),(d_valid,'val')]\n",
    "    model = xgb.train(params, d_tr, num_boost_round=5500, \n",
    "                      evals=watchlist,verbose_eval=200,\n",
    "                              early_stopping_rounds=100)\n",
    "    valid_pred = model.predict(d_valid)\n",
    "    pred_sex[valid_index] =valid_pred                  \n",
    "    a = log_loss(valid_y, valid_pred)    \n",
    "    test_sex += model.predict(xgb.DMatrix(test_data[features]))/5\n",
    "    print (\"idx: \", i) \n",
    "    print (\" loss: %.5f\" % a)\n",
    "#     print \" gini: %.5f\" % g\n",
    "    auc.append(a)  \n",
    "print (\"mean\")\n",
    "print (\"auc:       %s\" % (sum(auc) / 5.0))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "761"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并训练集、测试集的性别预测结果\n",
    "train_sex = pd.DataFrame(pred_sex, columns=['sex2'])\n",
    "test_sex = pd.DataFrame(test_sex, columns=['sex2'])\n",
    "sex=pd.concat([train_sex,test_sex])\n",
    "sex['sex1'] = 1-sex['sex2']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 APP 的 tf-idf 预测年龄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr stacking\n",
      "stack:1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分7.486756621689155\n",
      "stack:2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分6.891032690192942\n",
      "stack:3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分7.5114\n",
      "stack:4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分7.301890567170151\n",
      "stack:5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分7.4786393196598295\n",
      "sgd stacking\n",
      "stack:1/5\n",
      "得分7.051974012993504\n",
      "stack:2/5\n",
      "得分6.294111766470059\n",
      "stack:3/5\n",
      "得分6.955\n",
      "stack:4/5\n",
      "得分6.659497849354806\n",
      "stack:5/5\n",
      "得分6.811905952976488\n",
      "PAC stacking\n",
      "stack:1/5\n",
      "[[0.07713337 0.06078497 0.16951103 ... 0.06231956 0.05098182 0.02156769]\n",
      " [0.04089013 0.03665824 0.04973171 ... 0.09544697 0.10504735 0.11336235]\n",
      " [0.04144628 0.0696375  0.07760912 ... 0.05934811 0.0120289  0.16582504]\n",
      " ...\n",
      " [0.07056763 0.01070354 0.0260266  ... 0.02990727 0.02982439 0.10643443]\n",
      " [0.13860084 0.28810021 0.09920855 ... 0.07184668 0.03201097 0.0181112 ]\n",
      " [0.08296375 0.1447091  0.02837199 ... 0.12883953 0.03925138 0.04625413]]\n",
      "得分8.996901549225388\n",
      "stack:2/5\n",
      "[[0.02417947 0.08456413 0.12493812 ... 0.0769574  0.06493059 0.1111957 ]\n",
      " [0.03053238 0.01633659 0.07832188 ... 0.02743429 0.11494769 0.09164805]\n",
      " [0.04752178 0.03683984 0.08151302 ... 0.10648105 0.07438747 0.08463277]\n",
      " ...\n",
      " [0.15426714 0.13663693 0.01552546 ... 0.03922786 0.04246156 0.04572334]\n",
      " [0.04546912 0.01719822 0.11075522 ... 0.16913317 0.09729489 0.0137751 ]\n",
      " [0.04432878 0.0677354  0.04635393 ... 0.07028761 0.06624644 0.07369707]]\n",
      "得分8.038788363490953\n",
      "stack:3/5\n",
      "[[0.05132128 0.03879854 0.16970029 ... 0.08275035 0.04725132 0.0268429 ]\n",
      " [0.04448644 0.1185509  0.12452919 ... 0.03357726 0.06882333 0.10773775]\n",
      " [0.06849264 0.02554326 0.05004291 ... 0.04005808 0.01137697 0.06121321]\n",
      " ...\n",
      " [0.06135131 0.17466262 0.22901291 ... 0.04649921 0.02544207 0.03700819]\n",
      " [0.07015157 0.07694396 0.04344227 ... 0.01606278 0.0110478  0.04825176]\n",
      " [0.04444586 0.05946151 0.07928614 ... 0.04036999 0.15631452 0.19642112]]\n",
      "得分8.8031\n",
      "stack:4/5\n",
      "[[0.04106357 0.0384534  0.08997031 ... 0.12567123 0.09018474 0.09769481]\n",
      " [0.02815904 0.02066654 0.0452152  ... 0.14002268 0.07380813 0.14937398]\n",
      " [0.02489694 0.1567483  0.25469432 ... 0.07159437 0.02296237 0.02769319]\n",
      " ...\n",
      " [0.0940088  0.09546682 0.04861072 ... 0.11184843 0.02548756 0.09226219]\n",
      " [0.08944365 0.08601766 0.02702397 ... 0.01232766 0.03436028 0.05431888]\n",
      " [0.06784656 0.10046198 0.14542915 ... 0.07572745 0.02669547 0.10179746]]\n",
      "得分8.64329298789637\n",
      "stack:5/5\n",
      "[[0.05726763 0.10210588 0.11578618 ... 0.10526077 0.04660764 0.03742783]\n",
      " [0.01364232 0.05076584 0.09318921 ... 0.10270491 0.16499153 0.04394201]\n",
      " [0.01818702 0.10528168 0.3664502  ... 0.13261215 0.02959355 0.00814051]\n",
      " ...\n",
      " [0.04115444 0.06863059 0.08685746 ... 0.07245461 0.08951241 0.05404742]\n",
      " [0.10962147 0.09437879 0.07872375 ... 0.06518901 0.02545653 0.01516047]\n",
      " [0.03206583 0.04278993 0.0321376  ... 0.11561858 0.03495225 0.03920901]]\n",
      "得分8.414107053526763\n",
      "RidgeClassfiy stacking\n",
      "stack:1/5\n",
      "[[0.07912959 0.08078737 0.09937469 ... 0.10682574 0.07900937 0.07039693]\n",
      " [0.07981198 0.0827782  0.09025542 ... 0.09629844 0.08728368 0.08391368]\n",
      " [0.07751715 0.09145424 0.08832121 ... 0.08639503 0.07645026 0.10116684]\n",
      " ...\n",
      " [0.07822922 0.07120966 0.08317638 ... 0.07919892 0.07430447 0.08429   ]\n",
      " [0.08069982 0.11891556 0.10030216 ... 0.08921977 0.07589509 0.07669968]\n",
      " [0.08238541 0.09293571 0.09155856 ... 0.08197499 0.07745261 0.08306044]]\n",
      "得分7.7702148925537236\n",
      "stack:2/5\n",
      "[[0.08069138 0.0855902  0.09788997 ... 0.09357806 0.08234507 0.09903813]\n",
      " [0.08052802 0.07770727 0.07996957 ... 0.08375553 0.09868694 0.09559246]\n",
      " [0.08016643 0.08119175 0.0818354  ... 0.09679657 0.08919566 0.09567912]\n",
      " ...\n",
      " [0.08858909 0.11051326 0.08992211 ... 0.0790873  0.08018527 0.08385274]\n",
      " [0.07854094 0.07612444 0.10768268 ... 0.09673819 0.08001611 0.07750695]\n",
      " [0.07833886 0.08575919 0.09031733 ... 0.0796314  0.08098684 0.0826379 ]]\n",
      "得分7.161951414575627\n",
      "stack:3/5\n",
      "[[0.07977735 0.08965584 0.1008403  ... 0.08781145 0.07871196 0.07653645]\n",
      " [0.07873791 0.09751433 0.09728825 ... 0.08050312 0.08197243 0.09223931]\n",
      " [0.08055957 0.08119567 0.09262723 ... 0.07711382 0.07416643 0.08953868]\n",
      " ...\n",
      " [0.07899407 0.10779356 0.10561996 ... 0.08620895 0.07455929 0.07894129]\n",
      " [0.08026532 0.09464307 0.08959696 ... 0.07351201 0.07224532 0.07487558]\n",
      " [0.07932043 0.0879865  0.09402686 ... 0.07967928 0.09666483 0.11946135]]\n",
      "得分7.8498\n",
      "stack:4/5\n",
      "[[0.08007774 0.07988542 0.08402439 ... 0.0969475  0.09588186 0.10518172]\n",
      " [0.07958857 0.07930238 0.08122061 ... 0.10032608 0.09731975 0.11357591]\n",
      " [0.07823784 0.10052821 0.11938359 ... 0.08092743 0.07544688 0.07840808]\n",
      " ...\n",
      " [0.083571   0.09279938 0.08285803 ... 0.08200213 0.08461298 0.08040358]\n",
      " [0.08098978 0.10000018 0.07422916 ... 0.07397478 0.08143816 0.08156815]\n",
      " [0.08310564 0.09952912 0.09889498 ... 0.08355489 0.08062118 0.085082  ]]\n",
      "得分7.4752425727718315\n",
      "stack:5/5\n",
      "[[0.07928364 0.0934809  0.08317921 ... 0.09035651 0.08449771 0.08500865]\n",
      " [0.07913002 0.0822873  0.11094479 ... 0.08412002 0.09708912 0.07685232]\n",
      " [0.07701434 0.09831702 0.14801095 ... 0.09256693 0.08195387 0.07538567]\n",
      " ...\n",
      " [0.08099981 0.09339875 0.09370626 ... 0.08302045 0.08387297 0.08186339]\n",
      " [0.08204485 0.09070548 0.0953229  ... 0.08121699 0.07527955 0.07623717]\n",
      " [0.07743934 0.09595436 0.07558029 ... 0.08437206 0.08647593 0.08200881]]\n",
      "得分7.754177088544272\n",
      "BernoulliNB stacking\n",
      "stack:1/5\n",
      "[[1.07062593e-61 4.21335707e-08 3.89196937e-03 ... 6.66525839e-04\n",
      "  8.00610368e-08 1.67335340e-05]\n",
      " [5.49323483e-63 5.84226691e-11 3.79944122e-05 ... 2.77440136e-02\n",
      "  8.46836968e-05 1.16195671e-02]\n",
      " [4.76190793e-64 7.85688997e-10 3.78921447e-04 ... 5.42835407e-04\n",
      "  2.10638883e-07 3.30032235e-03]\n",
      " ...\n",
      " [3.23215693e-50 8.43415474e-09 9.05807762e-07 ... 8.01503204e-08\n",
      "  6.62794343e-10 3.20485918e-07]\n",
      " [2.97949930e-57 4.76291297e-06 3.66939531e-03 ... 7.48214785e-05\n",
      "  5.46086963e-08 3.37807260e-05]\n",
      " [5.47316454e-61 4.04205981e-09 2.03771885e-05 ... 3.43976728e-05\n",
      "  1.04726110e-08 7.00332199e-05]]\n",
      "得分6.380409795102449\n",
      "stack:2/5\n",
      "[[2.98227509e-61 9.84714138e-09 1.14099006e-02 ... 1.17717224e-03\n",
      "  1.27783079e-06 7.06872784e-04]\n",
      " [5.50012329e-65 3.64212179e-11 4.04215025e-05 ... 1.27068314e-02\n",
      "  1.45683449e-04 3.98279674e-02]\n",
      " [7.04852177e-64 4.76377557e-12 7.55411891e-06 ... 1.49180884e-01\n",
      "  5.86863582e-04 1.29891849e-01]\n",
      " ...\n",
      " [1.24498243e-58 1.12426254e-06 3.10036786e-04 ... 4.16826860e-07\n",
      "  1.16668423e-09 2.08981348e-06]\n",
      " [2.82632677e-61 1.04812978e-09 8.55287395e-05 ... 8.06411001e-04\n",
      "  7.30316501e-07 8.51387602e-04]\n",
      " [5.23529677e-61 8.21465989e-10 6.53441485e-06 ... 1.02049596e-04\n",
      "  4.21219015e-07 3.24444531e-04]]\n",
      "得分5.896930920723783\n",
      "stack:3/5\n",
      "[[3.77614649e-57 4.11629267e-07 1.06228420e-02 ... 2.92458257e-04\n",
      "  1.65152149e-07 1.30009572e-06]\n",
      " [5.04850495e-62 2.48577938e-07 3.39995686e-02 ... 1.09933540e-04\n",
      "  1.12483376e-07 1.02060102e-05]\n",
      " [1.57920779e-53 3.25745563e-06 3.61966763e-01 ... 1.98402199e-05\n",
      "  4.66939536e-08 1.97212385e-05]\n",
      " ...\n",
      " [3.86616001e-55 8.36186962e-04 6.38262615e-03 ... 4.87146282e-08\n",
      "  4.16830888e-12 7.13004864e-09]\n",
      " [3.69664828e-60 4.74170504e-09 2.32131939e-05 ... 7.86918423e-06\n",
      "  6.39888211e-09 5.65988074e-06]\n",
      " [6.88612349e-64 2.59524843e-12 2.05133744e-05 ... 1.99150352e-02\n",
      "  1.04760236e-04 1.53859118e-01]]\n",
      "得分6.1254\n",
      "stack:4/5\n",
      "[[2.27290606e-64 4.39956519e-12 5.01949553e-06 ... 3.12592186e-02\n",
      "  1.47056648e-04 1.57254927e-01]\n",
      " [1.64305418e-64 2.93072473e-12 3.28293215e-06 ... 3.38514283e-02\n",
      "  1.57927373e-04 1.83119894e-01]\n",
      " [1.66491405e-59 3.31837148e-05 6.89823485e-01 ... 1.30273175e-07\n",
      "  1.13735229e-11 4.54184709e-09]\n",
      " ...\n",
      " [1.15141694e-56 2.39912633e-07 1.09756717e-05 ... 2.43163060e-08\n",
      "  2.21786793e-12 1.71998331e-08]\n",
      " [6.48910670e-56 1.11121027e-07 2.69636219e-07 ... 1.95370393e-10\n",
      "  2.68393426e-12 5.81860829e-09]\n",
      " [7.76071748e-63 7.93192214e-11 1.08900615e-05 ... 5.77355423e-03\n",
      "  9.27311779e-06 1.82721039e-02]]\n",
      "得分6.084225267580274\n",
      "stack:5/5\n",
      "[[2.18036061e-62 2.97085882e-10 7.04575410e-06 ... 7.76014094e-04\n",
      "  1.12020555e-06 1.06331994e-03]\n",
      " [7.20431458e-65 4.84311161e-10 9.84178820e-03 ... 7.04709214e-05\n",
      "  1.56954150e-08 1.55454212e-06]\n",
      " [7.21884761e-62 2.05393468e-08 2.81239691e-02 ... 2.26987036e-03\n",
      "  2.33153557e-06 8.80625026e-04]\n",
      " ...\n",
      " [4.26190011e-63 7.44565985e-11 1.51780554e-05 ... 8.60371730e-03\n",
      "  2.35862505e-05 1.88785925e-02]\n",
      " [1.31911769e-62 7.10746360e-11 9.03691628e-06 ... 5.54889489e-03\n",
      "  1.38155843e-05 1.25154221e-02]\n",
      " [4.38555747e-61 1.67799511e-09 5.44197878e-06 ... 1.09452133e-04\n",
      "  1.39179881e-07 1.35171119e-04]]\n",
      "得分5.926763381690845\n",
      "MultinomialNB stacking\n",
      "stack:1/5\n",
      "[[5.74493274e-06 4.61463282e-03 4.09327732e-02 ... 4.27409291e-02\n",
      "  3.87341973e-03 1.16232011e-02]\n",
      " [2.53595829e-04 1.07822958e-02 5.34924029e-02 ... 8.73620856e-02\n",
      "  3.29682580e-02 5.87040014e-02]\n",
      " [6.96445577e-06 3.22876741e-03 3.25182966e-02 ... 3.28045196e-02\n",
      "  5.54554859e-03 5.51932016e-02]\n",
      " ...\n",
      " [1.97971620e-04 5.02170059e-03 1.58007135e-02 ... 2.11582028e-02\n",
      "  6.30008029e-03 3.24535791e-02]\n",
      " [4.57333942e-04 6.29045033e-02 1.17879701e-01 ... 2.86586345e-02\n",
      "  6.54830454e-03 2.07064332e-02]\n",
      " [7.26318782e-05 1.49406346e-02 2.40394722e-02 ... 9.52649656e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.56903709e-04 1.18486389e-02]]\n",
      "得分6.410794602698651\n",
      "stack:2/5\n",
      "[[1.57491980e-06 1.41652236e-03 2.51789002e-02 ... 3.53685460e-02\n",
      "  5.23901685e-03 3.78292472e-02]\n",
      " [3.92615955e-06 1.79113239e-03 2.11122499e-02 ... 4.71180132e-02\n",
      "  2.44356017e-02 8.69246436e-02]\n",
      " [3.48729320e-05 2.58794514e-03 2.10664459e-02 ... 1.05757091e-01\n",
      "  3.70895168e-02 9.02131628e-02]\n",
      " ...\n",
      " [1.14783466e-04 2.89874496e-02 4.21409881e-02 ... 6.07219929e-03\n",
      "  1.70108136e-03 9.42463189e-03]\n",
      " [3.20148514e-04 1.99691425e-02 8.48070322e-02 ... 4.12726780e-02\n",
      "  9.46464780e-03 3.16609227e-02]\n",
      " [2.98180013e-04 1.22697543e-02 2.30495765e-02 ... 2.11435430e-02\n",
      "  8.90848031e-03 3.39600898e-02]]\n",
      "得分6.145256423073078\n",
      "stack:3/5\n",
      "[[3.43480584e-05 7.26233731e-03 4.99491236e-02 ... 4.28083983e-02\n",
      "  7.83186441e-03 2.14004797e-02]\n",
      " [4.18121523e-06 4.43896859e-03 4.93356287e-02 ... 3.23462077e-02\n",
      "  6.38398827e-03 3.09554526e-02]\n",
      " [7.02596959e-04 2.08965378e-02 1.04334994e-01 ... 3.34353936e-02\n",
      "  1.13390526e-02 4.31474939e-02]\n",
      " ...\n",
      " [2.47501821e-05 2.14988309e-02 4.34829155e-02 ... 6.85783926e-03\n",
      "  8.54311073e-04 7.06428650e-03]\n",
      " [7.55449925e-05 1.05407060e-02 2.95591329e-02 ... 1.38099853e-02\n",
      "  2.88703420e-03 1.18321805e-02]\n",
      " [1.83384080e-05 1.95275597e-03 2.74620138e-02 ... 5.74240082e-02\n",
      "  2.11844377e-02 9.29893596e-02]]\n",
      "得分6.3948\n",
      "stack:4/5\n",
      "[[3.70066237e-05 2.21242161e-03 2.25688980e-02 ... 9.54288810e-02\n",
      "  4.08096189e-02 1.42821366e-01]\n",
      " [4.76004266e-05 1.59458068e-03 1.80376474e-02 ... 1.18275392e-01\n",
      "  5.80326966e-02 1.99483224e-01]\n",
      " [7.33944749e-06 1.34908649e-02 1.51132651e-01 ... 1.22384312e-02\n",
      "  1.27192777e-03 6.59138683e-03]\n",
      " ...\n",
      " [2.26701847e-05 7.82574244e-03 1.74749345e-02 ... 4.52674710e-03\n",
      "  5.27466669e-04 4.70706372e-03]\n",
      " [5.39264745e-05 9.64612212e-03 1.23886463e-02 ... 2.89409015e-03\n",
      "  1.12936043e-03 7.02811355e-03]\n",
      " [1.76901204e-03 5.28234110e-02 9.40236083e-02 ... 3.62628121e-02\n",
      "  9.39179031e-03 4.11382175e-02]]\n",
      "得分6.26778033410023\n",
      "stack:5/5\n",
      "[[1.60988938e-05 6.25041862e-03 1.86316697e-02 ... 3.03322026e-02\n",
      "  5.30573546e-03 2.40189316e-02]\n",
      " [2.71030169e-06 2.61883874e-03 7.03855998e-02 ... 2.84504496e-02\n",
      "  4.80517758e-03 1.79303077e-02]\n",
      " [1.10530464e-04 2.56897148e-02 2.32860203e-01 ... 3.21829831e-02\n",
      "  8.43843784e-03 2.63536647e-02]\n",
      " ...\n",
      " [6.14698261e-04 3.10188770e-02 8.76031774e-02 ... 4.91865052e-02\n",
      "  1.92724317e-02 4.05884806e-02]\n",
      " [8.72562304e-04 2.36057993e-02 5.96367427e-02 ... 4.76937754e-02\n",
      "  1.65534071e-02 4.42790313e-02]\n",
      " [8.04869344e-05 1.17497249e-02 1.78483081e-02 ... 1.68055101e-02\n",
      "  5.80874974e-03 2.57010337e-02]]\n",
      "得分6.287443721860931\n",
      "LinerSVC stacking\n",
      "stack:1/5\n",
      "[[0.07485798 0.0718178  0.10452422 ... 0.113412   0.07310539 0.05942657]\n",
      " [0.06711943 0.07601658 0.09184419 ... 0.0994438  0.08941727 0.08292825]\n",
      " [0.05965574 0.09258378 0.09128843 ... 0.08762667 0.06267409 0.10853221]\n",
      " ...\n",
      " [0.07621905 0.05482931 0.07507567 ... 0.07132437 0.07129518 0.08422896]\n",
      " [0.08549798 0.13397435 0.10579854 ... 0.08339964 0.0698967  0.06913057]\n",
      " [0.08636487 0.10095741 0.08270153 ... 0.08460842 0.06988473 0.08370069]]\n",
      "得分8.014992503748125\n",
      "stack:2/5\n",
      "[[0.06658878 0.08401396 0.09860757 ... 0.09653551 0.08091515 0.10262164]\n",
      " [0.06864282 0.07098796 0.07819201 ... 0.07586861 0.10421218 0.09715092]\n",
      " [0.07133255 0.0776048  0.08060305 ... 0.09917196 0.08925546 0.09258821]\n",
      " ...\n",
      " [0.10360218 0.11865489 0.07644248 ... 0.08098061 0.07956386 0.08488361]\n",
      " [0.06798372 0.07134985 0.11332429 ... 0.10425253 0.0808778  0.07313899]\n",
      " [0.07484922 0.08611125 0.0877274  ... 0.07992241 0.08094458 0.08058992]]\n",
      "得分7.458962311306608\n",
      "stack:3/5\n",
      "[[0.07412495 0.08802297 0.10499993 ... 0.0905132  0.07372429 0.06894817]\n",
      " [0.06468841 0.10295174 0.10336145 ... 0.07484823 0.07787308 0.09178747]\n",
      " [0.07660644 0.07304803 0.08984399 ... 0.0726746  0.0625414  0.09073187]\n",
      " ...\n",
      " [0.07194757 0.11967865 0.11455625 ... 0.08513471 0.06348611 0.07494741]\n",
      " [0.07968329 0.09657416 0.0935797  ... 0.0616115  0.06177606 0.07021459]\n",
      " [0.06671149 0.08351383 0.09449034 ... 0.07948406 0.10403975 0.12024586]]\n",
      "得分8.0707\n",
      "stack:4/5\n",
      "[[0.07842534 0.07175273 0.08514435 ... 0.09758065 0.09786125 0.10550124]\n",
      " [0.07562529 0.06930476 0.08253054 ... 0.10171099 0.09914799 0.11558477]\n",
      " [0.06632987 0.11696143 0.13583494 ... 0.08304862 0.0640828  0.06697865]\n",
      " ...\n",
      " [0.09250402 0.09353703 0.07783287 ... 0.08361247 0.07767342 0.07664401]\n",
      " [0.08018757 0.10719182 0.06681306 ... 0.06304676 0.07989321 0.08012168]\n",
      " [0.0835294  0.09972829 0.09954519 ... 0.08370742 0.07833166 0.08409864]]\n",
      "得分7.862358707612284\n",
      "stack:5/5\n",
      "[[0.07132238 0.09492749 0.08058986 ... 0.09410064 0.08365465 0.07978941]\n",
      " [0.05518647 0.08022667 0.12149414 ... 0.08402592 0.10340284 0.07235678]\n",
      " [0.0594696  0.10077031 0.17593572 ... 0.10259329 0.07680606 0.05839361]\n",
      " ...\n",
      " [0.079835   0.09683538 0.09289549 ... 0.08274172 0.08336683 0.07646575]\n",
      " [0.08197213 0.09383179 0.09588334 ... 0.08154892 0.07152927 0.07198566]\n",
      " [0.06458933 0.09659129 0.07157539 ... 0.0859517  0.08327704 0.08302238]]\n",
      "得分7.9685842921460734\n"
     ]
    }
   ],
   "source": [
    "df_stack = pd.DataFrame()\n",
    "df_stack['device_id']=all_id['device_id']\n",
    "score = deviceid_train['age']\n",
    "\n",
    "########################### lr(LogisticRegression) ################################\n",
    "print('lr stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 11))\n",
    "stack_test = np.zeros((len(deviceid_test), 11))\n",
    "score_va = 0\n",
    "\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,score)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    clf = LogisticRegression(random_state=1017, C=8)\n",
    "    clf.fit(train_app[tr], score[tr])\n",
    "    score_va = clf.predict_proba(train_app[va])\n",
    "\n",
    "    score_te = clf.predict_proba(test_app)\n",
    "    print('得分' + str(mean_squared_error(score[va], clf.predict(train_app[va]))))\n",
    "    stack_train[va] = score_va\n",
    "    stack_test+= score_te\n",
    "stack_test /= n_folds\n",
    "\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "for i in range(stack.shape[1]):\n",
    "    df_stack['pack_tfidf_lr_classfiy_{}'.format(i)] = stack[:, i]\n",
    "\n",
    "\n",
    "########################### SGD(随机梯度下降) ################################\n",
    "print('sgd stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 11))\n",
    "stack_test = np.zeros((len(deviceid_test), 11))\n",
    "score_va = 0\n",
    "\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,score)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    sgd = SGDClassifier(random_state=1017, loss='log')\n",
    "    sgd.fit(train_app[tr], score[tr])\n",
    "    score_va = sgd.predict_proba(train_app[va])\n",
    "    score_te = sgd.predict_proba(test_app)\n",
    "    print('得分' + str(mean_squared_error(score[va], sgd.predict(train_app[va]))))\n",
    "    stack_train[va] = score_va\n",
    "    stack_test+= score_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "for i in range(stack.shape[1]):\n",
    "    df_stack['pack_tfidf_sgd_classfiy_{}'.format(i)] = stack[:, i]\n",
    "\n",
    "\n",
    "########################### pac(PassiveAggressiveClassifier) ################################\n",
    "print('PAC stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 11))\n",
    "stack_test = np.zeros((len(deviceid_test), 11))\n",
    "score_va = 0\n",
    "\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,score)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    pac = PassiveAggressiveClassifier(random_state=1017)\n",
    "    pac.fit(train_app[tr], score[tr])\n",
    "    score_va = pac._predict_proba_lr(train_app[va])\n",
    "    score_te = pac._predict_proba_lr(test_app)\n",
    "    print(score_va)\n",
    "    print('得分' + str(mean_squared_error(score[va], pac.predict(train_app[va]))))\n",
    "    stack_train[va] += score_va\n",
    "    stack_test += score_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "for i in range(stack.shape[1]):\n",
    "    df_stack['pack_tfidf_pac_classfiy_{}'.format(i)] = stack[:, i]\n",
    "\n",
    "\n",
    "\n",
    "########################### ridge(RidgeClassfiy) ################################\n",
    "print('RidgeClassfiy stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 11))\n",
    "stack_test = np.zeros((len(deviceid_test), 11))\n",
    "score_va = 0\n",
    "\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,score)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    ridge = RidgeClassifier(random_state=1017)\n",
    "    ridge.fit(train_app[tr], score[tr])\n",
    "    score_va = ridge._predict_proba_lr(train_app[va])\n",
    "    score_te = ridge._predict_proba_lr(test_app)\n",
    "    print(score_va)\n",
    "    print('得分' + str(mean_squared_error(score[va], ridge.predict(train_app[va]))))\n",
    "    stack_train[va] += score_va\n",
    "    stack_test += score_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "for i in range(stack.shape[1]):\n",
    "    df_stack['pack_tfidf_ridge_classfiy_{}'.format(i)] = stack[:, i]\n",
    "\n",
    "\n",
    "\n",
    "########################### bnb(BernoulliNB) ################################\n",
    "print('BernoulliNB stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 11))\n",
    "stack_test = np.zeros((len(deviceid_test), 11))\n",
    "score_va = 0\n",
    "\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,score)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(train_app[tr], score[tr])\n",
    "    score_va = bnb.predict_proba(train_app[va])\n",
    "    score_te = bnb.predict_proba(test_app)\n",
    "    print(score_va)\n",
    "    print('得分' + str(mean_squared_error(score[va], bnb.predict(train_app[va]))))\n",
    "    stack_train[va] += score_va\n",
    "    stack_test += score_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "for i in range(stack.shape[1]):\n",
    "    df_stack['pack_tfidf_bnb_classfiy_{}'.format(i)] = stack[:, i]\n",
    "\n",
    "########################### mnb(MultinomialNB) ################################\n",
    "print('MultinomialNB stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 11))\n",
    "stack_test = np.zeros((len(deviceid_test), 11))\n",
    "score_va = 0\n",
    "\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,score)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(train_app[tr], score[tr])\n",
    "    score_va = mnb.predict_proba(train_app[va])\n",
    "    score_te = mnb.predict_proba(test_app)\n",
    "    print(score_va)\n",
    "    print('得分' + str(mean_squared_error(score[va], mnb.predict(train_app[va]))))\n",
    "    stack_train[va] += score_va\n",
    "    stack_test += score_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "for i in range(stack.shape[1]):\n",
    "    df_stack['pack_tfidf_mnb_classfiy_{}'.format(i)] = stack[:, i]\n",
    "\n",
    "\n",
    "############################ Linersvc(LinerSVC) ################################\n",
    "print('LinerSVC stacking')\n",
    "stack_train = np.zeros((len(deviceid_train), 11))\n",
    "stack_test = np.zeros((len(deviceid_test), 11))\n",
    "score_va = 0\n",
    "\n",
    "for i, (tr,va) in enumerate(kv.split(train_app,score)):\n",
    "    print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "    lsvc = LinearSVC(random_state=1017)\n",
    "    lsvc.fit(train_app[tr], score[tr])\n",
    "    score_va = lsvc._predict_proba_lr(train_app[va])\n",
    "    score_te = lsvc._predict_proba_lr(test_app)\n",
    "    print(score_va)\n",
    "    print('得分' + str(mean_squared_error(score[va], lsvc.predict(train_app[va]))))\n",
    "    stack_train[va] += score_va\n",
    "    stack_test += score_te\n",
    "stack_test /= n_folds\n",
    "stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "for i in range(stack.shape[1]):\n",
    "    df_stack['pack_tfidf_lsvc_classfiy_{}'.format(i)] = stack[:, i]\n",
    "    \n",
    "df_stack.to_csv('./Demo/pack_tfidf_age.csv', index=None, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拆分训练集、测试集年龄与预测的结果\n",
    "age=pd.read_csv(\"./Demo/pack_tfidf_age.csv\")\n",
    "train_data = pd.merge(deviceid_train,age,on=\"device_id\",how=\"left\")\n",
    "test_data = pd.merge(deviceid_test,age,on=\"device_id\",how=\"left\")\n",
    "features = [x for x in train_data.columns if x not in ['device_id',\"age\",\"sex\",\"label\",\"app\"]]\n",
    "X=train_data[features]\n",
    "Y = train_data['age']\n",
    "del package_time\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.39261\tval-mlogloss:2.39375\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-mlogloss:1.92146\tval-mlogloss:2.07677\n",
      "[400]\ttrain-mlogloss:1.76388\tval-mlogloss:2.02748\n",
      "[600]\ttrain-mlogloss:1.66875\tval-mlogloss:2.02164\n",
      "Stopping. Best iteration:\n",
      "[553]\ttrain-mlogloss:1.6883\tval-mlogloss:2.02085\n",
      "\n",
      "idx:  0\n",
      " loss: 2.02185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.39273\tval-mlogloss:2.3935\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-mlogloss:1.93122\tval-mlogloss:2.06083\n",
      "[400]\ttrain-mlogloss:1.78117\tval-mlogloss:2.02234\n",
      "Stopping. Best iteration:\n",
      "[408]\ttrain-mlogloss:1.77686\tval-mlogloss:2.02197\n",
      "\n",
      "idx:  1\n",
      " loss: 2.02630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.39258\tval-mlogloss:2.39375\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-mlogloss:1.92154\tval-mlogloss:2.08548\n",
      "[400]\ttrain-mlogloss:1.77097\tval-mlogloss:2.05639\n",
      "Stopping. Best iteration:\n",
      "[364]\ttrain-mlogloss:1.79072\tval-mlogloss:2.05576\n",
      "\n",
      "idx:  2\n",
      " loss: 2.05991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.39265\tval-mlogloss:2.3937\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-mlogloss:1.91947\tval-mlogloss:2.07561\n",
      "[400]\ttrain-mlogloss:1.7624\tval-mlogloss:2.02614\n",
      "[600]\ttrain-mlogloss:1.67019\tval-mlogloss:2.02076\n",
      "Stopping. Best iteration:\n",
      "[561]\ttrain-mlogloss:1.68571\tval-mlogloss:2.02043\n",
      "\n",
      "idx:  3\n",
      " loss: 2.02171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.39258\tval-mlogloss:2.39377\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 100 rounds.\n",
      "[200]\ttrain-mlogloss:1.91761\tval-mlogloss:2.07628\n",
      "[400]\ttrain-mlogloss:1.75807\tval-mlogloss:2.02423\n",
      "[600]\ttrain-mlogloss:1.66239\tval-mlogloss:2.01306\n",
      "[800]\ttrain-mlogloss:1.58997\tval-mlogloss:2.01078\n",
      "Stopping. Best iteration:\n",
      "[824]\ttrain-mlogloss:1.58197\tval-mlogloss:2.01067\n",
      "\n",
      "idx:  4\n",
      " loss: 2.01098\n",
      "mean\n",
      "auc:       2.028149457113755\n"
     ]
    }
   ],
   "source": [
    "# 使用 xgb 预测最终的年龄\n",
    "params={\n",
    "\t'booster':'gbtree',\n",
    "\t'objective': 'multi:softprob',\n",
    "#      'is_unbalance':'True',\n",
    "# \t'scale_pos_weight': 1500.0/13458.0,\n",
    "        'eval_metric': \"mlogloss\",\n",
    "    'num_class':11,\n",
    "\t'gamma':0.1,#0.2 is ok\n",
    "\t'max_depth':6,\n",
    "# \t'lambda':20,\n",
    "    # \"alpha\":5,\n",
    "        'subsample':0.7,\n",
    "        'colsample_bytree':0.4 ,\n",
    "        # 'min_child_weight':2.5, \n",
    "        'eta': 0.01,\n",
    "    # 'learning_rate':0.01,\n",
    "    \"silent\":1,\n",
    "\t'seed':1024,\n",
    "\t'nthread':12,\n",
    "    }\n",
    "\n",
    "auc = [] \n",
    "test_age = np.zeros((len(deviceid_test),11 ))\n",
    "pred_age=np.zeros((len(deviceid_train),11))\n",
    "for i, (train_index,valid_index) in enumerate(kv.split(X,Y)):\n",
    "    tr_x = X.loc[train_index,:]\n",
    "    tr_y = Y[train_index]\n",
    "    valid_x = X.loc[valid_index,:]\n",
    "    valid_y = Y[valid_index]    \n",
    "    d_tr = xgb.DMatrix(tr_x, label=tr_y)\n",
    "    d_valid = xgb.DMatrix(valid_x, label=valid_y)\n",
    "    watchlist  = [(d_tr,'train'),(d_valid,'val')]\n",
    "    model = xgb.train(params, d_tr, num_boost_round=5500, \n",
    "                      evals=watchlist,verbose_eval=200,\n",
    "                              early_stopping_rounds=100)\n",
    "    pred = model.predict(d_valid)\n",
    "    pred_age[valid_index] =pred                  \n",
    "    a = log_loss(valid_y, pred)    \n",
    "    test_age += model.predict(xgb.DMatrix(test_data[features]))/5\n",
    "    print (\"idx: \", i) \n",
    "    print (\" loss: %.5f\" % a)\n",
    "#     print \" gini: %.5f\" % g\n",
    "    auc.append(a)  \n",
    "print (\"mean\")\n",
    "print (\"auc:       %s\" % (sum(auc) / 5.0))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并训练集、测试集的预测年龄\n",
    "age=np.vstack((pred_age,test_age))\n",
    "age = pd.DataFrame(age)\n",
    "\n",
    "age.index=range(len(age))\n",
    "sex.index=range(len(sex))\n",
    "\n",
    "# 计算每个[性别-年龄]的概率\n",
    "# age1 表示性别为 0 的各年龄层分布概率\n",
    "# age2 表示性别为 1 的各年龄层分布概率\n",
    "sex_age1=age.copy()\n",
    "sex_age2=age.copy()\n",
    "for i in range(11):\n",
    "    sex_age1[i]=sex['sex1']*age[i]\n",
    "    sex_age2[i]=sex['sex2']*age[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加上设备 id 列 \n",
    "final_pred = pd.concat([sex_age1,sex_age2],1)\n",
    "all_id.columns= ['DeviceID']\n",
    "final=pd.concat([all_id,final_pred],1)\n",
    "final.columns = ['DeviceID', '1-0', '1-1', '1-2', '1-3', '1-4', '1-5', '1-6', \n",
    "         '1-7','1-8', '1-9', '1-10', '2-0', '2-1', '2-2', '2-3', '2-4', \n",
    "         '2-5', '2-6', '2-7', '2-8', '2-9', '2-10']\n",
    "\n",
    "# 取出测试集的预测结果，保存到 csv 中\n",
    "final[50000:].to_csv('./Demo/xgb_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除一些变量，回收内存\n",
    "del deviceid_train\n",
    "del deviceid_test\n",
    "del user\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>memory</th>\n",
       "      <th>convert_memory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>df_app</td>\n",
       "      <td>6831678012</td>\n",
       "      <td>6GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>atime</td>\n",
       "      <td>174103998</td>\n",
       "      <td>166MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>train_data</td>\n",
       "      <td>157459034</td>\n",
       "      <td>150MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>X</td>\n",
       "      <td>132960744</td>\n",
       "      <td>127MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>tr_x</td>\n",
       "      <td>105333189</td>\n",
       "      <td>100MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>use_time_top100_statis</td>\n",
       "      <td>100684892</td>\n",
       "      <td>96MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>test_data</td>\n",
       "      <td>70940379</td>\n",
       "      <td>68MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>deviceid_packages</td>\n",
       "      <td>65227140</td>\n",
       "      <td>62MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>top100_statis</td>\n",
       "      <td>63868579</td>\n",
       "      <td>61MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>df_stack</td>\n",
       "      <td>51272687</td>\n",
       "      <td>49MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>wtime</td>\n",
       "      <td>45867197</td>\n",
       "      <td>44MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>apps</td>\n",
       "      <td>34434974</td>\n",
       "      <td>33MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>app_cat_num</td>\n",
       "      <td>33236263</td>\n",
       "      <td>32MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>app_cat_time</td>\n",
       "      <td>33236263</td>\n",
       "      <td>32MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>cat_time</td>\n",
       "      <td>26492177</td>\n",
       "      <td>25MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>cat_num</td>\n",
       "      <td>26492177</td>\n",
       "      <td>25MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>valid_x</td>\n",
       "      <td>26316859</td>\n",
       "      <td>25MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>train_str_app</td>\n",
       "      <td>25113761</td>\n",
       "      <td>24MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>deviced_brand</td>\n",
       "      <td>22266652</td>\n",
       "      <td>21MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>ftime</td>\n",
       "      <td>20436439</td>\n",
       "      <td>19MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>final</td>\n",
       "      <td>19272807</td>\n",
       "      <td>18MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>weektime</td>\n",
       "      <td>12872831</td>\n",
       "      <td>12MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>final_pred</td>\n",
       "      <td>12800104</td>\n",
       "      <td>12MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>test_str_app</td>\n",
       "      <td>11354312</td>\n",
       "      <td>11MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>ph_ver_dummy</td>\n",
       "      <td>11127383</td>\n",
       "      <td>11MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>tfidf_feat</td>\n",
       "      <td>10545567</td>\n",
       "      <td>10MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>_7</td>\n",
       "      <td>9143498</td>\n",
       "      <td>9MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>dapp_stat</td>\n",
       "      <td>8218303</td>\n",
       "      <td>8MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>app</td>\n",
       "      <td>7054543</td>\n",
       "      <td>7MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>all_id</td>\n",
       "      <td>6472855</td>\n",
       "      <td>6MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>sex_age2</td>\n",
       "      <td>6400128</td>\n",
       "      <td>6MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>sex_age1</td>\n",
       "      <td>6400128</td>\n",
       "      <td>6MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>age</td>\n",
       "      <td>6400128</td>\n",
       "      <td>6MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>stack</td>\n",
       "      <td>6400088</td>\n",
       "      <td>6MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>pred_age</td>\n",
       "      <td>4400112</td>\n",
       "      <td>4MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>stack_train</td>\n",
       "      <td>4400112</td>\n",
       "      <td>4MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>app_num</td>\n",
       "      <td>3401752</td>\n",
       "      <td>3MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>app_use_time</td>\n",
       "      <td>3401752</td>\n",
       "      <td>3MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>app_category</td>\n",
       "      <td>3148208</td>\n",
       "      <td>3MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>package_label</td>\n",
       "      <td>2779184</td>\n",
       "      <td>3MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>score</td>\n",
       "      <td>2110744</td>\n",
       "      <td>2MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Y</td>\n",
       "      <td>2110744</td>\n",
       "      <td>2MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>test_age</td>\n",
       "      <td>2000088</td>\n",
       "      <td>2MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>score_te</td>\n",
       "      <td>2000088</td>\n",
       "      <td>2MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>stack_test</td>\n",
       "      <td>2000088</td>\n",
       "      <td>2MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>sex</td>\n",
       "      <td>1163784</td>\n",
       "      <td>1MB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name      memory convert_memory\n",
       "20                  df_app  6831678012            6GB\n",
       "5                    atime   174103998          166MB\n",
       "31              train_data   157459034          150MB\n",
       "33                       X   132960744          127MB\n",
       "35                    tr_x   105333189          100MB\n",
       "16  use_time_top100_statis   100684892           96MB\n",
       "32               test_data    70940379           68MB\n",
       "3        deviceid_packages    65227140           62MB\n",
       "17           top100_statis    63868579           61MB\n",
       "25                df_stack    51272687           49MB\n",
       "4                    wtime    45867197           44MB\n",
       "21                    apps    34434974           33MB\n",
       "13             app_cat_num    33236263           32MB\n",
       "14            app_cat_time    33236263           32MB\n",
       "12                cat_time    26492177           25MB\n",
       "11                 cat_num    26492177           25MB\n",
       "36                 valid_x    26316859           25MB\n",
       "22           train_str_app    25113761           24MB\n",
       "0            deviced_brand    22266652           21MB\n",
       "8                    ftime    20436439           19MB\n",
       "45                   final    19272807           18MB\n",
       "9                 weektime    12872831           12MB\n",
       "44              final_pred    12800104           12MB\n",
       "23            test_str_app    11354312           11MB\n",
       "18            ph_ver_dummy    11127383           11MB\n",
       "30              tfidf_feat    10545567           10MB\n",
       "6                       _7     9143498            9MB\n",
       "7                dapp_stat     8218303            8MB\n",
       "10                     app     7054543            7MB\n",
       "24                  all_id     6472855            6MB\n",
       "43                sex_age2     6400128            6MB\n",
       "42                sex_age1     6400128            6MB\n",
       "39                     age     6400128            6MB\n",
       "29                   stack     6400088            6MB\n",
       "41                pred_age     4400112            4MB\n",
       "27             stack_train     4400112            4MB\n",
       "19                 app_num     3401752            3MB\n",
       "15            app_use_time     3401752            3MB\n",
       "2             app_category     3148208            3MB\n",
       "1            package_label     2779184            3MB\n",
       "37                   score     2110744            2MB\n",
       "34                       Y     2110744            2MB\n",
       "40                test_age     2000088            2MB\n",
       "38                score_te     2000088            2MB\n",
       "28              stack_test     2000088            2MB\n",
       "26                     sex     1163784            1MB"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_df = get_memory()\n",
    "memory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_app\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 增强版：使用神经网络训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取之前处理好的特征\n",
    "behave_train = pd.read_csv('./Demo/train_statistic_feat.csv')\n",
    "behave_test = pd.read_csv('./Demo/test_statistic_feat.csv')\n",
    "\n",
    "# # 设置列不限制数量\n",
    "# pd.set_option('display.max_columns',None)\n",
    "# # 设置行不限制数量\n",
    "# pd.set_option('display.max_rows',None)\n",
    "# # 由于 behave_train.columns 显示不全，因此转换为 np.array 再显示\n",
    "# # print(np.array(behave_train.columns))\n",
    "# # behave_train['app']\n",
    "# # 由于这一列是字符串，故删除\n",
    "# del behave_train['app']\n",
    "\n",
    "behave_train.drop(['sex', 'age', 'label', 'app'], 1, inplace=True)\n",
    "behave_test.drop(['sex', 'age', 'label', 'app'], 1, inplace=True)\n",
    "\n",
    "# 读取 设备信息，包括品牌和型号\n",
    "brand=pd.read_csv('./Demo/deviceid_brand.tsv',sep='\\t', names=['device_id','brand','model'])\n",
    "# 读取训练数据集\n",
    "train=pd.read_csv('./Demo/deviceid_train.tsv',sep='\\t',names=['device_id','sex','age'])\n",
    "# 读取测试数据集\n",
    "test=pd.read_csv('./Demo/deviceid_test.tsv',sep='\\t',names=['device_id'])\n",
    "# 读取 APP 使用情况\n",
    "# 读取设备安装的 app 数据\n",
    "packages=pd.read_csv('./Demo/deviceid_packages.tsv',sep='\\t', names=['device_id','apps'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接品牌和型号，和测试集、训练集合并\n",
    "brand['phone_version'] = brand['brand'] + ' ' + brand['model']\n",
    "train = pd.merge(brand[['device_id', 'phone_version']],\n",
    "                 train, on='device_id', how='right')\n",
    "test = pd.merge(brand[['device_id', 'phone_version']],\n",
    "                test, on='device_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把用户行为数据合并到训练集、测试集\n",
    "train = pd.merge(train, behave_train, on='device_id', how='left')\n",
    "test = pd.merge(test, behave_test, on='device_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理app，为下面分词做准备\n",
    "gc.collect()\n",
    "packages['app_lenghth'] = packages['apps'].apply(\n",
    "    lambda x: x.split(',')).apply(lambda x: len(x))\n",
    "packages['app_list'] = packages['apps'].apply(lambda x: x.split(','))\n",
    "# 把app 数据合并到训练集、测试集，下面转换为词索引\n",
    "train = pd.merge(train, packages, on='device_id', how='left')\n",
    "test = pd.merge(test, packages, on='device_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>apps</th>\n",
       "      <th>app_lenghth</th>\n",
       "      <th>app_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00009270c4ec26e1d76f5d86847009c9</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086,90cb852cf345e...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1896072db9ce6406febfc17f681c2086, 90cb852cf34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000189ef5d5b951841d416a8c6c5b995</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086,97d0422a3317b...</td>\n",
       "      <td>19</td>\n",
       "      <td>[1896072db9ce6406febfc17f681c2086, 97d0422a331...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00026d79a6f0955fc860947724e24765</td>\n",
       "      <td>c33b35d6254ad9c0c238233eb97a6c60</td>\n",
       "      <td>1</td>\n",
       "      <td>[c33b35d6254ad9c0c238233eb97a6c60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002e3afb8146bc08e40575e45f0eca6</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086,07e967d75aab2...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1896072db9ce6406febfc17f681c2086, 07e967d75aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0004709a296f9b925ae283efe2f043e7</td>\n",
       "      <td>4538778ad75aa8ce61c9d13fb9cb661b,86f9f299cdbc8...</td>\n",
       "      <td>16</td>\n",
       "      <td>[4538778ad75aa8ce61c9d13fb9cb661b, 86f9f299cdb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          device_id  \\\n",
       "0  00009270c4ec26e1d76f5d86847009c9   \n",
       "1  000189ef5d5b951841d416a8c6c5b995   \n",
       "2  00026d79a6f0955fc860947724e24765   \n",
       "3  0002e3afb8146bc08e40575e45f0eca6   \n",
       "4  0004709a296f9b925ae283efe2f043e7   \n",
       "\n",
       "                                                apps  app_lenghth  \\\n",
       "0  1896072db9ce6406febfc17f681c2086,90cb852cf345e...            3   \n",
       "1  1896072db9ce6406febfc17f681c2086,97d0422a3317b...           19   \n",
       "2                   c33b35d6254ad9c0c238233eb97a6c60            1   \n",
       "3  1896072db9ce6406febfc17f681c2086,07e967d75aab2...            3   \n",
       "4  4538778ad75aa8ce61c9d13fb9cb661b,86f9f299cdbc8...           16   \n",
       "\n",
       "                                            app_list  \n",
       "0  [1896072db9ce6406febfc17f681c2086, 90cb852cf34...  \n",
       "1  [1896072db9ce6406febfc17f681c2086, 97d0422a331...  \n",
       "2                 [c33b35d6254ad9c0c238233eb97a6c60]  \n",
       "3  [1896072db9ce6406febfc17f681c2086, 07e967d75aa...  \n",
       "4  [4538778ad75aa8ce61c9d13fb9cb661b, 86f9f299cdb...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Word2Vec，训练 APP 的词向量\n",
    "embed_size = 128\n",
    "fastmodel = Word2Vec(list(packages['app_list']), size=embed_size, window=4, min_count=3, negative=2,\n",
    "                     sg=1, sample=0.002, hs=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdim_0</th>\n",
       "      <th>fdim_1</th>\n",
       "      <th>fdim_2</th>\n",
       "      <th>fdim_3</th>\n",
       "      <th>fdim_4</th>\n",
       "      <th>fdim_5</th>\n",
       "      <th>fdim_6</th>\n",
       "      <th>fdim_7</th>\n",
       "      <th>fdim_8</th>\n",
       "      <th>fdim_9</th>\n",
       "      <th>...</th>\n",
       "      <th>fdim_119</th>\n",
       "      <th>fdim_120</th>\n",
       "      <th>fdim_121</th>\n",
       "      <th>fdim_122</th>\n",
       "      <th>fdim_123</th>\n",
       "      <th>fdim_124</th>\n",
       "      <th>fdim_125</th>\n",
       "      <th>fdim_126</th>\n",
       "      <th>fdim_127</th>\n",
       "      <th>app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.121516</td>\n",
       "      <td>0.372894</td>\n",
       "      <td>-0.245987</td>\n",
       "      <td>0.132014</td>\n",
       "      <td>-0.001482</td>\n",
       "      <td>-0.068758</td>\n",
       "      <td>-0.092777</td>\n",
       "      <td>0.200586</td>\n",
       "      <td>-0.134259</td>\n",
       "      <td>0.064190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.582489</td>\n",
       "      <td>-0.314622</td>\n",
       "      <td>-0.197775</td>\n",
       "      <td>-0.016513</td>\n",
       "      <td>0.417600</td>\n",
       "      <td>0.397454</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>-0.195148</td>\n",
       "      <td>-0.190888</td>\n",
       "      <td>1896072db9ce6406febfc17f681c2086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.064080</td>\n",
       "      <td>0.218942</td>\n",
       "      <td>-0.037752</td>\n",
       "      <td>0.016974</td>\n",
       "      <td>-0.039094</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>-0.371990</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>-0.251649</td>\n",
       "      <td>-0.081215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>-0.123432</td>\n",
       "      <td>0.077276</td>\n",
       "      <td>-0.002812</td>\n",
       "      <td>0.371476</td>\n",
       "      <td>0.270820</td>\n",
       "      <td>0.099713</td>\n",
       "      <td>-0.193485</td>\n",
       "      <td>-0.113203</td>\n",
       "      <td>90cb852cf345e04d508fe03f74089183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.076992</td>\n",
       "      <td>0.167960</td>\n",
       "      <td>-0.197834</td>\n",
       "      <td>-0.066358</td>\n",
       "      <td>-0.264205</td>\n",
       "      <td>-0.183335</td>\n",
       "      <td>-0.049631</td>\n",
       "      <td>-0.117933</td>\n",
       "      <td>-0.180492</td>\n",
       "      <td>0.099059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168310</td>\n",
       "      <td>-0.295977</td>\n",
       "      <td>-0.334155</td>\n",
       "      <td>-0.121751</td>\n",
       "      <td>0.094657</td>\n",
       "      <td>0.059842</td>\n",
       "      <td>-0.004529</td>\n",
       "      <td>0.093666</td>\n",
       "      <td>0.058432</td>\n",
       "      <td>8c8544b6c129ad4a431be753143ed1c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.035663</td>\n",
       "      <td>0.049326</td>\n",
       "      <td>-0.220225</td>\n",
       "      <td>0.034521</td>\n",
       "      <td>-0.261449</td>\n",
       "      <td>-0.296225</td>\n",
       "      <td>-0.389785</td>\n",
       "      <td>0.019488</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>-0.047799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058925</td>\n",
       "      <td>0.132131</td>\n",
       "      <td>-0.012750</td>\n",
       "      <td>-0.303868</td>\n",
       "      <td>-0.242535</td>\n",
       "      <td>0.129828</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>0.262386</td>\n",
       "      <td>-0.171694</td>\n",
       "      <td>97d0422a3317b1929926dc90cda4fc53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.288690</td>\n",
       "      <td>0.112326</td>\n",
       "      <td>-0.097046</td>\n",
       "      <td>0.151983</td>\n",
       "      <td>-0.201054</td>\n",
       "      <td>-0.122145</td>\n",
       "      <td>-0.200348</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>-0.054769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120937</td>\n",
       "      <td>-0.107319</td>\n",
       "      <td>0.034874</td>\n",
       "      <td>-0.216375</td>\n",
       "      <td>0.130095</td>\n",
       "      <td>0.094428</td>\n",
       "      <td>-0.070014</td>\n",
       "      <td>-0.050806</td>\n",
       "      <td>-0.151717</td>\n",
       "      <td>5e8709466b22da6b45bfd30825bd3620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fdim_0    fdim_1    fdim_2    fdim_3    fdim_4    fdim_5    fdim_6  \\\n",
       "0 -0.121516  0.372894 -0.245987  0.132014 -0.001482 -0.068758 -0.092777   \n",
       "1 -0.064080  0.218942 -0.037752  0.016974 -0.039094  0.009881 -0.371990   \n",
       "2  0.076992  0.167960 -0.197834 -0.066358 -0.264205 -0.183335 -0.049631   \n",
       "3 -0.035663  0.049326 -0.220225  0.034521 -0.261449 -0.296225 -0.389785   \n",
       "4  0.288690  0.112326 -0.097046  0.151983 -0.201054 -0.122145 -0.200348   \n",
       "\n",
       "     fdim_7    fdim_8    fdim_9  ...  fdim_119  fdim_120  fdim_121  fdim_122  \\\n",
       "0  0.200586 -0.134259  0.064190  ... -0.582489 -0.314622 -0.197775 -0.016513   \n",
       "1  0.021120 -0.251649 -0.081215  ... -0.009384 -0.123432  0.077276 -0.002812   \n",
       "2 -0.117933 -0.180492  0.099059  ...  0.168310 -0.295977 -0.334155 -0.121751   \n",
       "3  0.019488 -0.000664 -0.047799  ... -0.058925  0.132131 -0.012750 -0.303868   \n",
       "4  0.004932 -0.016378 -0.054769  ... -0.120937 -0.107319  0.034874 -0.216375   \n",
       "\n",
       "   fdim_123  fdim_124  fdim_125  fdim_126  fdim_127  \\\n",
       "0  0.417600  0.397454  0.017911 -0.195148 -0.190888   \n",
       "1  0.371476  0.270820  0.099713 -0.193485 -0.113203   \n",
       "2  0.094657  0.059842 -0.004529  0.093666  0.058432   \n",
       "3 -0.242535  0.129828  0.072585  0.262386 -0.171694   \n",
       "4  0.130095  0.094428 -0.070014 -0.050806 -0.151717   \n",
       "\n",
       "                                app  \n",
       "0  1896072db9ce6406febfc17f681c2086  \n",
       "1  90cb852cf345e04d508fe03f74089183  \n",
       "2  8c8544b6c129ad4a431be753143ed1c3  \n",
       "3  97d0422a3317b1929926dc90cda4fc53  \n",
       "4  5e8709466b22da6b45bfd30825bd3620  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将词向量转换为 DataFrame\n",
    "# 每行对应一个 APP 的词向量\n",
    "embedding_fast=pd.DataFrame([fastmodel[word] for word in fastmodel.wv.vocab])\n",
    "embedding_fast['app'] = list(fastmodel.wv.vocab)\n",
    "embedding_fast.columns = [\"fdim_%s\" % str(i) for i in range(embed_size)]+['app']\n",
    "embedding_fast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from gensim.models import FastText, Word2Vec\n",
    "import re\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import *\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "import keras.backend as K\n",
    "from keras.optimizers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽取出 APP 列表，填充使得长度均为 50\n",
    "tokenizer = Tokenizer(lower=False, char_level=False, split=',')\n",
    "\n",
    "tokenizer.fit_on_texts(list(packages['apps']))\n",
    "# 使用 texts_to_sequences 将 APP 转换为数字\n",
    "X_seq = tokenizer.texts_to_sequences(train['apps'])\n",
    "X_test_seq = tokenizer.texts_to_sequences(test['apps'])\n",
    "\n",
    "maxlen = 50\n",
    "X_app = pad_sequences(X_seq, maxlen=maxlen, value=0)\n",
    "X_app_test = pad_sequences(X_test_seq, maxlen=maxlen, value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   2,\n",
       "        11,   7,   5,  24,   4,   6,  51,   9,  14,  35, 780])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看某个设备安装的 APP\n",
    "X_app[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 总共有 35000 个不同 APP\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建性别标签\n",
    "Y_sex = train['sex']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 根据 tokenizer 的索引，创建词向量矩阵。用于后面的 Embedding 层\n",
    "# 总共有 35000 个不同 APP，由于 tokenizer 的索引从 1 开始，因此为 35001\n",
    "max_feaures = 35001\n",
    "embedding_matrix = np.zeros((max_feaures, embed_size))\n",
    "for word in tokenizer.word_index:\n",
    "    if word not in fastmodel.wv.vocab:\n",
    "        continue\n",
    "    embedding_matrix[tokenizer.word_index[word]]= fastmodel[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别对训练集、测试集的用户行为数据做过滤，根据训练集、测试集的设备 id 过滤\n",
    "behave_train = pd.merge(train[['device_id']],\n",
    "                        behave_train, on='device_id', how=\"left\")\n",
    "behave_test = pd.merge(test[['device_id']],\n",
    "                       behave_test, on='device_id', how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出数值矩阵，去掉第一列：设备 ID\n",
    "X_behave = behave_train.iloc[:, 1:].values\n",
    "X_behave_test = behave_test.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预测性别的模型\n",
    "def model_conv1D(embedding_matrix):\n",
    "    K.clear_session()\n",
    "    # The embedding layer containing the word vectors\n",
    "    # embedding 层是根据词取出对应的词向量\n",
    "    emb_layer = Embedding(\n",
    "        input_dim=embedding_matrix.shape[0],# 有多少个词\n",
    "        output_dim=embedding_matrix.shape[1], # 词向量的维度\n",
    "        weights=[embedding_matrix], # 词向量矩阵\n",
    "        input_length=maxlen,# 最多有 50 个词\n",
    "        trainable=False\n",
    "    )\n",
    "    # units=128 就是输出层的维度,return_sequences=True 表示中间的状态也保留\n",
    "    # input(batch_size, num_words, dim), output(batch_size, num_words, units*2)\n",
    "    lstm_layer = Bidirectional(GRU(128, recurrent_dropout=0.15, dropout=0.15, return_sequences=True))    \n",
    "    # 1D convolutions that can iterate over the word vectors\n",
    "    \n",
    "    # output (batch_size, num_words-kernel_size+1, filters)\n",
    "    conv1 = Conv1D(filters=128, kernel_size=1,\n",
    "                   padding='same', activation='relu',)\n",
    "    \n",
    "    # Define inputs\n",
    "    seq = Input(shape=(maxlen,))  \n",
    "    # Run inputs through embedding\n",
    "    emb = emb_layer(seq)    \n",
    "    \n",
    "    lstm = lstm_layer(emb)\n",
    "    # Run through CONV + GAP layers\n",
    "    conv1a = conv1(lstm)\n",
    "    # output (batch_size, 1, channels(units)) (128,128)\n",
    "    gap1a = GlobalAveragePooling1D()(conv1a)\n",
    "    # output (batch_size, 1, channels(units)) (128,128)\n",
    "    gmp1a = GlobalMaxPool1D()(conv1a)    \n",
    "    \n",
    "    # 385 对应于 X_behave 的维度\n",
    "    hin = Input(shape=(385, ))\n",
    "    htime = Dense(64, activation='relu')(hin) # (128, 64)\n",
    "    merge1 = concatenate([gap1a, gmp1a, htime])    # (128, 320) 128+128+64=320\n",
    "    \n",
    "    # The MLP that determines the outcome\n",
    "    x = Dropout(0.3)(merge1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(200, activation='relu',)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(200, activation='relu',)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(200, activation='relu',)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    pred = Dense(1, activation='sigmoid')(x)    \n",
    "    \n",
    "    # model = Model(inputs=[seq1, seq2, magic_input, distance_input], outputs=pred)\n",
    "    model = Model(inputs=[seq, hin], outputs=pred)    \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam())\n",
    "#     model.summary()\n",
    "    return model    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 128)      4480128     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50, 256)      197376      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 50, 128)      32896       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 385)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           24704       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 320)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 320)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 320)          1280        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 200)          64200       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200)          800         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          40200       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 200)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200)          800         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 200)          40200       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 200)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200)          800         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            201         batch_normalization_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 4,883,585\n",
      "Trainable params: 401,617\n",
      "Non-trainable params: 4,481,968\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_sex = model_conv1D(embedding_matrix)\n",
    "model_sex.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD |  1\n",
      "Train on 39999 samples, validate on 10001 samples\n",
      "Epoch 1/50\n",
      "39999/39999 [==============================] - ETA: 35:20 - loss: na - ETA: 27:09 - loss: na - ETA: 24:20 - loss: na - ETA: 23:12 - loss: na - ETA: 22:07 - loss: na - ETA: 21:39 - loss: na - ETA: 21:19 - loss: na - ETA: 21:02 - loss: na - ETA: 20:44 - loss: na - ETA: 20:28 - loss: na - ETA: 20:12 - loss: na - ETA: 19:55 - loss: na - ETA: 19:45 - loss: na - ETA: 19:37 - loss: na - ETA: 19:30 - loss: na - ETA: 19:24 - loss: na - ETA: 19:13 - loss: na - ETA: 19:05 - loss: na - ETA: 18:56 - loss: na - ETA: 18:50 - loss: na - ETA: 18:43 - loss: na - ETA: 18:37 - loss: na - ETA: 18:30 - loss: na - ETA: 18:23 - loss: na - ETA: 18:18 - loss: na - ETA: 18:11 - loss: na - ETA: 18:06 - loss: na - ETA: 17:59 - loss: na - ETA: 17:54 - loss: na - ETA: 17:49 - loss: na - ETA: 17:45 - loss: na - ETA: 17:40 - loss: na - ETA: 17:35 - loss: na - ETA: 17:29 - loss: na - ETA: 17:24 - loss: na - ETA: 17:19 - loss: na - ETA: 17:14 - loss: na - ETA: 17:09 - loss: na - ETA: 17:05 - loss: na - ETA: 17:00 - loss: na - ETA: 16:56 - loss: na - ETA: 16:51 - loss: na - ETA: 16:47 - loss: na - ETA: 16:43 - loss: na - ETA: 16:40 - loss: na - ETA: 16:36 - loss: na - ETA: 16:32 - loss: na - ETA: 16:28 - loss: na - ETA: 16:23 - loss: na - ETA: 16:19 - loss: na - ETA: 16:15 - loss: na - ETA: 16:10 - loss: na - ETA: 16:06 - loss: na - ETA: 16:03 - loss: na - ETA: 15:59 - loss: na - ETA: 15:55 - loss: na - ETA: 15:51 - loss: na - ETA: 15:47 - loss: na - ETA: 15:43 - loss: na - ETA: 15:39 - loss: na - ETA: 15:36 - loss: na - ETA: 15:32 - loss: na - ETA: 15:29 - loss: na - ETA: 15:25 - loss: na - ETA: 15:21 - loss: na - ETA: 15:18 - loss: na - ETA: 15:14 - loss: na - ETA: 15:10 - loss: na - ETA: 15:08 - loss: na - ETA: 15:05 - loss: na - ETA: 15:01 - loss: na - ETA: 14:59 - loss: na - ETA: 14:55 - loss: na - ETA: 14:51 - loss: na - ETA: 14:48 - loss: na - ETA: 14:44 - loss: na - ETA: 14:41 - loss: na - ETA: 14:38 - loss: na - ETA: 14:34 - loss: na - ETA: 14:31 - loss: na - ETA: 14:26 - loss: na - ETA: 14:22 - loss: na - ETA: 14:19 - loss: na - ETA: 14:15 - loss: na - ETA: 14:11 - loss: na - ETA: 14:08 - loss: na - ETA: 14:04 - loss: na - ETA: 14:01 - loss: na - ETA: 13:57 - loss: na - ETA: 13:54 - loss: na - ETA: 13:51 - loss: na - ETA: 13:47 - loss: na - ETA: 13:44 - loss: na - ETA: 13:40 - loss: na - ETA: 13:36 - loss: na - ETA: 13:32 - loss: na - ETA: 13:28 - loss: na - ETA: 13:25 - loss: na - ETA: 13:20 - loss: na - ETA: 13:17 - loss: na - ETA: 13:13 - loss: na - ETA: 13:09 - loss: na - ETA: 13:05 - loss: na - ETA: 13:01 - loss: na - ETA: 12:58 - loss: na - ETA: 12:53 - loss: na - ETA: 12:50 - loss: na - ETA: 12:46 - loss: na - ETA: 12:42 - loss: na - ETA: 12:38 - loss: na - ETA: 12:34 - loss: na - ETA: 12:30 - loss: na - ETA: 12:27 - loss: na - ETA: 12:23 - loss: na - ETA: 12:19 - loss: na - ETA: 12:15 - loss: na - ETA: 12:12 - loss: na - ETA: 12:08 - loss: na - ETA: 12:04 - loss: na - ETA: 12:00 - loss: na - ETA: 11:56 - loss: na - ETA: 11:52 - loss: na - ETA: 11:48 - loss: na - ETA: 11:45 - loss: na - ETA: 11:41 - loss: na - ETA: 11:37 - loss: na - ETA: 11:33 - loss: na - ETA: 11:29 - loss: na - ETA: 11:25 - loss: na - ETA: 11:22 - loss: na - ETA: 11:18 - loss: na - ETA: 11:14 - loss: na - ETA: 11:10 - loss: na - ETA: 11:06 - loss: na - ETA: 11:03 - loss: na - ETA: 10:59 - loss: na - ETA: 10:55 - loss: na - ETA: 10:51 - loss: na - ETA: 10:47 - loss: na - ETA: 10:44 - loss: na - ETA: 10:40 - loss: na - ETA: 10:36 - loss: na - ETA: 10:32 - loss: na - ETA: 10:28 - loss: na - ETA: 10:24 - loss: na - ETA: 10:21 - loss: na - ETA: 10:17 - loss: na - ETA: 10:13 - loss: na - ETA: 10:09 - loss: na - ETA: 10:05 - loss: na - ETA: 10:02 - loss: na - ETA: 9:58 - loss: na - ETA: 9:54 - loss: n - ETA: 9:50 - loss: n - ETA: 9:46 - loss: n - ETA: 9:43 - loss: n - ETA: 9:39 - loss: n - ETA: 9:35 - loss: n - ETA: 9:31 - loss: n - ETA: 9:27 - loss: n - ETA: 9:23 - loss: n - ETA: 9:20 - loss: n - ETA: 9:16 - loss: n - ETA: 9:12 - loss: n - ETA: 9:08 - loss: n - ETA: 9:05 - loss: n - ETA: 9:01 - loss: n - ETA: 8:57 - loss: n - ETA: 8:53 - loss: n - ETA: 8:49 - loss: n - ETA: 8:46 - loss: n - ETA: 8:42 - loss: n - ETA: 8:38 - loss: n - ETA: 8:34 - loss: n - ETA: 8:31 - loss: n - ETA: 8:27 - loss: n - ETA: 8:23 - loss: n - ETA: 8:20 - loss: n - ETA: 8:16 - loss: n - ETA: 8:12 - loss: n - ETA: 8:08 - loss: n - ETA: 8:04 - loss: n - ETA: 8:00 - loss: n - ETA: 7:57 - loss: n - ETA: 7:53 - loss: n - ETA: 7:49 - loss: n - ETA: 7:46 - loss: n - ETA: 7:42 - loss: n - ETA: 7:38 - loss: n - ETA: 7:34 - loss: n - ETA: 7:31 - loss: n - ETA: 7:27 - loss: n - ETA: 7:23 - loss: n - ETA: 7:19 - loss: n - ETA: 7:16 - loss: n - ETA: 7:12 - loss: n - ETA: 7:08 - loss: n - ETA: 7:04 - loss: n - ETA: 7:01 - loss: n - ETA: 6:57 - loss: n - ETA: 6:53 - loss: n - ETA: 6:49 - loss: n - ETA: 6:46 - loss: n - ETA: 6:42 - loss: n - ETA: 6:38 - loss: n - ETA: 6:34 - loss: n - ETA: 6:31 - loss: n - ETA: 6:27 - loss: n - ETA: 6:23 - loss: n - ETA: 6:20 - loss: n - ETA: 6:16 - loss: n - ETA: 6:12 - loss: n - ETA: 6:08 - loss: n - ETA: 6:04 - loss: n - ETA: 6:01 - loss: n - ETA: 5:57 - loss: n - ETA: 5:53 - loss: n - ETA: 5:49 - loss: n - ETA: 5:46 - loss: n - ETA: 5:42 - loss: n - ETA: 5:38 - loss: n - ETA: 5:35 - loss: n - ETA: 5:31 - loss: n - ETA: 5:27 - loss: n - ETA: 5:24 - loss: n - ETA: 5:20 - loss: n - ETA: 5:16 - loss: n - ETA: 5:12 - loss: n - ETA: 5:09 - loss: n - ETA: 5:05 - loss: n - ETA: 5:01 - loss: n - ETA: 4:58 - loss: n - ETA: 4:54 - loss: n - ETA: 4:50 - loss: n - ETA: 4:46 - loss: n - ETA: 4:43 - loss: n - ETA: 4:39 - loss: n - ETA: 4:35 - loss: n - ETA: 4:32 - loss: n - ETA: 4:28 - loss: n - ETA: 4:24 - loss: n - ETA: 4:20 - loss: n - ETA: 4:17 - loss: n - ETA: 4:13 - loss: n - ETA: 4:09 - loss: n - ETA: 4:05 - loss: n - ETA: 4:02 - loss: n - ETA: 3:58 - loss: n - ETA: 3:54 - loss: n - ETA: 3:51 - loss: n - ETA: 3:47 - loss: n - ETA: 3:43 - loss: n - ETA: 3:39 - loss: n - ETA: 3:36 - loss: n - ETA: 3:32 - loss: n - ETA: 3:28 - loss: n - ETA: 3:25 - loss: n - ETA: 3:21 - loss: n - ETA: 3:17 - loss: n - ETA: 3:13 - loss: n - ETA: 3:10 - loss: n - ETA: 3:06 - loss: n - ETA: 3:02 - loss: n - ETA: 2:59 - loss: n - ETA: 2:55 - loss: n - ETA: 2:51 - loss: n - ETA: 2:48 - loss: n - ETA: 2:44 - loss: n - ETA: 2:40 - loss: n - ETA: 2:36 - loss: n - ETA: 2:33 - loss: n - ETA: 2:29 - loss: n - ETA: 2:25 - loss: n - ETA: 2:22 - loss: n - ETA: 2:18 - loss: n - ETA: 2:14 - loss: n - ETA: 2:11 - loss: n - ETA: 2:07 - loss: n - ETA: 2:03 - loss: n - ETA: 2:00 - loss: n - ETA: 1:56 - loss: n - ETA: 1:52 - loss: n - ETA: 1:48 - loss: n - ETA: 1:45 - loss: n - ETA: 1:41 - loss: n - ETA: 1:37 - loss: n - ETA: 1:34 - loss: n - ETA: 1:30 - loss: n - ETA: 1:26 - loss: n - ETA: 1:23 - loss: n - ETA: 1:19 - loss: n - ETA: 1:15 - loss: n - ETA: 1:11 - loss: n - ETA: 1:08 - loss: n - ETA: 1:04 - loss: n - ETA: 1:00 - loss: n - ETA: 57s - loss: nan - ETA: 53s - loss: na - ETA: 49s - loss: na - ETA: 46s - loss: na - ETA: 42s - loss: na - ETA: 38s - loss: na - ETA: 35s - loss: na - ETA: 31s - loss: na - ETA: 27s - loss: na - ETA: 23s - loss: na - ETA: 20s - loss: na - ETA: 16s - loss: na - ETA: 12s - loss: na - ETA: 9s - loss: na - ETA: 5s - loss: n - ETA: 1s - loss: n - 1162s 29ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:434: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss did not improve from inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:1024: RuntimeWarning: invalid value encountered in less\n",
      "  self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:538: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss: nan\n",
      "FOLD |  2\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - ETA: 32:24 - loss: na - ETA: 25:26 - loss: na - ETA: 23:14 - loss: na - ETA: 22:05 - loss: na - ETA: 21:28 - loss: na - ETA: 20:59 - loss: na - ETA: 20:36 - loss: na - ETA: 20:21 - loss: na - ETA: 20:02 - loss: na - ETA: 19:51 - loss: na - ETA: 19:44 - loss: na - ETA: 19:36 - loss: na - ETA: 19:28 - loss: na - ETA: 19:20 - loss: na - ETA: 19:11 - loss: na - ETA: 19:06 - loss: na - ETA: 18:58 - loss: na - ETA: 18:50 - loss: na - ETA: 18:43 - loss: na - ETA: 18:40 - loss: na - ETA: 18:32 - loss: na - ETA: 18:26 - loss: na - ETA: 18:19 - loss: na - ETA: 18:16 - loss: na - ETA: 18:11 - loss: na - ETA: 18:06 - loss: na - ETA: 18:01 - loss: na - ETA: 17:57 - loss: na - ETA: 17:53 - loss: na - ETA: 17:48 - loss: na - ETA: 17:44 - loss: na - ETA: 17:40 - loss: na - ETA: 17:34 - loss: na - ETA: 17:30 - loss: na - ETA: 17:25 - loss: na - ETA: 17:22 - loss: na - ETA: 17:17 - loss: na - ETA: 17:12 - loss: na - ETA: 17:09 - loss: na - ETA: 17:05 - loss: na - ETA: 17:01 - loss: na - ETA: 16:57 - loss: na - ETA: 16:53 - loss: na - ETA: 16:49 - loss: na - ETA: 16:46 - loss: na - ETA: 16:42 - loss: na - ETA: 16:38 - loss: na - ETA: 16:34 - loss: na - ETA: 16:29 - loss: na - ETA: 16:25 - loss: na - ETA: 16:21 - loss: na - ETA: 16:17 - loss: na - ETA: 16:13 - loss: na - ETA: 16:09 - loss: na - ETA: 16:05 - loss: na - ETA: 16:01 - loss: na - ETA: 15:57 - loss: na - ETA: 15:53 - loss: na - ETA: 15:50 - loss: na - ETA: 15:46 - loss: na - ETA: 15:41 - loss: na - ETA: 15:38 - loss: na - ETA: 15:34 - loss: na - ETA: 15:30 - loss: na - ETA: 15:26 - loss: na - ETA: 15:21 - loss: na - ETA: 15:18 - loss: na - ETA: 15:14 - loss: na - ETA: 15:10 - loss: na - ETA: 15:06 - loss: na - ETA: 15:03 - loss: na - ETA: 14:59 - loss: na - ETA: 14:55 - loss: na - ETA: 14:52 - loss: na - ETA: 14:48 - loss: na - ETA: 14:44 - loss: na - ETA: 14:40 - loss: na - ETA: 14:36 - loss: na - ETA: 14:33 - loss: na - ETA: 14:29 - loss: na - ETA: 14:25 - loss: na - ETA: 14:21 - loss: na - ETA: 14:18 - loss: na - ETA: 14:14 - loss: na - ETA: 14:10 - loss: na - ETA: 14:06 - loss: na - ETA: 14:02 - loss: na - ETA: 13:58 - loss: na - ETA: 13:55 - loss: na - ETA: 13:51 - loss: na - ETA: 13:47 - loss: na - ETA: 13:44 - loss: na - ETA: 13:40 - loss: na - ETA: 13:36 - loss: na - ETA: 13:32 - loss: na - ETA: 13:28 - loss: na - ETA: 13:25 - loss: na - ETA: 13:21 - loss: na - ETA: 13:17 - loss: na - ETA: 13:14 - loss: na - ETA: 13:10 - loss: na - ETA: 13:06 - loss: na - ETA: 13:02 - loss: na - ETA: 12:59 - loss: na - ETA: 12:54 - loss: na - ETA: 12:51 - loss: na - ETA: 12:47 - loss: na - ETA: 12:43 - loss: na - ETA: 12:39 - loss: na - ETA: 12:35 - loss: na - ETA: 12:32 - loss: na - ETA: 12:28 - loss: na - ETA: 12:24 - loss: na - ETA: 12:21 - loss: na - ETA: 12:17 - loss: na - ETA: 12:13 - loss: na - ETA: 12:09 - loss: na - ETA: 12:05 - loss: na - ETA: 12:02 - loss: na - ETA: 11:58 - loss: na - ETA: 11:54 - loss: na - ETA: 11:51 - loss: na - ETA: 11:47 - loss: na - ETA: 11:43 - loss: na - ETA: 11:39 - loss: na - ETA: 11:35 - loss: na - ETA: 11:31 - loss: na - ETA: 11:28 - loss: na - ETA: 11:24 - loss: na - ETA: 11:20 - loss: na - ETA: 11:16 - loss: na - ETA: 11:12 - loss: na - ETA: 11:09 - loss: na - ETA: 11:05 - loss: na - ETA: 11:01 - loss: na - ETA: 10:58 - loss: na - ETA: 10:54 - loss: na - ETA: 10:50 - loss: na - ETA: 10:46 - loss: na - ETA: 10:42 - loss: na - ETA: 10:39 - loss: na - ETA: 10:35 - loss: na - ETA: 10:31 - loss: na - ETA: 10:28 - loss: na - ETA: 10:24 - loss: na - ETA: 10:20 - loss: na - ETA: 10:16 - loss: na - ETA: 10:12 - loss: na - ETA: 10:08 - loss: na - ETA: 10:04 - loss: na - ETA: 10:01 - loss: na - ETA: 9:57 - loss: na - ETA: 9:53 - loss: n - ETA: 9:50 - loss: n - ETA: 9:46 - loss: n - ETA: 9:42 - loss: n - ETA: 9:38 - loss: n - ETA: 9:35 - loss: n - ETA: 9:31 - loss: n - ETA: 9:27 - loss: n - ETA: 9:23 - loss: n - ETA: 9:20 - loss: n - ETA: 9:16 - loss: n - ETA: 9:12 - loss: n - ETA: 9:08 - loss: n - ETA: 9:05 - loss: n - ETA: 9:01 - loss: n - ETA: 8:57 - loss: n - ETA: 8:54 - loss: n - ETA: 8:50 - loss: n - ETA: 8:46 - loss: n - ETA: 8:42 - loss: n - ETA: 8:39 - loss: n - ETA: 8:35 - loss: n - ETA: 8:31 - loss: n - ETA: 8:27 - loss: n - ETA: 8:24 - loss: n - ETA: 8:20 - loss: n - ETA: 8:16 - loss: n - ETA: 8:12 - loss: n - ETA: 8:09 - loss: n - ETA: 8:05 - loss: n - ETA: 8:01 - loss: n - ETA: 7:57 - loss: n - ETA: 7:54 - loss: n - ETA: 7:50 - loss: n - ETA: 7:46 - loss: n - ETA: 7:43 - loss: n - ETA: 7:39 - loss: n - ETA: 7:35 - loss: n - ETA: 7:32 - loss: n - ETA: 7:28 - loss: n - ETA: 7:24 - loss: n - ETA: 7:20 - loss: n - ETA: 7:17 - loss: n - ETA: 7:13 - loss: n - ETA: 7:09 - loss: n - ETA: 7:05 - loss: n - ETA: 7:02 - loss: n - ETA: 6:58 - loss: n - ETA: 6:54 - loss: n - ETA: 6:51 - loss: n - ETA: 6:47 - loss: n - ETA: 6:43 - loss: n - ETA: 6:40 - loss: n - ETA: 6:36 - loss: n - ETA: 6:32 - loss: n - ETA: 6:28 - loss: n - ETA: 6:25 - loss: n - ETA: 6:21 - loss: n - ETA: 6:17 - loss: n - ETA: 6:13 - loss: n - ETA: 6:10 - loss: n - ETA: 6:06 - loss: n - ETA: 6:02 - loss: n - ETA: 5:59 - loss: n - ETA: 5:55 - loss: n - ETA: 5:51 - loss: n - ETA: 5:47 - loss: n - ETA: 5:44 - loss: n - ETA: 5:40 - loss: n - ETA: 5:36 - loss: n - ETA: 5:32 - loss: n - ETA: 5:29 - loss: n - ETA: 5:25 - loss: n - ETA: 5:21 - loss: n - ETA: 5:17 - loss: n - ETA: 5:14 - loss: n - ETA: 5:10 - loss: n - ETA: 5:06 - loss: n - ETA: 5:03 - loss: n - ETA: 4:59 - loss: n - ETA: 4:55 - loss: n - ETA: 4:52 - loss: n - ETA: 4:48 - loss: n - ETA: 4:44 - loss: n - ETA: 4:40 - loss: n - ETA: 4:37 - loss: n - ETA: 4:33 - loss: n - ETA: 4:29 - loss: n - ETA: 4:26 - loss: n - ETA: 4:22 - loss: n - ETA: 4:18 - loss: n - ETA: 4:14 - loss: n - ETA: 4:11 - loss: n - ETA: 4:07 - loss: n - ETA: 4:03 - loss: n - ETA: 3:59 - loss: n - ETA: 3:56 - loss: n - ETA: 3:52 - loss: n - ETA: 3:48 - loss: n - ETA: 3:45 - loss: n - ETA: 3:41 - loss: n - ETA: 3:37 - loss: n - ETA: 3:33 - loss: n - ETA: 3:30 - loss: n - ETA: 3:26 - loss: n - ETA: 3:22 - loss: n - ETA: 3:18 - loss: n - ETA: 3:15 - loss: n - ETA: 3:11 - loss: n - ETA: 3:07 - loss: n - ETA: 3:04 - loss: n - ETA: 3:00 - loss: n - ETA: 2:56 - loss: n - ETA: 2:53 - loss: n - ETA: 2:49 - loss: n - ETA: 2:45 - loss: n - ETA: 2:41 - loss: n - ETA: 2:38 - loss: n - ETA: 2:34 - loss: n - ETA: 2:30 - loss: n - ETA: 2:27 - loss: n - ETA: 2:23 - loss: n - ETA: 2:19 - loss: n - ETA: 2:15 - loss: n - ETA: 2:12 - loss: n - ETA: 2:08 - loss: n - ETA: 2:04 - loss: n - ETA: 2:00 - loss: n - ETA: 1:57 - loss: n - ETA: 1:53 - loss: n - ETA: 1:49 - loss: n - ETA: 1:46 - loss: n - ETA: 1:42 - loss: n - ETA: 1:38 - loss: n - ETA: 1:34 - loss: n - ETA: 1:31 - loss: n - ETA: 1:27 - loss: n - ETA: 1:23 - loss: n - ETA: 1:20 - loss: n - ETA: 1:16 - loss: n - ETA: 1:12 - loss: n - ETA: 1:08 - loss: n - ETA: 1:05 - loss: n - ETA: 1:01 - loss: n - ETA: 57s - loss: nan - ETA: 53s - loss: na - ETA: 50s - loss: na - ETA: 46s - loss: na - ETA: 42s - loss: na - ETA: 39s - loss: na - ETA: 35s - loss: na - ETA: 31s - loss: na - ETA: 27s - loss: na - ETA: 24s - loss: na - ETA: 20s - loss: na - ETA: 16s - loss: na - ETA: 13s - loss: na - ETA: 9s - loss: na - ETA: 5s - loss: n - ETA: 1s - loss: n - 1172s 29ms/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00001: val_loss did not improve from inf\n",
      "log loss: nan\n",
      "FOLD |  3\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - ETA: 33:30 - loss: na - ETA: 26:23 - loss: na - ETA: 24:01 - loss: na - ETA: 22:36 - loss: na - ETA: 21:58 - loss: na - ETA: 21:30 - loss: na - ETA: 21:09 - loss: na - ETA: 20:52 - loss: na - ETA: 20:34 - loss: na - ETA: 20:23 - loss: na - ETA: 20:14 - loss: na - ETA: 20:05 - loss: na - ETA: 19:56 - loss: na - ETA: 19:44 - loss: na - ETA: 19:36 - loss: na - ETA: 19:27 - loss: na - ETA: 19:19 - loss: na - ETA: 19:13 - loss: na - ETA: 19:05 - loss: na - ETA: 19:01 - loss: na - ETA: 18:58 - loss: na - ETA: 18:51 - loss: na - ETA: 18:44 - loss: na - ETA: 18:39 - loss: na - ETA: 18:36 - loss: na - ETA: 18:30 - loss: na - ETA: 18:24 - loss: na - ETA: 18:19 - loss: na - ETA: 18:13 - loss: na - ETA: 18:08 - loss: na - ETA: 18:04 - loss: na - ETA: 17:59 - loss: na - ETA: 17:54 - loss: na - ETA: 17:48 - loss: na - ETA: 17:44 - loss: na - ETA: 17:40 - loss: na - ETA: 17:35 - loss: na - ETA: 17:30 - loss: na - ETA: 17:25 - loss: na - ETA: 17:21 - loss: na - ETA: 17:17 - loss: na - ETA: 17:13 - loss: na - ETA: 17:08 - loss: na - ETA: 17:04 - loss: na - ETA: 17:00 - loss: na - ETA: 16:56 - loss: na - ETA: 16:51 - loss: na - ETA: 16:47 - loss: na - ETA: 16:42 - loss: na - ETA: 16:37 - loss: na - ETA: 16:33 - loss: na - ETA: 16:29 - loss: na - ETA: 16:24 - loss: na - ETA: 16:20 - loss: na - ETA: 16:16 - loss: na - ETA: 16:12 - loss: na - ETA: 16:07 - loss: na - ETA: 16:03 - loss: na - ETA: 15:59 - loss: na - ETA: 15:55 - loss: na - ETA: 15:51 - loss: na - ETA: 15:48 - loss: na - ETA: 15:43 - loss: na - ETA: 15:39 - loss: na - ETA: 15:35 - loss: na - ETA: 15:31 - loss: na - ETA: 15:27 - loss: na - ETA: 15:23 - loss: na - ETA: 15:19 - loss: na - ETA: 15:15 - loss: na - ETA: 15:11 - loss: na - ETA: 15:07 - loss: na - ETA: 15:03 - loss: na - ETA: 14:59 - loss: na - ETA: 14:55 - loss: na - ETA: 14:51 - loss: na - ETA: 14:48 - loss: na - ETA: 14:44 - loss: na - ETA: 14:40 - loss: na - ETA: 14:37 - loss: na - ETA: 14:33 - loss: na - ETA: 14:30 - loss: na - ETA: 14:25 - loss: na - ETA: 14:21 - loss: na - ETA: 14:17 - loss: na - ETA: 14:13 - loss: na - ETA: 14:10 - loss: na - ETA: 14:06 - loss: na - ETA: 14:02 - loss: na - ETA: 13:58 - loss: na - ETA: 13:54 - loss: na - ETA: 13:51 - loss: na - ETA: 13:47 - loss: na - ETA: 13:43 - loss: na - ETA: 13:39 - loss: na - ETA: 13:35 - loss: na - ETA: 13:31 - loss: na - ETA: 13:27 - loss: na - ETA: 13:24 - loss: na - ETA: 13:20 - loss: na - ETA: 13:16 - loss: na - ETA: 13:12 - loss: na - ETA: 13:08 - loss: na - ETA: 13:05 - loss: na - ETA: 13:01 - loss: na - ETA: 12:57 - loss: na - ETA: 12:53 - loss: na - ETA: 12:49 - loss: na - ETA: 12:45 - loss: na - ETA: 12:41 - loss: na - ETA: 12:38 - loss: na - ETA: 12:34 - loss: na - ETA: 12:31 - loss: na - ETA: 12:27 - loss: na - ETA: 12:23 - loss: na - ETA: 12:19 - loss: na - ETA: 12:15 - loss: na - ETA: 12:11 - loss: na - ETA: 12:07 - loss: na - ETA: 12:03 - loss: na - ETA: 12:00 - loss: na - ETA: 11:56 - loss: na - ETA: 11:52 - loss: na - ETA: 11:48 - loss: na - ETA: 11:45 - loss: na - ETA: 11:41 - loss: na - ETA: 11:37 - loss: na - ETA: 11:33 - loss: na - ETA: 11:29 - loss: na - ETA: 11:25 - loss: na - ETA: 11:22 - loss: na - ETA: 11:18 - loss: na - ETA: 11:14 - loss: na - ETA: 11:10 - loss: na - ETA: 11:06 - loss: na - ETA: 11:03 - loss: na - ETA: 10:59 - loss: na - ETA: 10:55 - loss: na - ETA: 10:51 - loss: na - ETA: 10:48 - loss: na - ETA: 10:44 - loss: na - ETA: 10:40 - loss: na - ETA: 10:36 - loss: na - ETA: 10:33 - loss: na - ETA: 10:29 - loss: na - ETA: 10:25 - loss: na - ETA: 10:22 - loss: na - ETA: 10:18 - loss: na - ETA: 10:14 - loss: na - ETA: 10:10 - loss: na - ETA: 10:07 - loss: na - ETA: 10:03 - loss: na - ETA: 9:59 - loss: na - ETA: 9:55 - loss: n - ETA: 9:51 - loss: n - ETA: 9:48 - loss: n - ETA: 9:44 - loss: n - ETA: 9:40 - loss: n - ETA: 9:36 - loss: n - ETA: 9:33 - loss: n - ETA: 9:29 - loss: n - ETA: 9:25 - loss: n - ETA: 9:21 - loss: n - ETA: 9:18 - loss: n - ETA: 9:14 - loss: n - ETA: 9:10 - loss: n - ETA: 9:06 - loss: n - ETA: 9:02 - loss: n - ETA: 8:59 - loss: n - ETA: 8:55 - loss: n - ETA: 8:51 - loss: n - ETA: 8:47 - loss: n - ETA: 8:44 - loss: n - ETA: 8:40 - loss: n - ETA: 8:36 - loss: n - ETA: 8:32 - loss: n - ETA: 8:29 - loss: n - ETA: 8:25 - loss: n - ETA: 8:21 - loss: n - ETA: 8:17 - loss: n - ETA: 8:13 - loss: n - ETA: 8:10 - loss: n - ETA: 8:06 - loss: n - ETA: 8:02 - loss: n - ETA: 7:58 - loss: n - ETA: 7:55 - loss: n - ETA: 7:51 - loss: n - ETA: 7:47 - loss: n - ETA: 7:43 - loss: n - ETA: 7:39 - loss: n - ETA: 7:36 - loss: n - ETA: 7:32 - loss: n - ETA: 7:28 - loss: n - ETA: 7:25 - loss: n - ETA: 7:21 - loss: n - ETA: 7:17 - loss: n - ETA: 7:13 - loss: n - ETA: 7:10 - loss: n - ETA: 7:06 - loss: n - ETA: 7:02 - loss: n - ETA: 6:58 - loss: n - ETA: 6:55 - loss: n - ETA: 6:51 - loss: n - ETA: 6:47 - loss: n - ETA: 6:43 - loss: n - ETA: 6:40 - loss: n - ETA: 6:36 - loss: n - ETA: 6:32 - loss: n - ETA: 6:28 - loss: n - ETA: 6:25 - loss: n - ETA: 6:21 - loss: n - ETA: 6:17 - loss: n - ETA: 6:13 - loss: n - ETA: 6:10 - loss: n - ETA: 6:06 - loss: n - ETA: 6:02 - loss: n - ETA: 5:58 - loss: n - ETA: 5:55 - loss: n - ETA: 5:51 - loss: n - ETA: 5:47 - loss: n - ETA: 5:43 - loss: n - ETA: 5:39 - loss: n - ETA: 5:36 - loss: n - ETA: 5:32 - loss: n - ETA: 5:28 - loss: n - ETA: 5:25 - loss: n - ETA: 5:21 - loss: n - ETA: 5:17 - loss: n - ETA: 5:13 - loss: n - ETA: 5:10 - loss: n - ETA: 5:06 - loss: n - ETA: 5:02 - loss: n - ETA: 4:59 - loss: n - ETA: 4:55 - loss: n - ETA: 4:51 - loss: n - ETA: 4:47 - loss: n - ETA: 4:43 - loss: n - ETA: 4:40 - loss: n - ETA: 4:36 - loss: n - ETA: 4:32 - loss: n - ETA: 4:28 - loss: n - ETA: 4:25 - loss: n - ETA: 4:21 - loss: n - ETA: 4:17 - loss: n - ETA: 4:13 - loss: n - ETA: 4:10 - loss: n - ETA: 4:06 - loss: n - ETA: 4:02 - loss: n - ETA: 3:58 - loss: n - ETA: 3:55 - loss: n - ETA: 3:51 - loss: n - ETA: 3:47 - loss: n - ETA: 3:43 - loss: n - ETA: 3:40 - loss: n - ETA: 3:36 - loss: n - ETA: 3:32 - loss: n - ETA: 3:28 - loss: n - ETA: 3:25 - loss: n - ETA: 3:21 - loss: n - ETA: 3:17 - loss: n - ETA: 3:13 - loss: n - ETA: 3:10 - loss: n - ETA: 3:06 - loss: n - ETA: 3:02 - loss: n - ETA: 2:58 - loss: n - ETA: 2:55 - loss: n - ETA: 2:51 - loss: n - ETA: 2:47 - loss: n - ETA: 2:43 - loss: n - ETA: 2:40 - loss: n - ETA: 2:36 - loss: n - ETA: 2:32 - loss: n - ETA: 2:28 - loss: n - ETA: 2:25 - loss: n - ETA: 2:21 - loss: n - ETA: 2:17 - loss: n - ETA: 2:13 - loss: n - ETA: 2:10 - loss: n - ETA: 2:06 - loss: n - ETA: 2:02 - loss: n - ETA: 1:58 - loss: n - ETA: 1:54 - loss: n - ETA: 1:51 - loss: n - ETA: 1:47 - loss: n - ETA: 1:43 - loss: n - ETA: 1:39 - loss: n - ETA: 1:36 - loss: n - ETA: 1:32 - loss: n - ETA: 1:28 - loss: n - ETA: 1:24 - loss: n - ETA: 1:21 - loss: n - ETA: 1:17 - loss: n - ETA: 1:13 - loss: n - ETA: 1:09 - loss: n - ETA: 1:06 - loss: n - ETA: 1:02 - loss: n - ETA: 58s - loss: nan - ETA: 54s - loss: na - ETA: 50s - loss: na - ETA: 47s - loss: na - ETA: 43s - loss: na - ETA: 39s - loss: na - ETA: 35s - loss: na - ETA: 32s - loss: na - ETA: 28s - loss: na - ETA: 24s - loss: na - ETA: 20s - loss: na - ETA: 16s - loss: na - ETA: 13s - loss: na - ETA: 9s - loss: na - ETA: 5s - loss: n - ETA: 1s - loss: n - 1190s 30ms/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00001: val_loss did not improve from inf\n",
      "log loss: nan\n",
      "FOLD |  4\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - ETA: 32:47 - loss: na - ETA: 26:16 - loss: na - ETA: 23:57 - loss: na - ETA: 22:43 - loss: na - ETA: 21:59 - loss: na - ETA: 21:31 - loss: na - ETA: 21:05 - loss: na - ETA: 20:44 - loss: na - ETA: 20:29 - loss: na - ETA: 20:14 - loss: na - ETA: 20:05 - loss: na - ETA: 19:56 - loss: na - ETA: 19:47 - loss: na - ETA: 19:37 - loss: na - ETA: 19:25 - loss: na - ETA: 19:17 - loss: na - ETA: 19:11 - loss: na - ETA: 19:04 - loss: na - ETA: 18:58 - loss: na - ETA: 18:52 - loss: na - ETA: 18:45 - loss: na - ETA: 18:39 - loss: na - ETA: 18:33 - loss: na - ETA: 18:28 - loss: na - ETA: 18:22 - loss: na - ETA: 18:20 - loss: na - ETA: 18:14 - loss: na - ETA: 18:08 - loss: na - ETA: 18:04 - loss: na - ETA: 17:58 - loss: na - ETA: 17:56 - loss: na - ETA: 17:52 - loss: na - ETA: 17:49 - loss: na - ETA: 17:45 - loss: na - ETA: 17:41 - loss: na - ETA: 17:39 - loss: na - ETA: 17:36 - loss: na - ETA: 17:32 - loss: na - ETA: 17:29 - loss: na - ETA: 17:26 - loss: na - ETA: 17:22 - loss: na - ETA: 17:19 - loss: na - ETA: 17:16 - loss: na - ETA: 17:13 - loss: na - ETA: 17:09 - loss: na - ETA: 17:06 - loss: na - ETA: 17:02 - loss: na - ETA: 16:58 - loss: na - ETA: 16:55 - loss: na - ETA: 16:52 - loss: na - ETA: 16:48 - loss: na - ETA: 16:44 - loss: na - ETA: 16:39 - loss: na - ETA: 16:35 - loss: na - ETA: 16:31 - loss: na - ETA: 16:27 - loss: na - ETA: 16:23 - loss: na - ETA: 16:19 - loss: na - ETA: 16:17 - loss: na - ETA: 16:12 - loss: na - ETA: 16:09 - loss: na - ETA: 16:06 - loss: na - ETA: 16:02 - loss: na - ETA: 15:58 - loss: na - ETA: 15:53 - loss: na - ETA: 15:49 - loss: na - ETA: 15:45 - loss: na - ETA: 15:40 - loss: na - ETA: 15:36 - loss: na - ETA: 15:32 - loss: na - ETA: 15:28 - loss: na - ETA: 15:23 - loss: na - ETA: 15:19 - loss: na - ETA: 15:15 - loss: na - ETA: 15:11 - loss: na - ETA: 15:08 - loss: na - ETA: 15:04 - loss: na - ETA: 15:00 - loss: na - ETA: 14:56 - loss: na - ETA: 14:52 - loss: na - ETA: 14:48 - loss: na - ETA: 14:43 - loss: na - ETA: 14:38 - loss: na - ETA: 14:34 - loss: na - ETA: 14:30 - loss: na - ETA: 14:26 - loss: na - ETA: 14:22 - loss: na - ETA: 14:18 - loss: na - ETA: 14:14 - loss: na - ETA: 14:10 - loss: na - ETA: 14:06 - loss: na - ETA: 14:02 - loss: na - ETA: 13:58 - loss: na - ETA: 13:54 - loss: na - ETA: 13:50 - loss: na - ETA: 13:46 - loss: na - ETA: 13:42 - loss: na - ETA: 13:38 - loss: na - ETA: 13:34 - loss: na - ETA: 13:30 - loss: na - ETA: 13:26 - loss: na - ETA: 13:22 - loss: na - ETA: 13:18 - loss: na - ETA: 13:14 - loss: na - ETA: 13:10 - loss: na - ETA: 13:07 - loss: na - ETA: 13:03 - loss: na - ETA: 12:59 - loss: na - ETA: 12:55 - loss: na - ETA: 12:52 - loss: na - ETA: 12:48 - loss: na - ETA: 12:45 - loss: na - ETA: 12:41 - loss: na - ETA: 12:38 - loss: na - ETA: 12:34 - loss: na - ETA: 12:31 - loss: na - ETA: 12:27 - loss: na - ETA: 12:24 - loss: na - ETA: 12:20 - loss: na - ETA: 12:16 - loss: na - ETA: 12:12 - loss: na - ETA: 12:08 - loss: na - ETA: 12:04 - loss: na - ETA: 12:00 - loss: na - ETA: 11:56 - loss: na - ETA: 11:52 - loss: na - ETA: 11:48 - loss: na - ETA: 11:44 - loss: na - ETA: 11:40 - loss: na - ETA: 11:36 - loss: na - ETA: 11:33 - loss: na - ETA: 11:29 - loss: na - ETA: 11:25 - loss: na - ETA: 11:21 - loss: na - ETA: 11:17 - loss: na - ETA: 11:13 - loss: na - ETA: 11:09 - loss: na - ETA: 11:05 - loss: na - ETA: 11:01 - loss: na - ETA: 10:57 - loss: na - ETA: 10:54 - loss: na - ETA: 10:50 - loss: na - ETA: 10:46 - loss: na - ETA: 10:42 - loss: na - ETA: 10:38 - loss: na - ETA: 10:34 - loss: na - ETA: 10:30 - loss: na - ETA: 10:26 - loss: na - ETA: 10:22 - loss: na - ETA: 10:19 - loss: na - ETA: 10:15 - loss: na - ETA: 10:11 - loss: na - ETA: 10:07 - loss: na - ETA: 10:03 - loss: na - ETA: 9:59 - loss: na - ETA: 9:55 - loss: n - ETA: 9:51 - loss: n - ETA: 9:47 - loss: n - ETA: 9:43 - loss: n - ETA: 9:40 - loss: n - ETA: 9:36 - loss: n - ETA: 9:32 - loss: n - ETA: 9:28 - loss: n - ETA: 9:24 - loss: n - ETA: 9:20 - loss: n - ETA: 9:16 - loss: n - ETA: 9:12 - loss: n - ETA: 9:08 - loss: n - ETA: 9:04 - loss: n - ETA: 9:00 - loss: n - ETA: 8:56 - loss: n - ETA: 8:53 - loss: n - ETA: 8:49 - loss: n - ETA: 8:45 - loss: n - ETA: 8:41 - loss: n - ETA: 8:37 - loss: n - ETA: 8:33 - loss: n - ETA: 8:29 - loss: n - ETA: 8:25 - loss: n - ETA: 8:22 - loss: n - ETA: 8:18 - loss: n - ETA: 8:14 - loss: n - ETA: 8:10 - loss: n - ETA: 8:06 - loss: n - ETA: 8:02 - loss: n - ETA: 7:58 - loss: n - ETA: 7:55 - loss: n - ETA: 7:51 - loss: n - ETA: 7:47 - loss: n - ETA: 7:43 - loss: n - ETA: 7:39 - loss: n - ETA: 7:36 - loss: n - ETA: 7:32 - loss: n - ETA: 7:28 - loss: n - ETA: 7:24 - loss: n - ETA: 7:20 - loss: n - ETA: 7:16 - loss: n - ETA: 7:13 - loss: n - ETA: 7:09 - loss: n - ETA: 7:05 - loss: n - ETA: 7:01 - loss: n - ETA: 6:57 - loss: n - ETA: 6:54 - loss: n - ETA: 6:50 - loss: n - ETA: 6:46 - loss: n - ETA: 6:42 - loss: n - ETA: 6:38 - loss: n - ETA: 6:34 - loss: n - ETA: 6:31 - loss: n - ETA: 6:27 - loss: n - ETA: 6:23 - loss: n - ETA: 6:19 - loss: n - ETA: 6:15 - loss: n - ETA: 6:12 - loss: n - ETA: 6:08 - loss: n - ETA: 6:04 - loss: n - ETA: 6:00 - loss: n - ETA: 5:56 - loss: n - ETA: 5:53 - loss: n - ETA: 5:49 - loss: n - ETA: 5:45 - loss: n - ETA: 5:41 - loss: n - ETA: 5:37 - loss: n - ETA: 5:34 - loss: n - ETA: 5:30 - loss: n - ETA: 5:26 - loss: n - ETA: 5:22 - loss: n - ETA: 5:18 - loss: n - ETA: 5:14 - loss: n - ETA: 5:11 - loss: n - ETA: 5:07 - loss: n - ETA: 5:03 - loss: n - ETA: 4:59 - loss: n - ETA: 4:56 - loss: n - ETA: 4:52 - loss: n - ETA: 4:48 - loss: n - ETA: 4:44 - loss: n - ETA: 4:40 - loss: n - ETA: 4:37 - loss: n - ETA: 4:33 - loss: n - ETA: 4:29 - loss: n - ETA: 4:25 - loss: n - ETA: 4:21 - loss: n - ETA: 4:18 - loss: n - ETA: 4:14 - loss: n - ETA: 4:10 - loss: n - ETA: 4:06 - loss: n - ETA: 4:03 - loss: n - ETA: 3:59 - loss: n - ETA: 3:55 - loss: n - ETA: 3:51 - loss: n - ETA: 3:48 - loss: n - ETA: 3:44 - loss: n - ETA: 3:40 - loss: n - ETA: 3:36 - loss: n - ETA: 3:33 - loss: n - ETA: 3:29 - loss: n - ETA: 3:25 - loss: n - ETA: 3:21 - loss: n - ETA: 3:18 - loss: n - ETA: 3:14 - loss: n - ETA: 3:10 - loss: n - ETA: 3:06 - loss: n - ETA: 3:02 - loss: n - ETA: 2:59 - loss: n - ETA: 2:55 - loss: n - ETA: 2:51 - loss: n - ETA: 2:47 - loss: n - ETA: 2:44 - loss: n - ETA: 2:40 - loss: n - ETA: 2:36 - loss: n - ETA: 2:32 - loss: n - ETA: 2:29 - loss: n - ETA: 2:25 - loss: n - ETA: 2:21 - loss: n - ETA: 2:17 - loss: n - ETA: 2:13 - loss: n - ETA: 2:10 - loss: n - ETA: 2:06 - loss: n - ETA: 2:02 - loss: n - ETA: 1:58 - loss: n - ETA: 1:55 - loss: n - ETA: 1:51 - loss: n - ETA: 1:47 - loss: n - ETA: 1:43 - loss: n - ETA: 1:39 - loss: n - ETA: 1:36 - loss: n - ETA: 1:32 - loss: n - ETA: 1:28 - loss: n - ETA: 1:24 - loss: n - ETA: 1:21 - loss: n - ETA: 1:17 - loss: n - ETA: 1:13 - loss: n - ETA: 1:09 - loss: n - ETA: 1:06 - loss: n - ETA: 1:02 - loss: n - ETA: 58s - loss: nan - ETA: 54s - loss: na - ETA: 50s - loss: na - ETA: 47s - loss: na - ETA: 43s - loss: na - ETA: 39s - loss: na - ETA: 35s - loss: na - ETA: 32s - loss: na - ETA: 28s - loss: na - ETA: 24s - loss: na - ETA: 20s - loss: na - ETA: 16s - loss: na - ETA: 13s - loss: na - ETA: 9s - loss: na - ETA: 5s - loss: n - ETA: 1s - loss: n - 1190s 30ms/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00001: val_loss did not improve from inf\n",
      "log loss: nan\n",
      "FOLD |  5\n",
      "Train on 40001 samples, validate on 9999 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40001/40001 [==============================] - ETA: 33:08 - loss: na - ETA: 26:05 - loss: na - ETA: 23:53 - loss: na - ETA: 22:42 - loss: na - ETA: 22:10 - loss: na - ETA: 21:45 - loss: na - ETA: 21:25 - loss: na - ETA: 21:07 - loss: na - ETA: 20:51 - loss: na - ETA: 20:38 - loss: na - ETA: 20:25 - loss: na - ETA: 20:14 - loss: na - ETA: 20:03 - loss: na - ETA: 19:53 - loss: na - ETA: 19:47 - loss: na - ETA: 19:36 - loss: na - ETA: 19:27 - loss: na - ETA: 19:20 - loss: na - ETA: 19:13 - loss: na - ETA: 19:07 - loss: na - ETA: 19:00 - loss: na - ETA: 18:54 - loss: na - ETA: 18:50 - loss: na - ETA: 18:44 - loss: na - ETA: 18:38 - loss: na - ETA: 18:31 - loss: na - ETA: 18:27 - loss: na - ETA: 18:22 - loss: na - ETA: 18:18 - loss: na - ETA: 18:14 - loss: na - ETA: 18:11 - loss: na - ETA: 18:08 - loss: na - ETA: 18:05 - loss: na - ETA: 18:02 - loss: na - ETA: 17:58 - loss: na - ETA: 17:54 - loss: na - ETA: 17:50 - loss: na - ETA: 17:46 - loss: na - ETA: 17:41 - loss: na - ETA: 17:38 - loss: na - ETA: 17:33 - loss: na - ETA: 17:29 - loss: na - ETA: 17:25 - loss: na - ETA: 17:21 - loss: na - ETA: 17:16 - loss: na - ETA: 17:10 - loss: na - ETA: 17:06 - loss: na - ETA: 17:02 - loss: na - ETA: 16:56 - loss: na - ETA: 16:52 - loss: na - ETA: 16:48 - loss: na - ETA: 16:43 - loss: na - ETA: 16:39 - loss: na - ETA: 16:35 - loss: na - ETA: 16:31 - loss: na - ETA: 16:27 - loss: na - ETA: 16:24 - loss: na - ETA: 16:20 - loss: na - ETA: 16:16 - loss: na - ETA: 16:12 - loss: na - ETA: 16:08 - loss: na - ETA: 16:04 - loss: na - ETA: 15:59 - loss: na - ETA: 15:55 - loss: na - ETA: 15:51 - loss: na - ETA: 15:47 - loss: na - ETA: 15:43 - loss: na - ETA: 15:39 - loss: na - ETA: 15:34 - loss: na - ETA: 15:30 - loss: na - ETA: 15:26 - loss: na - ETA: 15:21 - loss: na - ETA: 15:16 - loss: na - ETA: 15:12 - loss: na - ETA: 15:08 - loss: na - ETA: 15:04 - loss: na - ETA: 14:59 - loss: na - ETA: 14:55 - loss: na - ETA: 14:51 - loss: na - ETA: 14:47 - loss: na - ETA: 14:43 - loss: na - ETA: 14:38 - loss: na - ETA: 14:35 - loss: na - ETA: 14:31 - loss: na - ETA: 14:27 - loss: na - ETA: 14:23 - loss: na - ETA: 14:19 - loss: na - ETA: 14:14 - loss: na - ETA: 14:10 - loss: na - ETA: 14:07 - loss: na - ETA: 14:02 - loss: na - ETA: 13:58 - loss: na - ETA: 13:54 - loss: na - ETA: 13:50 - loss: na - ETA: 13:46 - loss: na - ETA: 13:42 - loss: na - ETA: 13:38 - loss: na - ETA: 13:34 - loss: na - ETA: 13:30 - loss: na - ETA: 13:26 - loss: na - ETA: 13:22 - loss: na - ETA: 13:19 - loss: na - ETA: 13:15 - loss: na - ETA: 13:11 - loss: na - ETA: 13:07 - loss: na - ETA: 13:03 - loss: na - ETA: 12:59 - loss: na - ETA: 12:55 - loss: na - ETA: 12:52 - loss: na - ETA: 12:48 - loss: na - ETA: 12:44 - loss: na - ETA: 12:40 - loss: na - ETA: 12:36 - loss: na - ETA: 12:33 - loss: na - ETA: 12:29 - loss: na - ETA: 12:25 - loss: na - ETA: 12:21 - loss: na - ETA: 12:17 - loss: na - ETA: 12:13 - loss: na - ETA: 12:09 - loss: na - ETA: 12:05 - loss: na - ETA: 12:02 - loss: na - ETA: 11:58 - loss: na - ETA: 11:54 - loss: na - ETA: 11:50 - loss: na - ETA: 11:46 - loss: na - ETA: 11:42 - loss: na - ETA: 11:39 - loss: na - ETA: 11:35 - loss: na - ETA: 11:31 - loss: na - ETA: 11:27 - loss: na - ETA: 11:23 - loss: na - ETA: 11:19 - loss: na - ETA: 11:16 - loss: na - ETA: 11:12 - loss: na - ETA: 11:08 - loss: na - ETA: 11:04 - loss: na - ETA: 11:00 - loss: na - ETA: 10:56 - loss: na - ETA: 10:52 - loss: na - ETA: 10:48 - loss: na - ETA: 10:44 - loss: na - ETA: 10:41 - loss: na - ETA: 10:37 - loss: na - ETA: 10:33 - loss: na - ETA: 10:29 - loss: na - ETA: 10:25 - loss: na - ETA: 10:21 - loss: na - ETA: 10:18 - loss: na - ETA: 10:14 - loss: na - ETA: 10:10 - loss: na - ETA: 10:07 - loss: na - ETA: 10:03 - loss: na - ETA: 9:59 - loss: na - ETA: 9:56 - loss: n - ETA: 9:52 - loss: n - ETA: 9:48 - loss: n - ETA: 9:45 - loss: n - ETA: 9:41 - loss: n - ETA: 9:37 - loss: n - ETA: 9:34 - loss: n - ETA: 9:30 - loss: n - ETA: 9:26 - loss: n - ETA: 9:22 - loss: n - ETA: 9:19 - loss: n - ETA: 9:15 - loss: n - ETA: 9:11 - loss: n - ETA: 9:07 - loss: n - ETA: 9:04 - loss: n - ETA: 9:00 - loss: n - ETA: 8:56 - loss: n - ETA: 8:53 - loss: n - ETA: 8:49 - loss: n - ETA: 8:45 - loss: n - ETA: 8:41 - loss: n - ETA: 8:37 - loss: n - ETA: 8:34 - loss: n - ETA: 8:30 - loss: n - ETA: 8:26 - loss: n - ETA: 8:22 - loss: n - ETA: 8:18 - loss: n - ETA: 8:14 - loss: n - ETA: 8:11 - loss: n - ETA: 8:07 - loss: n - ETA: 8:03 - loss: n - ETA: 7:59 - loss: n - ETA: 7:55 - loss: n - ETA: 7:52 - loss: n - ETA: 7:48 - loss: n - ETA: 7:44 - loss: n - ETA: 7:40 - loss: n - ETA: 7:37 - loss: n - ETA: 7:33 - loss: n - ETA: 7:29 - loss: n - ETA: 7:25 - loss: n - ETA: 7:21 - loss: n - ETA: 7:18 - loss: n - ETA: 7:14 - loss: n - ETA: 7:10 - loss: n - ETA: 7:06 - loss: n - ETA: 7:02 - loss: n - ETA: 6:58 - loss: n - ETA: 6:55 - loss: n - ETA: 6:51 - loss: n - ETA: 6:47 - loss: n - ETA: 6:43 - loss: n - ETA: 6:40 - loss: n - ETA: 6:36 - loss: n - ETA: 6:32 - loss: n - ETA: 6:29 - loss: n - ETA: 6:25 - loss: n - ETA: 6:21 - loss: n - ETA: 6:17 - loss: n - ETA: 6:13 - loss: n - ETA: 6:10 - loss: n - ETA: 6:06 - loss: n - ETA: 6:02 - loss: n - ETA: 5:58 - loss: n - ETA: 5:55 - loss: n - ETA: 5:51 - loss: n - ETA: 5:47 - loss: n - ETA: 5:43 - loss: n - ETA: 5:39 - loss: n - ETA: 5:36 - loss: n - ETA: 5:32 - loss: n - ETA: 5:28 - loss: n - ETA: 5:24 - loss: n - ETA: 5:20 - loss: n - ETA: 5:16 - loss: n - ETA: 5:13 - loss: n - ETA: 5:09 - loss: n - ETA: 5:05 - loss: n - ETA: 5:01 - loss: n - ETA: 4:58 - loss: n - ETA: 4:54 - loss: n - ETA: 4:50 - loss: n - ETA: 4:46 - loss: n - ETA: 4:42 - loss: n - ETA: 4:38 - loss: n - ETA: 4:35 - loss: n - ETA: 4:31 - loss: n - ETA: 4:27 - loss: n - ETA: 4:23 - loss: n - ETA: 4:19 - loss: n - ETA: 4:16 - loss: n - ETA: 4:12 - loss: n - ETA: 4:08 - loss: n - ETA: 4:04 - loss: n - ETA: 4:00 - loss: n - ETA: 3:57 - loss: n - ETA: 3:53 - loss: n - ETA: 3:49 - loss: n - ETA: 3:45 - loss: n - ETA: 3:41 - loss: n - ETA: 3:38 - loss: n - ETA: 3:34 - loss: n - ETA: 3:30 - loss: n - ETA: 3:26 - loss: n - ETA: 3:23 - loss: n - ETA: 3:19 - loss: n - ETA: 3:15 - loss: n - ETA: 3:11 - loss: n - ETA: 3:07 - loss: n - ETA: 3:04 - loss: n - ETA: 3:00 - loss: n - ETA: 2:56 - loss: n - ETA: 2:52 - loss: n - ETA: 2:48 - loss: n - ETA: 2:45 - loss: n - ETA: 2:41 - loss: n - ETA: 2:37 - loss: n - ETA: 2:33 - loss: n - ETA: 2:30 - loss: n - ETA: 2:26 - loss: n - ETA: 2:22 - loss: n - ETA: 2:18 - loss: n - ETA: 2:14 - loss: n - ETA: 2:11 - loss: n - ETA: 2:07 - loss: n - ETA: 2:03 - loss: n - ETA: 1:59 - loss: n - ETA: 1:55 - loss: n - ETA: 1:52 - loss: n - ETA: 1:48 - loss: n - ETA: 1:44 - loss: n - ETA: 1:40 - loss: n - ETA: 1:36 - loss: n - ETA: 1:33 - loss: n - ETA: 1:29 - loss: n - ETA: 1:25 - loss: n - ETA: 1:21 - loss: n - ETA: 1:17 - loss: n - ETA: 1:14 - loss: n - ETA: 1:10 - loss: n - ETA: 1:06 - loss: n - ETA: 1:02 - loss: n - ETA: 58s - loss: nan - ETA: 55s - loss: na - ETA: 51s - loss: na - ETA: 47s - loss: na - ETA: 43s - loss: na - ETA: 39s - loss: na - ETA: 36s - loss: na - ETA: 32s - loss: na - ETA: 28s - loss: na - ETA: 24s - loss: na - ETA: 20s - loss: na - ETA: 17s - loss: na - ETA: 13s - loss: na - ETA: 9s - loss: na - ETA: 5s - loss: n - ETA: 1s - loss: n - 1195s 30ms/step - loss: nan - val_loss: nan\n",
      "\n",
      "Epoch 00001: val_loss did not improve from inf\n",
      "log loss: nan\n"
     ]
    }
   ],
   "source": [
    "# 训练模型，预测性别\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=20, shuffle=True)\n",
    "\n",
    "text_sex = np.zeros((test.shape[0], ))\n",
    "train_sex = np.zeros((train.shape[0], 1))\n",
    "score = []\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(kfold.split(X_app, Y_sex)):\n",
    "    print(\"FOLD | \", i+1)\n",
    "    filepath = \"model/sex_weights_best_%d.h5\" % i\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.8, patience=2, min_lr=0.0001, verbose=0)\n",
    "    earlystopping = EarlyStopping(\n",
    "        monitor='val_loss', min_delta=0.0001, patience=6, verbose=1, mode='auto')\n",
    "    callbacks = [checkpoint, reduce_lr, earlystopping]\n",
    "    \n",
    "    model_sex = model_conv1D(embedding_matrix)\n",
    "    X_app_train = X_app[train_index]\n",
    "    x_app_valid = X_app[valid_index]\n",
    "    x_behave_train = X_behave[train_index]\n",
    "    x_behave_valid = X_behave[valid_index]\n",
    "    y_train = Y_sex[train_index]\n",
    "    y_valid = Y_sex[valid_index]    \n",
    "    hist = model_sex.fit([X_app_train, x_behave_train], y_train, batch_size=128, epochs=50, validation_data=([x_app_valid, x_behave_valid], y_valid),\n",
    "                         callbacks=callbacks, verbose=1, shuffle=True)   \n",
    "    if os.path.exists(filepath):\n",
    "        model_sex.load_weights(filepath)\n",
    "    else:\n",
    "        model_sex.save_weights(filepath)\n",
    "    text_sex += np.squeeze(model_sex.predict([X_app_test, X_behave_test]))/kfold.n_splits    \n",
    "    train_sex[valid_index] = model_sex.predict([x_app_valid, x_behave_valid])\n",
    "    score.append(np.min(hist.history['val_loss']))    \n",
    "    print('log loss:', np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理预测结果，预测结果是性别为 1 的概率，根据性别为 1 的概率计算性别为 0 的概率。\n",
    "text_sex = pd.DataFrame(text_sex, columns=['sex2'])\n",
    "text_sex['sex1'] = 1-text_sex['sex2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预测年龄的模型\n",
    "def model_age_conv(embedding_matrix):\n",
    "\n",
    "    # The embedding layer containing the word vectors\n",
    "    K.clear_session()\n",
    "    emb_layer = Embedding(\n",
    "        input_dim=embedding_matrix.shape[0],\n",
    "        output_dim=embedding_matrix.shape[1],\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=maxlen,\n",
    "        trainable=False\n",
    "    )\n",
    "    lstm_layer = Bidirectional(\n",
    "        GRU(128, recurrent_dropout=0.15, dropout=0.15, return_sequences=True))\n",
    "\n",
    "    # 1D convolutions that can iterate over the word vectors\n",
    "    conv1 = Conv1D(filters=128, kernel_size=1,\n",
    "                   padding='same', activation='relu',)\n",
    "    conv2 = Conv1D(filters=64, kernel_size=2,\n",
    "                   padding='same', activation='relu', )\n",
    "    conv3 = Conv1D(filters=64, kernel_size=3,\n",
    "                   padding='same', activation='relu',)\n",
    "    conv5 = Conv1D(filters=32, kernel_size=5,\n",
    "                   padding='same', activation='relu',)\n",
    "\n",
    "    # Define inputs\n",
    "    seq = Input(shape=(maxlen,))\n",
    "\n",
    "    # Run inputs through embedding\n",
    "    emb = emb_layer(seq)\n",
    "\n",
    "    lstm = lstm_layer(emb)\n",
    "    # Run through CONV + GAP layers\n",
    "    conv1a = conv1(lstm)\n",
    "    gap1a = GlobalAveragePooling1D()(conv1a)\n",
    "    gmp1a = GlobalMaxPool1D()(conv1a)\n",
    "\n",
    "    conv2a = conv2(lstm)\n",
    "    gap2a = GlobalAveragePooling1D()(conv2a)\n",
    "    gmp2a = GlobalMaxPool1D()(conv2a)\n",
    "\n",
    "    conv3a = conv3(lstm)\n",
    "    gap3a = GlobalAveragePooling1D()(conv3a)\n",
    "    gmp3a = GlobalMaxPooling1D()(conv3a)\n",
    "\n",
    "    conv5a = conv5(lstm)\n",
    "    gap5a = GlobalAveragePooling1D()(conv5a)\n",
    "    gmp5a = GlobalMaxPooling1D()(conv5a)\n",
    "\n",
    "    # 385 对应于 X_behave 的维度\n",
    "    hin = Input(shape=(385, ))\n",
    "    htime = Dense(64, activation='relu')(hin)\n",
    "    merge1 = concatenate([gap1a, gmp1a, htime])\n",
    "\n",
    "#     merge1 = concatenate([gap1a, gap2a, gap3a, gap5a])\n",
    "\n",
    "    # The MLP that determines the outcome\n",
    "    x = Dropout(0.3)(merge1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(200, activation='relu',)(x)\n",
    "    x = Dropout(0.22)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(200, activation='relu',)(x)\n",
    "    x = Dropout(0.22)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(200, activation='relu',)(x)\n",
    "    x = Dropout(0.22)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    pred = Dense(11, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[seq, hin], outputs=pred)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam())\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型，预测年龄\n",
    "test_age = np.zeros((X_app_test.shape[0], 11))\n",
    "train_age = np.zeros((X_app.shape[0], 11))\n",
    "Y_age = to_categorical(train['age'])\n",
    "\n",
    "score = []\n",
    "for i, (train_index, valid_index) in enumerate(kfold.split(X_app, train['age'])):\n",
    "\n",
    "    print(\"FOLD | \", i+1)\n",
    "\n",
    "    filepath2 = \"model/age_weights_best_%d.h5\" % i\n",
    "    checkpoint2 = ModelCheckpoint(\n",
    "        filepath2, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    reduce_lr2 = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.8, patience=2, min_lr=0.0001, verbose=1)\n",
    "    earlystopping2 = EarlyStopping(\n",
    "        monitor='val_loss', min_delta=0.0001, patience=8, verbose=1, mode='auto')\n",
    "    callbacks2 = [checkpoint2, reduce_lr2, earlystopping2]\n",
    "\n",
    "    model_age = model_age_conv(embedding_matrix)\n",
    "\n",
    "    X_app_train = X_app[train_index]\n",
    "    x_app_valid = X_app[valid_index]\n",
    "    x_behave_train = X_behave[train_index]\n",
    "    x_behave_valid = X_behave[valid_index]\n",
    "    y_train = Y_age[train_index]\n",
    "    y_valid = Y_age[valid_index]  \n",
    "\n",
    "\n",
    "    hist = model_age.fit([X_app_train, x_behave_train], y_train, batch_size=128, epochs=50, validation_data=([x_app_valid, x_behave_valid], y_valid),\n",
    "                         callbacks=callbacks2, verbose=1, shuffle=True)\n",
    "\n",
    "    if os.path.exists(filepath2):\n",
    "        model_age.load_weights(filepath2)\n",
    "    else:\n",
    "        model_age.save_weights(filepath2)\n",
    "    train_age[valid_index] = model_age.predict([x_app_valid, x_behave_valid])\n",
    "    test_age += model_age.predict([X_app_test, X_behave_test])/kfold.n_splits\n",
    "    score.append(np.min(hist.history['val_loss']))\n",
    "print('log loss:', np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据性别和年龄的预测结果，计算各个[性别-年龄]组合的概率，作为与预测集的结果，保存到 csv 中\n",
    "test_age = pd.DataFrame(test_age)\n",
    "test_age1 = test_age\n",
    "test_age2 = test_age\n",
    "for i in range(11):\n",
    "    test_age1[i] = text_sex['sex1']*test_age[i]\n",
    "    test_age2[i] = text_sex['sex2']*test_age[i]\n",
    "id_list=test[['device_id']]\n",
    "id_list.columns = ['DeviceID']\n",
    "final = pd.concat([id_list,test_age1, test_age2], 1)\n",
    "final.columns = ['DeviceID', '1-0', '1-1', '1-2', '1-3', '1-4', '1-5', '1-6',\n",
    "                 '1-7', '1-8', '1-9', '1-10', '2-0', '2-1', '2-2', '2-3', '2-4',\n",
    "                 '2-5', '2-6', '2-7', '2-8', '2-9', '2-10']\n",
    "final.to_csv('./Demo/nn_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
